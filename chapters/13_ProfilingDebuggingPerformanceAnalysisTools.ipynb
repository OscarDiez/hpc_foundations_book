{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tools for Profiling HPC Applications\n",
        "\n",
        "In high-performance computing (HPC), optimizing applications requires a deep understanding of how code interacts with the underlying hardware. Profiling tools provide insights into CPU usage, memory consumption, and performance characteristics. In this section, we explore some widely used tools for CPU and memory profiling, including `gprof`, `perf`, and Intel's VTune.\n",
        "\n",
        "### Gprof and Perf\n",
        "\n",
        "**Gprof** is a GNU profiling tool that collects and arranges statistics on program execution. It is useful for identifying functions consuming the most time, making it ideal for CPU-bound applications. However, Gprof might miss short-lived functions or provide limited insights into multi-threaded programs.\n",
        "\n",
        "**Perf**, built into the Linux kernel, offers a more comprehensive analysis by providing detailed information about CPU usage, cache hits and misses, and more. Perf supports system-wide and application-specific profiling, making it valuable for identifying bottlenecks in complex HPC environments.\n",
        "\n",
        "Example of using `perf` for profiling:\n",
        "```bash\n",
        "perf record -F 99 -a -g -- ./my_hpc_application\n",
        "perf report\n"
      ],
      "metadata": {
        "id": "Jv5jEkrZChrr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools for Profiling HPC Applications\n",
        "\n",
        "In high-performance computing (HPC), it is crucial to understand where computational resources are spent in order to optimize performance. Profiling tools, such as `gprof`, help identify functions that consume the most execution time.\n",
        "\n",
        "In this exercise, we will:\n",
        "1. Write three functions that perform different matrix operations (multiplication, addition, and transpose).\n",
        "2. Use `gprof` to profile the execution and compare the time spent in each function.\n",
        "3. Learn how to analyze profiling reports and identify which function is the most computationally expensive.\n",
        "\n",
        "By understanding profiling reports, we can focus our optimization efforts on the most time-consuming parts of the code.\n"
      ],
      "metadata": {
        "id": "dOWXOX6zDCYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "def is_colab():\n",
        "    # Check if running in Google Colab\n",
        "    return os.path.exists('/content')\n",
        "\n",
        "def is_hpc_cluster():\n",
        "    # Check if running on an HPC cluster\n",
        "    return os.path.exists('/cvmfs/soft.computecanada.ca')\n",
        "\n",
        "def compile_and_run_gprof_code():\n",
        "    # Write the C code for profiling with gprof\n",
        "    code = \"\"\"\n",
        "    #include <stdio.h>\n",
        "    #include <stdlib.h>\n",
        "\n",
        "    #define N 500  // Define matrix size\n",
        "\n",
        "    // Matrix Multiplication\n",
        "    void matrix_multiply(int A[N][N], int B[N][N], int C[N][N]) {\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            for (int j = 0; j < N; j++) {\n",
        "                C[i][j] = 0;\n",
        "                for (int k = 0; k < N; k++) {\n",
        "                    C[i][j] += A[i][k] * B[k][j];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Matrix Addition\n",
        "    void matrix_add(int A[N][N], int B[N][N], int C[N][N]) {\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            for (int j = 0; j < N; j++) {\n",
        "                C[i][j] = A[i][j] + B[i][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Matrix Transpose\n",
        "    void matrix_transpose(int A[N][N], int T[N][N]) {\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            for (int j = 0; j < N; j++) {\n",
        "                T[j][i] = A[i][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    int main() {\n",
        "        int A[N][N], B[N][N], C[N][N], T[N][N];\n",
        "\n",
        "        // Initialize matrices A and B with random values\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            for (int j = 0; j < N; j++) {\n",
        "                A[i][j] = rand() % 100;\n",
        "                B[i][j] = rand() % 100;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // Perform matrix operations\n",
        "        matrix_multiply(A, B, C);      // Matrix Multiplication\n",
        "        matrix_add(A, B, C);           // Matrix Addition\n",
        "        matrix_transpose(A, T);        // Matrix Transpose\n",
        "\n",
        "        return 0;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    # Save the C code to a file\n",
        "    with open(\"matrix_operations.c\", \"w\") as file:\n",
        "        file.write(code)\n",
        "\n",
        "    # Compile the C program with profiling enabled (-pg flag)\n",
        "    if is_colab():\n",
        "        # In Colab\n",
        "        !gcc -pg -o matrix_operations matrix_operations.c\n",
        "        !./matrix_operations\n",
        "        !gprof matrix_operations gmon.out > profile_report.txt\n",
        "        !cat profile_report.txt\n",
        "    elif is_hpc_cluster():\n",
        "        # In HPC Cluster\n",
        "        subprocess.run([\"gcc\", \"-pg\", \"-o\", \"matrix_operations\", \"matrix_operations.c\"])\n",
        "        subprocess.run([\"./matrix_operations\"])\n",
        "        subprocess.run([\"gprof\", \"./matrix_operations\", \"gmon.out\"], stdout=open('profile_report.txt', 'w'))\n",
        "        with open('profile_report.txt', 'r') as f:\n",
        "            print(f.read())\n",
        "\n",
        "# Run the function to compile and profile the code\n",
        "compile_and_run_gprof_code()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dihlr5gLDDNJ",
        "outputId": "069941bd-0f5a-4118-a7c0-846a0d656abe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flat profile:\n",
            "\n",
            "Each sample counts as 0.01 seconds.\n",
            "  %   cumulative   self              self     total           \n",
            " time   seconds   seconds    calls   s/call   s/call  name    \n",
            " 99.35      1.52     1.52        1     1.52     1.52  matrix_multiply\n",
            "  0.65      1.53     0.01        1     0.01     0.01  matrix_transpose\n",
            "  0.00      1.53     0.00        1     0.00     0.00  matrix_add\n",
            "\n",
            " %         the percentage of the total running time of the\n",
            "time       program used by this function.\n",
            "\n",
            "cumulative a running sum of the number of seconds accounted\n",
            " seconds   for by this function and those listed above it.\n",
            "\n",
            " self      the number of seconds accounted for by this\n",
            "seconds    function alone.  This is the major sort for this\n",
            "           listing.\n",
            "\n",
            "calls      the number of times this function was invoked, if\n",
            "           this function is profiled, else blank.\n",
            "\n",
            " self      the average number of milliseconds spent in this\n",
            "ms/call    function per call, if this function is profiled,\n",
            "\t   else blank.\n",
            "\n",
            " total     the average number of milliseconds spent in this\n",
            "ms/call    function and its descendents per call, if this\n",
            "\t   function is profiled, else blank.\n",
            "\n",
            "name       the name of the function.  This is the minor sort\n",
            "           for this listing. The index shows the location of\n",
            "\t   the function in the gprof listing. If the index is\n",
            "\t   in parenthesis it shows where it would appear in\n",
            "\t   the gprof listing if it were to be printed.\n",
            "\f\n",
            "Copyright (C) 2012-2022 Free Software Foundation, Inc.\n",
            "\n",
            "Copying and distribution of this file, with or without modification,\n",
            "are permitted in any medium without royalty provided the copyright\n",
            "notice and this notice are preserved.\n",
            "\f\n",
            "\t\t     Call graph (explanation follows)\n",
            "\n",
            "\n",
            "granularity: each sample hit covers 4 byte(s) for 0.65% of 1.53 seconds\n",
            "\n",
            "index % time    self  children    called     name\n",
            "                                                 <spontaneous>\n",
            "[1]    100.0    0.00    1.53                 main [1]\n",
            "                1.52    0.00       1/1           matrix_multiply [2]\n",
            "                0.01    0.00       1/1           matrix_transpose [3]\n",
            "                0.00    0.00       1/1           matrix_add [4]\n",
            "-----------------------------------------------\n",
            "                1.52    0.00       1/1           main [1]\n",
            "[2]     99.3    1.52    0.00       1         matrix_multiply [2]\n",
            "-----------------------------------------------\n",
            "                0.01    0.00       1/1           main [1]\n",
            "[3]      0.7    0.01    0.00       1         matrix_transpose [3]\n",
            "-----------------------------------------------\n",
            "                0.00    0.00       1/1           main [1]\n",
            "[4]      0.0    0.00    0.00       1         matrix_add [4]\n",
            "-----------------------------------------------\n",
            "\n",
            " This table describes the call tree of the program, and was sorted by\n",
            " the total amount of time spent in each function and its children.\n",
            "\n",
            " Each entry in this table consists of several lines.  The line with the\n",
            " index number at the left hand margin lists the current function.\n",
            " The lines above it list the functions that called this function,\n",
            " and the lines below it list the functions this one called.\n",
            " This line lists:\n",
            "     index\tA unique number given to each element of the table.\n",
            "\t\tIndex numbers are sorted numerically.\n",
            "\t\tThe index number is printed next to every function name so\n",
            "\t\tit is easier to look up where the function is in the table.\n",
            "\n",
            "     % time\tThis is the percentage of the `total' time that was spent\n",
            "\t\tin this function and its children.  Note that due to\n",
            "\t\tdifferent viewpoints, functions excluded by options, etc,\n",
            "\t\tthese numbers will NOT add up to 100%.\n",
            "\n",
            "     self\tThis is the total amount of time spent in this function.\n",
            "\n",
            "     children\tThis is the total amount of time propagated into this\n",
            "\t\tfunction by its children.\n",
            "\n",
            "     called\tThis is the number of times the function was called.\n",
            "\t\tIf the function called itself recursively, the number\n",
            "\t\tonly includes non-recursive calls, and is followed by\n",
            "\t\ta `+' and the number of recursive calls.\n",
            "\n",
            "     name\tThe name of the current function.  The index number is\n",
            "\t\tprinted after it.  If the function is a member of a\n",
            "\t\tcycle, the cycle number is printed between the\n",
            "\t\tfunction's name and the index number.\n",
            "\n",
            "\n",
            " For the function's parents, the fields have the following meanings:\n",
            "\n",
            "     self\tThis is the amount of time that was propagated directly\n",
            "\t\tfrom the function into this parent.\n",
            "\n",
            "     children\tThis is the amount of time that was propagated from\n",
            "\t\tthe function's children into this parent.\n",
            "\n",
            "     called\tThis is the number of times this parent called the\n",
            "\t\tfunction `/' the total number of times the function\n",
            "\t\twas called.  Recursive calls to the function are not\n",
            "\t\tincluded in the number after the `/'.\n",
            "\n",
            "     name\tThis is the name of the parent.  The parent's index\n",
            "\t\tnumber is printed after it.  If the parent is a\n",
            "\t\tmember of a cycle, the cycle number is printed between\n",
            "\t\tthe name and the index number.\n",
            "\n",
            " If the parents of the function cannot be determined, the word\n",
            " `<spontaneous>' is printed in the `name' field, and all the other\n",
            " fields are blank.\n",
            "\n",
            " For the function's children, the fields have the following meanings:\n",
            "\n",
            "     self\tThis is the amount of time that was propagated directly\n",
            "\t\tfrom the child into the function.\n",
            "\n",
            "     children\tThis is the amount of time that was propagated from the\n",
            "\t\tchild's children to the function.\n",
            "\n",
            "     called\tThis is the number of times the function called\n",
            "\t\tthis child `/' the total number of times the child\n",
            "\t\twas called.  Recursive calls by the child are not\n",
            "\t\tlisted in the number after the `/'.\n",
            "\n",
            "     name\tThis is the name of the child.  The child's index\n",
            "\t\tnumber is printed after it.  If the child is a\n",
            "\t\tmember of a cycle, the cycle number is printed\n",
            "\t\tbetween the name and the index number.\n",
            "\n",
            " If there are any cycles (circles) in the call graph, there is an\n",
            " entry for the cycle-as-a-whole.  This entry shows who called the\n",
            " cycle (as parents) and the members of the cycle (as children.)\n",
            " The `+' recursive calls entry shows the number of function calls that\n",
            " were internal to the cycle, and the calls entry for each member shows,\n",
            " for that member, how many times it was called from other members of\n",
            " the cycle.\n",
            "\f\n",
            "Copyright (C) 2012-2022 Free Software Foundation, Inc.\n",
            "\n",
            "Copying and distribution of this file, with or without modification,\n",
            "are permitted in any medium without royalty provided the copyright\n",
            "notice and this notice are preserved.\n",
            "\f\n",
            "Index by function name\n",
            "\n",
            "   [4] matrix_add              [2] matrix_multiply         [3] matrix_transpose\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation of Profiling Code\n",
        "\n",
        "### What the Code Does\n",
        "\n",
        "The C program performs a matrix multiplication of two 500x500 matrices. It is compiled with the `-pg` flag, enabling `gprof` to collect profiling information. This information is saved in a file called `gmon.out`, and `gprof` generates a detailed profiling report that shows how much time was spent in each function.\n",
        "\n",
        "The profiling process is as follows:\n",
        "1. **Matrix Multiplication**: The program generates random 500x500 matrices, multiplies them, and outputs nothing (focusing only on profiling performance).\n",
        "2. **Profiling with `gprof`**: The program is compiled with the `-pg` flag to enable profiling. After running the program, `gprof` is used to generate a profiling report.\n",
        "\n",
        "### Understanding the Report\n",
        "\n",
        "The report will show statistics on function calls, including:\n",
        "- **Self Time**: The time spent in the function itself.\n",
        "- **Total Time**: The total time spent in the function, including calls to other functions.\n",
        "- **Call Graph**: A breakdown of which functions were called, and how much time was spent in each.\n",
        "\n",
        "### Learning Points\n",
        "- **Profiling in HPC**: Profiling helps identify bottlenecks in HPC applications, especially in compute-heavy functions like matrix multiplication.\n",
        "- **Environment-Specific Execution**: This notebook is designed to run in both Google Colab and an HPC cluster, adjusting the commands for each environment.\n",
        "- **Next Steps**: Use this information to optimize the matrix multiplication algorithm by implementing techniques like loop unrolling, blocking, or vectorization to improve performance.\n"
      ],
      "metadata": {
        "id": "-UJivaDJC9e7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Valgrind Memory Profiling Example\n",
        "\n",
        "In this section, we will demonstrate how to use **Valgrind**, a powerful dynamic analysis tool, to detect memory-related issues in a C program. Valgrind can identify problems such as memory leaks, invalid memory access, buffer overflows, and other memory mismanagement issues.\n",
        "\n",
        "The following example intentionally introduces two common memory issues:\n",
        "- **Memory Leak**: We allocate memory for an array but forget to free it, which leads to a memory leak.\n",
        "- **Invalid Write**: The program accesses an out-of-bounds memory location (writing past the allocated memory), which Valgrind will catch as an invalid write.\n",
        "\n",
        "The Valgrind tool will analyze the program and generate detailed information on these issues, helping us understand what went wrong and where.\n",
        "\n",
        "We will:\n",
        "1. Compile a simple C program with memory errors.\n",
        "2. Run the compiled program through Valgrind's Memcheck tool.\n",
        "3. Analyze the Valgrind output to identify the errors.\n",
        "\n",
        "Let's begin by running the following code.\n"
      ],
      "metadata": {
        "id": "VwXb9Z8xFm9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If using a cluster with modules (e.g. Magi Castle)\n",
        "!bash -c \"module load valgrind-mpi/3.16.1 && module list\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkLoud-qIjqy",
        "outputId": "6bd55a0b-4e80-44b1-87b1-e310098d867c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bash: line 1: module: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IF no modules try to install it (e/g/ COLAB)\n",
        "# Install Valgrind (required for Colab and similar environments)\n",
        "!apt-get install -y valgrind\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H65UfYZRGNbp",
        "outputId": "9550d224-703f-4ad1-b38c-91ff2cc7b0d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  gdb libbabeltrace1 libc6-dbg libdebuginfod-common libdebuginfod1 libipt2\n",
            "  libsource-highlight-common libsource-highlight4v5\n",
            "Suggested packages:\n",
            "  gdb-doc gdbserver valgrind-dbg valgrind-mpi kcachegrind alleyoop valkyrie\n",
            "The following NEW packages will be installed:\n",
            "  gdb libbabeltrace1 libc6-dbg libdebuginfod-common libdebuginfod1 libipt2\n",
            "  libsource-highlight-common libsource-highlight4v5 valgrind\n",
            "0 upgraded, 9 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 32.3 MB of archives.\n",
            "After this operation, 111 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdebuginfod-common all 0.186-1build1 [7,878 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libbabeltrace1 amd64 1.5.8-2build1 [160 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdebuginfod1 amd64 0.186-1build1 [12.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libipt2 amd64 2.0.5-1 [46.4 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight-common all 3.1.9-4.1build2 [64.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight4v5 amd64 3.1.9-4.1build2 [207 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gdb amd64 12.1-0ubuntu1~22.04.2 [3,920 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc6-dbg amd64 2.35-0ubuntu3.8 [13.8 MB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 valgrind amd64 1:3.18.1-1ubuntu2 [14.1 MB]\n",
            "Fetched 32.3 MB in 2s (16.6 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package libdebuginfod-common.\n",
            "(Reading database ... 123614 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libdebuginfod-common_0.186-1build1_all.deb ...\n",
            "Unpacking libdebuginfod-common (0.186-1build1) ...\n",
            "Selecting previously unselected package libbabeltrace1:amd64.\n",
            "Preparing to unpack .../1-libbabeltrace1_1.5.8-2build1_amd64.deb ...\n",
            "Unpacking libbabeltrace1:amd64 (1.5.8-2build1) ...\n",
            "Selecting previously unselected package libdebuginfod1:amd64.\n",
            "Preparing to unpack .../2-libdebuginfod1_0.186-1build1_amd64.deb ...\n",
            "Unpacking libdebuginfod1:amd64 (0.186-1build1) ...\n",
            "Selecting previously unselected package libipt2.\n",
            "Preparing to unpack .../3-libipt2_2.0.5-1_amd64.deb ...\n",
            "Unpacking libipt2 (2.0.5-1) ...\n",
            "Selecting previously unselected package libsource-highlight-common.\n",
            "Preparing to unpack .../4-libsource-highlight-common_3.1.9-4.1build2_all.deb ...\n",
            "Unpacking libsource-highlight-common (3.1.9-4.1build2) ...\n",
            "Selecting previously unselected package libsource-highlight4v5.\n",
            "Preparing to unpack .../5-libsource-highlight4v5_3.1.9-4.1build2_amd64.deb ...\n",
            "Unpacking libsource-highlight4v5 (3.1.9-4.1build2) ...\n",
            "Selecting previously unselected package gdb.\n",
            "Preparing to unpack .../6-gdb_12.1-0ubuntu1~22.04.2_amd64.deb ...\n",
            "Unpacking gdb (12.1-0ubuntu1~22.04.2) ...\n",
            "Selecting previously unselected package libc6-dbg:amd64.\n",
            "Preparing to unpack .../7-libc6-dbg_2.35-0ubuntu3.8_amd64.deb ...\n",
            "Unpacking libc6-dbg:amd64 (2.35-0ubuntu3.8) ...\n",
            "Selecting previously unselected package valgrind.\n",
            "Preparing to unpack .../8-valgrind_1%3a3.18.1-1ubuntu2_amd64.deb ...\n",
            "Unpacking valgrind (1:3.18.1-1ubuntu2) ...\n",
            "Setting up libdebuginfod-common (0.186-1build1) ...\n",
            "\n",
            "Creating config file /etc/profile.d/debuginfod.sh with new version\n",
            "\n",
            "Creating config file /etc/profile.d/debuginfod.csh with new version\n",
            "Setting up libdebuginfod1:amd64 (0.186-1build1) ...\n",
            "Setting up libsource-highlight-common (3.1.9-4.1build2) ...\n",
            "Setting up libc6-dbg:amd64 (2.35-0ubuntu3.8) ...\n",
            "Setting up libipt2 (2.0.5-1) ...\n",
            "Setting up libbabeltrace1:amd64 (1.5.8-2build1) ...\n",
            "Setting up valgrind (1:3.18.1-1ubuntu2) ...\n",
            "Setting up libsource-highlight4v5 (3.1.9-4.1build2) ...\n",
            "Setting up gdb (12.1-0ubuntu1~22.04.2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "def run_valgrind_example():\n",
        "    # C code with memory and logic errors\n",
        "    code = \"\"\"\n",
        "    #include <stdio.h>\n",
        "    #include <stdlib.h>\n",
        "\n",
        "    int main() {\n",
        "        int *array = (int*)malloc(5 * sizeof(int));  // Allocate space for 5 integers\n",
        "\n",
        "        // Error: Accessing out-of-bounds memory (invalid write)\n",
        "        for (int i = 0; i <= 5; ++i) {  // The loop should run until i < 5\n",
        "            array[i] = i * 10;\n",
        "        }\n",
        "\n",
        "        // Printing the array\n",
        "        printf(\"Array contents:\\\\n\");\n",
        "        for (int i = 0; i < 5; ++i) {\n",
        "            printf(\"%d \", array[i]);\n",
        "        }\n",
        "        printf(\"\\\\n\");\n",
        "\n",
        "        // Error: Forgetting to free the memory (memory leak)\n",
        "        // free(array);  <-- This line is commented, leading to a memory leak\n",
        "\n",
        "        return 0;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    # Save the C code to a file\n",
        "    with open(\"valgrind_example.c\", \"w\") as file:\n",
        "        file.write(code)\n",
        "\n",
        "    # Compile the C program\n",
        "    compile_result = subprocess.run([\"gcc\", \"-o\", \"valgrind_example\", \"valgrind_example.c\"], capture_output=True, text=True)\n",
        "\n",
        "    if compile_result.returncode != 0:\n",
        "        print(f\"Compilation failed:\\n{compile_result.stderr}\")\n",
        "        return\n",
        "    else:\n",
        "        print(\"Compilation successful.\")\n",
        "\n",
        "    # Run the program with Valgrind's Memcheck tool to detect memory errors\n",
        "    valgrind_command = [\n",
        "        \"valgrind\",\n",
        "        \"--leak-check=full\",           # Detailed memory leak detection\n",
        "        \"--track-origins=yes\",         # Track where uninitialized values come from\n",
        "        \"--show-reachable=yes\",        # Show all reachable memory at the end\n",
        "        \"--log-file=valgrind_log.txt\", # Save Valgrind output to a file\n",
        "        \"./valgrind_example\"\n",
        "    ]\n",
        "\n",
        "    valgrind_result = subprocess.run(valgrind_command, capture_output=True, text=True)\n",
        "\n",
        "    if valgrind_result.returncode != 0:\n",
        "        print(f\"Valgrind execution failed:\\n{valgrind_result.stderr}\")\n",
        "    else:\n",
        "        print(\"Valgrind execution output:\\n\")\n",
        "        with open(\"valgrind_log.txt\", \"r\") as log_file:\n",
        "            print(log_file.read())\n",
        "\n",
        "# Run the function to compile and execute the C program under Valgrind\n",
        "run_valgrind_example()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZvI93c1MJpp",
        "outputId": "46ecad6f-0d98-44cd-d931-4026a5806b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compilation successful.\n",
            "Valgrind execution output:\n",
            "\n",
            "==18106== Memcheck, a memory error detector\n",
            "==18106== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.\n",
            "==18106== Using Valgrind-3.18.1 and LibVEX; rerun with -h for copyright info\n",
            "==18106== Command: ./valgrind_example\n",
            "==18106== Parent PID: 237\n",
            "==18106== \n",
            "==18106== Invalid write of size 4\n",
            "==18106==    at 0x1091ED: main (in /content/valgrind_example)\n",
            "==18106==  Address 0x4a9d054 is 0 bytes after a block of size 20 alloc'd\n",
            "==18106==    at 0x4848899: malloc (in /usr/libexec/valgrind/vgpreload_memcheck-amd64-linux.so)\n",
            "==18106==    by 0x1091BE: main (in /content/valgrind_example)\n",
            "==18106== \n",
            "==18106== \n",
            "==18106== HEAP SUMMARY:\n",
            "==18106==     in use at exit: 20 bytes in 1 blocks\n",
            "==18106==   total heap usage: 2 allocs, 1 frees, 4,116 bytes allocated\n",
            "==18106== \n",
            "==18106== 20 bytes in 1 blocks are definitely lost in loss record 1 of 1\n",
            "==18106==    at 0x4848899: malloc (in /usr/libexec/valgrind/vgpreload_memcheck-amd64-linux.so)\n",
            "==18106==    by 0x1091BE: main (in /content/valgrind_example)\n",
            "==18106== \n",
            "==18106== LEAK SUMMARY:\n",
            "==18106==    definitely lost: 20 bytes in 1 blocks\n",
            "==18106==    indirectly lost: 0 bytes in 0 blocks\n",
            "==18106==      possibly lost: 0 bytes in 0 blocks\n",
            "==18106==    still reachable: 0 bytes in 0 blocks\n",
            "==18106==         suppressed: 0 bytes in 0 blocks\n",
            "==18106== \n",
            "==18106== For lists of detected and suppressed errors, rerun with: -s\n",
            "==18106== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Valgrind Output Explanation\n",
        "\n",
        "The Valgrind Memcheck tool analyzed the program and detected two critical issues:\n",
        "\n",
        "1. **Invalid Write**:\n",
        "    - Valgrind reports an **invalid write** of size 4 (attempting to write an integer).\n",
        "    - This happens because the loop accesses memory beyond the allocated array. The array has 5 elements (index 0 to 4), but the loop tries to access index 5 (`i <= 5` should be `i < 5`).\n",
        "    - Valgrind provides the exact line where the error occurred and the size of the block of memory allocated (`20 bytes for 5 integers`).\n",
        "\n",
        "2. **Memory Leak**:\n",
        "    - Valgrind detects that 20 bytes of memory were **definitely lost**. This means that memory was allocated but never freed, leading to a memory leak.\n",
        "    - Valgrind's **Leak Summary** shows that the program allocated memory but did not free it (since `free(array);` was commented out).\n",
        "\n",
        "This example demonstrates the power of Valgrind in detecting common memory errors that can lead to crashes or inefficient memory usage in programs. Valgrind is particularly useful in ensuring memory safety and identifying bugs that can otherwise be difficult to catch through regular debugging.\n"
      ],
      "metadata": {
        "id": "hPZoJHP8Mr8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Executing Serial and Parallel Profiling on an HPC Cluster with TAU\n",
        "\n",
        "Profiling is a critical technique used in High-Performance Computing (HPC) to identify bottlenecks and optimize code performance. This guide will walk you through the steps to execute serial and parallel profiling on an HPC cluster using **TAU** (Tuning and Analysis Utilities).\n",
        "\n",
        "We will use **matrix multiplication** as an example for both serial and parallel profiling.\n",
        "\n",
        "---\n",
        "\n",
        "## Serial Profiling: Step-by-Step\n",
        "\n",
        "### 1. Loading the Required Modules\n",
        "\n",
        "Before running TAU, you need to load the necessary modules. TAU is typically available on HPC systems as a module. To check if TAU is available and load it, run the following commands:\n",
        "\n",
        "```bash\n",
        "module avail tau   # Check if TAU is available on your cluster\n",
        "module load tau/2.30.1  # Load the required version of TAU\n"
      ],
      "metadata": {
        "id": "t1xtGcKYcpm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### **Step 2: Serial Matrix Multiplication Program (C)**\n",
        "\n",
        "The following C code performs matrix multiplication for two 500x500 matrices.\n",
        "\n",
        "```c\n",
        "#include <stdio.h>\n",
        "\n",
        "#define N 500  // Size of the matrix\n",
        "\n",
        "void matrix_multiply(double A[N][N], double B[N][N], double C[N][N]) {\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            C[i][j] = 0;\n",
        "            for (int k = 0; k < N; k++) {\n",
        "                C[i][j] += A[i][k] * B[k][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    double A[N][N], B[N][N], C[N][N];\n",
        "    \n",
        "    // Initialize matrices A and B\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            A[i][j] = i + j;\n",
        "            B[i][j] = i - j;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Perform matrix multiplication\n",
        "    matrix_multiply(A, B, C);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "4T5C2Vy9d04m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Step 3: Compiling the Serial Program**\n",
        "\n",
        "Use TAU's compiler to instrument the code for profiling:\n",
        "\n",
        "```bash\n",
        "tau_cc -o matrix_serial matrix_multiply.c\n",
        "```\n",
        "\n",
        "This will compile the serial matrix multiplication program and prepare it for profiling.\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 4: Running the Serial Program**\n",
        "\n",
        "Now, run the compiled program:\n",
        "\n",
        "```bash\n",
        "./matrix_serial\n",
        "```\n",
        "\n",
        "This will generate a profiling log of the program’s execution.\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 5: Viewing the Profiling Results**\n",
        "\n",
        "Once the program finishes running, use TAU’s `pprof` tool to view the profiling results:\n",
        "\n",
        "\n",
        "You will see a table showing the breakdown of where the program spent its time. The output might look like this:\n",
        "\n",
        "```bash\n",
        "% cumulative self self total time seconds seconds calls ms/call ms/call name 75.0 0.30 0.30 1 300.00 400.00 matrix_multiply 25.0 0.40 0.10 1 100.00 100.00 initialize_matrix\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 6: Analysis**\n",
        "\n",
        "The output shows that the `matrix_multiply` function takes the majority of the program’s execution time. This function can be optimized by techniques such as:\n",
        "\n",
        "- **Loop Unrolling**: Reduces loop overhead and increases instruction-level parallelism.\n",
        "- **Cache Blocking**: Improves cache usage by breaking down the matrix into smaller blocks.\n",
        "\n"
      ],
      "metadata": {
        "id": "m6iZr_s_fHUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parallel Matrix Multiplication Code\n",
        "### **Step 1: Writing the Parallel Matrix Multiplication Code**\n",
        "\n",
        "The following code demonstrates a parallel matrix multiplication implementation using MPI. This code will be used to perform profiling on a parallel workload:\n",
        "\n",
        "```c\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define N 4  // Matrix size (N x N)\n",
        "\n",
        "void matrix_multiply(double A[N][N], double B[N][N], double C[N][N]) {\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            C[i][j] = 0;\n",
        "            for (int k = 0; k < N; k++) {\n",
        "                C[i][j] += A[i][k] * B[k][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    MPI_Init(&argc, &argv);  // Initialize MPI\n",
        "\n",
        "    int rank, size;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "\n",
        "    double A[N][N], B[N][N], C[N][N];\n",
        "\n",
        "    // Initialize matrices A and B\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            A[i][j] = rank + i + j;\n",
        "            B[i][j] = rank + i - j;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Perform matrix multiplication\n",
        "    matrix_multiply(A, B, C);\n",
        "\n",
        "    // Print the result matrix from process 0\n",
        "    if (rank == 0) {\n",
        "        printf(\"Matrix C (result):\\n\");\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            for (int j = 0; j < N; j++) {\n",
        "                printf(\"%f \", C[i][j]);\n",
        "            }\n",
        "            printf(\"\\n\");\n",
        "        }\n",
        "    }\n",
        "\n",
        "    MPI_Finalize();  // Finalize MPI\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "b5BHOpyAfyF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2: Compiling the Parallel Program**\n",
        "\n",
        "To instrument the code for profiling with TAU and compile it, use the following command:\n",
        "\n",
        "```bash\n",
        "tau_cc -T mpi -o matrix_parallel mpi_matrix_multiply.c\n",
        "```\n",
        "\n",
        "This will compile the program and instrument it for parallel profiling.\n",
        "\n",
        "Step 3: Running the Parallel Program with TAU\n",
        "Run the instrumented parallel program using mpirun and tau_exec to trace the parallel execution:\n",
        "\n",
        "```bash\n",
        "tau_exec mpirun --oversubscribe -np 4 ./matrix_parallel\n",
        "```\n",
        "\n",
        "The --oversubscribe flag allows more processes than the available CPU cores in testing environments. After executing the program, TAU will record profiling data for each MPI process.\n",
        "\n",
        "Step 4: Viewing the Profiling Data\n",
        "Once the program finishes, you can view the profiling data using TAU’s paraprof tool, which provides a GUI interface to visualize the results:\n",
        "\n",
        "```bash\n",
        "paraprof\n",
        "```\n",
        "\n",
        "In case you encounter issues with Java, ensure that the correct version of Java is loaded using the appropriate module (e.g., module load java/17.0.2).\n",
        "\n",
        "Step 5: Analyzing the Profiling Output\n",
        "TAU will generate a detailed report that includes information about MPI calls and the time spent in each function. An example of the analysis output might look like this:\n",
        "\n",
        "```bash\n",
        "Process 0: Time spent in MPI_Wait: 50%\n",
        "Process 1: Time spent in MPI_Wait: 5%\n",
        "Process 2: Time spent in MPI_Wait: 5%\n",
        "```\n",
        "\n",
        "This suggests that process 0 is spending a significant amount of time waiting, likely due to load imbalance. Improving load balancing by redistributing matrix blocks or optimizing communication can enhance performance.\n",
        "\n",
        "Step 6: Optimization Suggestions\n",
        "The profiling results indicate that the workload is not evenly distributed across the processes. To address this:\n",
        "\n",
        "Redistribute Matrix Blocks: Split matrix blocks evenly across processes to ensure that no single process does more work than others.\n",
        "Optimize Communication: Reduce the time spent waiting for data from other processes by optimizing communication between processes using non-blocking MPI calls."
      ],
      "metadata": {
        "id": "3gn0F4-ef62I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Profiling in HPC with Gperftools\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this practice, we will explore how to profile applications in a high-performance computing (HPC) environment using **gperftools**. Gperftools is a popular set of performance analysis tools originally developed by Google and widely used in HPC to measure CPU and memory usage in large-scale applications. Profiling is a crucial step in optimizing HPC applications, as it helps developers identify bottlenecks and inefficient code paths, which is especially important in parallel and distributed computing environments.\n",
        "\n",
        "We will focus on two main tools in this suite:\n",
        "1. **pprof**: A CPU statistical profiler that provides insights into the time spent in different parts of a program.\n",
        "2. **tc_malloc**: A thread-caching memory allocator that enhances memory allocation performance and supports dynamic memory profiling.\n",
        "\n",
        "By the end of this practice, you will:\n",
        "- Learn how to use gperftools to profile a basic C++ application.\n",
        "- Understand how to interpret profiling data for performance tuning.\n",
        "- Explore profiling in both single-node and multi-node (MPI-based) setups.\n",
        "\n",
        "**Why profiling?**\n",
        "Profiling helps us to:\n",
        "- Identify performance bottlenecks.\n",
        "- Optimize the code for better CPU usage.\n",
        "- Monitor memory leaks and dynamic memory allocation issues.\n",
        "- Enhance scalability by understanding the performance of MPI-based parallel applications.\n",
        "\n",
        "---\n",
        "\n",
        "## Steps for Profiling with Gperftools\n",
        "\n",
        "We will use a simple matrix multiplication program as our example to understand how profiling works. This example will be written in C++, and we will:\n",
        "1. Compile the program with gperftools profiling enabled.\n",
        "2. Run the program to generate a profile report.\n",
        "3. Analyze the profiling report using `pprof`.\n",
        "\n",
        "**Note:** The profiling tools need to be installed in the environment where the code is run, which we will do step by step in this notebook.\n",
        "\n",
        "---\n",
        "\n",
        "## Installation of Gperftools in Google Colab\n",
        "\n",
        "We will first install `gperftools` in Google Colab as it is not natively available.\n"
      ],
      "metadata": {
        "id": "-rQICJH5hgIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq libgoogle-perftools-dev graphviz ghostscript"
      ],
      "metadata": {
        "id": "omrOZ27qHdEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a C++ source file with both inefficient and optimized functions\n",
        "cpp_code = \"\"\"\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <gperftools/profiler.h>\n",
        "#include <chrono>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// Inefficient matrix multiplication\n",
        "void matrixMultiplyInefficient(int N) {\n",
        "    vector<vector<int>> A(N, vector<int>(N, 1));\n",
        "    vector<vector<int>> B(N, vector<int>(N, 1));\n",
        "    vector<vector<int>> C(N, vector<int>(N, 0));\n",
        "\n",
        "    // Inefficient nested loops (bad cache usage)\n",
        "    for (int j = 0; j < N; ++j) {\n",
        "        for (int i = 0; i < N; ++i) {\n",
        "            for (int k = 0; k < N; ++k) {\n",
        "                C[j][i] += A[k][j] * B[i][k];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Optimized matrix multiplication\n",
        "void matrixMultiplyOptimized(int N) {\n",
        "    vector<vector<int>> A(N, vector<int>(N, 1));\n",
        "    vector<vector<int>> B(N, vector<int>(N, 1));\n",
        "    vector<vector<int>> C(N, vector<int>(N, 0));\n",
        "\n",
        "    // Optimized nested loops (better cache usage)\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int k = 0; k < N; ++k) {\n",
        "            int r = A[i][k];\n",
        "            for (int j = 0; j < N; ++j) {\n",
        "                C[i][j] += r * B[k][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 500;  // Adjusted matrix size for demonstration\n",
        "\n",
        "    // Start profiling\n",
        "    ProfilerStart(\"matrixmult.prof\");\n",
        "\n",
        "    // Measure execution time of the inefficient function\n",
        "    auto start = chrono::high_resolution_clock::now();\n",
        "    matrixMultiplyInefficient(N);\n",
        "    auto end = chrono::high_resolution_clock::now();\n",
        "    auto duration_inefficient = chrono::duration_cast<chrono::milliseconds>(end - start).count();\n",
        "    cout << \"Inefficient function time: \" << duration_inefficient << \" ms\" << endl;\n",
        "\n",
        "    // Measure execution time of the optimized function\n",
        "    start = chrono::high_resolution_clock::now();\n",
        "    matrixMultiplyOptimized(N);\n",
        "    end = chrono::high_resolution_clock::now();\n",
        "    auto duration_optimized = chrono::duration_cast<chrono::milliseconds>(end - start).count();\n",
        "    cout << \"Optimized function time: \" << duration_optimized << \" ms\" << endl;\n",
        "\n",
        "    // Stop profiling\n",
        "    ProfilerStop();\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Save the C++ code to a file\n",
        "with open(\"matrixmult.cpp\", \"w\") as file:\n",
        "    file.write(cpp_code)\n"
      ],
      "metadata": {
        "id": "9uTWLMmnHYk0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compile the code with debug symbols\n",
        "!g++ -O2 -g matrixmult.cpp -o matrixmult -lprofiler\n",
        "\n",
        "# Run the compiled program\n",
        "!./matrixmult\n",
        "\n",
        "# Generate an SVG profiling report\n",
        "!pprof --svg ./matrixmult matrixmult.prof > profiling_report.svg\n",
        "\n",
        "# Display the SVG report\n",
        "from IPython.display import SVG, display\n",
        "display(SVG(filename='profiling_report.svg'))\n",
        "\n",
        "# Display line-by-line profiling report\n",
        "print(\"Line-by-Line Profiling Report:\")\n",
        "!pprof --lines --text ./matrixmult matrixmult.prof\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "V06YjNUiHiwn",
        "outputId": "3ba073a3-abe8-4c2e-e109-b65dcc39ac77"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inefficient function time: 176 ms\n",
            "Optimized function time: 106 ms\n",
            "PROFILE: interrupts/evictions/bytes = 28/10/848\n",
            "Using local file ./matrixmult.\n",
            "Using local file matrixmult.prof.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100%\" height=\"100%\">\n<script type=\"text/ecmascript\"><![CDATA[\n// SVGPan\n// http://www.cyberz.org/blog/2009/12/08/svgpan-a-javascript-svg-panzoomdrag-library/\n// Local modification: if(true || ...) below to force panning, never moving.\n\n/**\n *  SVGPan library 1.2\n * ====================\n *\n * Given an unique existing element with id \"viewport\", including the\n * the library into any SVG adds the following capabilities:\n *\n *  - Mouse panning\n *  - Mouse zooming (using the wheel)\n *  - Object dargging\n *\n * Known issues:\n *\n *  - Zooming (while panning) on Safari has still some issues\n *\n * Releases:\n *\n * 1.2, Sat Mar 20 08:42:50 GMT 2010, Zeng Xiaohui\n *\tFixed a bug with browser mouse handler interaction\n *\n * 1.1, Wed Feb  3 17:39:33 GMT 2010, Zeng Xiaohui\n *\tUpdated the zoom code to support the mouse wheel on Safari/Chrome\n *\n * 1.0, Andrea Leofreddi\n *\tFirst release\n *\n * This code is licensed under the following BSD license:\n *\n * Copyright 2009-2010 Andrea Leofreddi <a.leofreddi@itcharm.com>. All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without modification, are\n * permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice, this list of\n *       conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above copyright notice, this list\n *       of conditions and the following disclaimer in the documentation and/or other materials\n *       provided with the distribution.\n *\n * THIS SOFTWARE IS PROVIDED BY Andrea Leofreddi ``AS IS'' AND ANY EXPRESS OR IMPLIED\n * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND\n * FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL Andrea Leofreddi OR\n * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\n * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\n * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n *\n * The views and conclusions contained in the software and documentation are those of the\n * authors and should not be interpreted as representing official policies, either expressed\n * or implied, of Andrea Leofreddi.\n */\n\nvar root = document.documentElement;\n\nvar state = 'none', stateTarget, stateOrigin, stateTf;\n\nsetupHandlers(root);\n\n/**\n * Register handlers\n */\nfunction setupHandlers(root){\n\tsetAttributes(root, {\n\t\t\"onmouseup\" : \"add(evt)\",\n\t\t\"onmousedown\" : \"handleMouseDown(evt)\",\n\t\t\"onmousemove\" : \"handleMouseMove(evt)\",\n\t\t\"onmouseup\" : \"handleMouseUp(evt)\",\n\t\t//\"onmouseout\" : \"handleMouseUp(evt)\", // Decomment this to stop the pan functionality when dragging out of the SVG element\n\t});\n\n\tif(navigator.userAgent.toLowerCase().indexOf('webkit') >= 0)\n\t\twindow.addEventListener('mousewheel', handleMouseWheel, false); // Chrome/Safari\n\telse\n\t\twindow.addEventListener('DOMMouseScroll', handleMouseWheel, false); // Others\n\n\tvar g = svgDoc.getElementById(\"svg\");\n\tg.width = \"100%\";\n\tg.height = \"100%\";\n}\n\n/**\n * Instance an SVGPoint object with given event coordinates.\n */\nfunction getEventPoint(evt) {\n\tvar p = root.createSVGPoint();\n\n\tp.x = evt.clientX;\n\tp.y = evt.clientY;\n\n\treturn p;\n}\n\n/**\n * Sets the current transform matrix of an element.\n */\nfunction setCTM(element, matrix) {\n\tvar s = \"matrix(\" + matrix.a + \",\" + matrix.b + \",\" + matrix.c + \",\" + matrix.d + \",\" + matrix.e + \",\" + matrix.f + \")\";\n\n\telement.setAttribute(\"transform\", s);\n}\n\n/**\n * Dumps a matrix to a string (useful for debug).\n */\nfunction dumpMatrix(matrix) {\n\tvar s = \"[ \" + matrix.a + \", \" + matrix.c + \", \" + matrix.e + \"\\n  \" + matrix.b + \", \" + matrix.d + \", \" + matrix.f + \"\\n  0, 0, 1 ]\";\n\n\treturn s;\n}\n\n/**\n * Sets attributes of an element.\n */\nfunction setAttributes(element, attributes){\n\tfor (i in attributes)\n\t\telement.setAttributeNS(null, i, attributes[i]);\n}\n\n/**\n * Handle mouse move event.\n */\nfunction handleMouseWheel(evt) {\n\tif(evt.preventDefault)\n\t\tevt.preventDefault();\n\n\tevt.returnValue = false;\n\n\tvar svgDoc = evt.target.ownerDocument;\n\n\tvar delta;\n\n\tif(evt.wheelDelta)\n\t\tdelta = evt.wheelDelta / 3600; // Chrome/Safari\n\telse\n\t\tdelta = evt.detail / -90; // Mozilla\n\n\tvar z = 1 + delta; // Zoom factor: 0.9/1.1\n\n\tvar g = svgDoc.getElementById(\"viewport\");\n\n\tvar p = getEventPoint(evt);\n\n\tp = p.matrixTransform(g.getCTM().inverse());\n\n\t// Compute new scale matrix in current mouse position\n\tvar k = root.createSVGMatrix().translate(p.x, p.y).scale(z).translate(-p.x, -p.y);\n\n        setCTM(g, g.getCTM().multiply(k));\n\n\tstateTf = stateTf.multiply(k.inverse());\n}\n\n/**\n * Handle mouse move event.\n */\nfunction handleMouseMove(evt) {\n\tif(evt.preventDefault)\n\t\tevt.preventDefault();\n\n\tevt.returnValue = false;\n\n\tvar svgDoc = evt.target.ownerDocument;\n\n\tvar g = svgDoc.getElementById(\"viewport\");\n\n\tif(state == 'pan') {\n\t\t// Pan mode\n\t\tvar p = getEventPoint(evt).matrixTransform(stateTf);\n\n\t\tsetCTM(g, stateTf.inverse().translate(p.x - stateOrigin.x, p.y - stateOrigin.y));\n\t} else if(state == 'move') {\n\t\t// Move mode\n\t\tvar p = getEventPoint(evt).matrixTransform(g.getCTM().inverse());\n\n\t\tsetCTM(stateTarget, root.createSVGMatrix().translate(p.x - stateOrigin.x, p.y - stateOrigin.y).multiply(g.getCTM().inverse()).multiply(stateTarget.getCTM()));\n\n\t\tstateOrigin = p;\n\t}\n}\n\n/**\n * Handle click event.\n */\nfunction handleMouseDown(evt) {\n\tif(evt.preventDefault)\n\t\tevt.preventDefault();\n\n\tevt.returnValue = false;\n\n\tvar svgDoc = evt.target.ownerDocument;\n\n\tvar g = svgDoc.getElementById(\"viewport\");\n\n\tif(true || evt.target.tagName == \"svg\") {\n\t\t// Pan mode\n\t\tstate = 'pan';\n\n\t\tstateTf = g.getCTM().inverse();\n\n\t\tstateOrigin = getEventPoint(evt).matrixTransform(stateTf);\n\t} else {\n\t\t// Move mode\n\t\tstate = 'move';\n\n\t\tstateTarget = evt.target;\n\n\t\tstateTf = g.getCTM().inverse();\n\n\t\tstateOrigin = getEventPoint(evt).matrixTransform(stateTf);\n\t}\n}\n\n/**\n * Handle mouse button release event.\n */\nfunction handleMouseUp(evt) {\n\tif(evt.preventDefault)\n\t\tevt.preventDefault();\n\n\tevt.returnValue = false;\n\n\tvar svgDoc = evt.target.ownerDocument;\n\n\tif(state == 'pan' || state == 'move') {\n\t\t// Quit pan mode\n\t\tstate = '';\n\t}\n}\n\n]]></script>\n<g id=\"viewport\" transform=\"translate(0,0)\">\n<g id=\"viewport\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 563)\">\n<title>./matrixmult; 28 samples</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-563 1137.5,-563 1137.5,4 -4,4\"/>\n<!-- Legend -->\n<g id=\"node1\" class=\"node\">\n<title>Legend</title>\n<text text-anchor=\"start\" x=\"8\" y=\"-535.8\" font-family=\"Times,serif\" font-size=\"24.00\">./matrixmult</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-509.8\" font-family=\"Times,serif\" font-size=\"24.00\">Total samples: 28</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-483.8\" font-family=\"Times,serif\" font-size=\"24.00\">Focusing on: 28</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-457.8\" font-family=\"Times,serif\" font-size=\"24.00\">Dropped nodes with &lt;= 0 abs(samples)</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-431.8\" font-family=\"Times,serif\" font-size=\"24.00\">Dropped edges with &lt;= 0 samples</text>\n</g>\n<!-- N1 -->\n<g id=\"node2\" class=\"node\">\n<title>N1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"486.5,-284 397.5,-284 397.5,-249 486.5,-249 486.5,-284\"/>\n<text text-anchor=\"middle\" x=\"442\" y=\"-273.6\" font-family=\"Times,serif\" font-size=\"8.00\">__libc_start_call_main</text>\n<text text-anchor=\"end\" x=\"478.5\" y=\"-264.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"478.5\" y=\"-255.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 28 (100.0%)</text>\n</g>\n<!-- N4 -->\n<g id=\"node5\" class=\"node\">\n<title>N4</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"474.5,-198 409.5,-198 409.5,-163 474.5,-163 474.5,-198\"/>\n<text text-anchor=\"middle\" x=\"442\" y=\"-187.6\" font-family=\"Times,serif\" font-size=\"8.00\">main</text>\n<text text-anchor=\"end\" x=\"466.5\" y=\"-178.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"466.5\" y=\"-169.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 28 (100.0%)</text>\n</g>\n<!-- N1&#45;&gt;N4 -->\n<g id=\"edge2\" class=\"edge\">\n<title>N1-&gt;N4</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"2\" d=\"M442,-248.9C442,-237.28 442,-221.51 442,-208.14\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"2\" points=\"445.5,-208.06 442,-198.06 438.5,-208.06 445.5,-208.06\"/>\n<text text-anchor=\"middle\" x=\"449\" y=\"-219.8\" font-family=\"Times,serif\" font-size=\"14.00\">28</text>\n</g>\n<!-- N2 -->\n<g id=\"node3\" class=\"node\">\n<title>N2</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"488,-370 396,-370 396,-335 488,-335 488,-370\"/>\n<text text-anchor=\"middle\" x=\"442\" y=\"-359.6\" font-family=\"Times,serif\" font-size=\"8.00\">__libc_start_main_impl</text>\n<text text-anchor=\"end\" x=\"480\" y=\"-350.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"480\" y=\"-341.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 28 (100.0%)</text>\n</g>\n<!-- N2&#45;&gt;N1 -->\n<g id=\"edge3\" class=\"edge\">\n<title>N2-&gt;N1</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"2\" d=\"M442,-334.9C442,-323.28 442,-307.51 442,-294.14\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"2\" points=\"445.5,-294.06 442,-284.06 438.5,-294.06 445.5,-294.06\"/>\n<text text-anchor=\"middle\" x=\"449\" y=\"-305.8\" font-family=\"Times,serif\" font-size=\"14.00\">28</text>\n</g>\n<!-- N3 -->\n<g id=\"node4\" class=\"node\">\n<title>N3</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"474.5,-507.5 409.5,-507.5 409.5,-472.5 474.5,-472.5 474.5,-507.5\"/>\n<text text-anchor=\"middle\" x=\"442\" y=\"-497.1\" font-family=\"Times,serif\" font-size=\"8.00\">_start</text>\n<text text-anchor=\"end\" x=\"466.5\" y=\"-488.1\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"466.5\" y=\"-479.1\" font-family=\"Times,serif\" font-size=\"8.00\">of 28 (100.0%)</text>\n</g>\n<!-- N3&#45;&gt;N2 -->\n<g id=\"edge1\" class=\"edge\">\n<title>N3-&gt;N2</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"2\" d=\"M442,-472.39C442,-449.43 442,-407.74 442,-380.33\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"2\" points=\"445.5,-380.25 442,-370.25 438.5,-380.25 445.5,-380.25\"/>\n<text text-anchor=\"middle\" x=\"449\" y=\"-391.8\" font-family=\"Times,serif\" font-size=\"14.00\">28</text>\n</g>\n<!-- N5 -->\n<g id=\"node6\" class=\"node\">\n<title>N5</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"690,-112 194,-112 194,0 690,0 690,-112\"/>\n<text text-anchor=\"middle\" x=\"442\" y=\"-70.4\" font-family=\"Times,serif\" font-size=\"47.00\">matrixMultiplyInefficient</text>\n<text text-anchor=\"end\" x=\"682\" y=\"-18.4\" font-family=\"Times,serif\" font-size=\"47.00\">17 (60.7%)</text>\n</g>\n<!-- N4&#45;&gt;N5 -->\n<g id=\"edge4\" class=\"edge\">\n<title>N4-&gt;N5</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"2\" d=\"M442,-162.98C442,-152.31 442,-137.67 442,-122.67\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"2\" points=\"445.5,-122.27 442,-112.27 438.5,-122.27 445.5,-122.27\"/>\n<text text-anchor=\"middle\" x=\"449\" y=\"-133.8\" font-family=\"Times,serif\" font-size=\"14.00\">17</text>\n</g>\n<!-- N6 -->\n<g id=\"node7\" class=\"node\">\n<title>N6</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1133.5,-103 708.5,-103 708.5,-9 1133.5,-9 1133.5,-103\"/>\n<text text-anchor=\"middle\" x=\"921\" y=\"-67.56\" font-family=\"Times,serif\" font-size=\"39.30\">matrixMultiplyOptimized</text>\n<text text-anchor=\"end\" x=\"1125.5\" y=\"-24.56\" font-family=\"Times,serif\" font-size=\"39.30\">11 (39.3%)</text>\n</g>\n<!-- N4&#45;&gt;N6 -->\n<g id=\"edge5\" class=\"edge\">\n<title>N4-&gt;N6</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"2\" d=\"M474.55,-171.18C527.17,-157.72 634.79,-130.19 731.18,-105.54\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"2\" points=\"732.25,-108.88 741.07,-103.01 730.52,-102.1 732.25,-108.88\"/>\n<text text-anchor=\"middle\" x=\"631\" y=\"-133.8\" font-family=\"Times,serif\" font-size=\"14.00\">11</text>\n</g>\n</g>\n</g></svg>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Line-by-Line Profiling Report:\n",
            "Using local file ./matrixmult.\n",
            "Using local file matrixmult.prof.\n",
            "Total: 28 samples\n",
            "      13  46.4%  46.4%       13  46.4% matrixMultiplyInefficient /content/matrixmult.cpp:19\n",
            "       6  21.4%  67.9%        6  21.4% matrixMultiplyOptimized /content/matrixmult.cpp:36\n",
            "       5  17.9%  85.7%        5  17.9% matrixMultiplyOptimized /content/matrixmult.cpp:35\n",
            "       4  14.3% 100.0%        4  14.3% matrixMultiplyInefficient /content/matrixmult.cpp:18\n",
            "       0   0.0% 100.0%       28 100.0% __libc_start_call_main ./csu/../sysdeps/nptl/libc_start_call_main.h:58\n",
            "       0   0.0% 100.0%       28 100.0% __libc_start_main_impl ./csu/../csu/libc-start.c:392\n",
            "       0   0.0% 100.0%       28 100.0% _start ??:0\n",
            "       0   0.0% 100.0%       17  60.7% main /content/matrixmult.cpp:50\n",
            "       0   0.0% 100.0%       11  39.3% main /content/matrixmult.cpp:57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nlkOaVmQjCG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation of Code Sections\n",
        "\n",
        "### 1. Installation of Gperftools\n",
        "\n",
        "We start by installing `gperftools` in Google Colab. The command `apt-get install google-perftools` installs the necessary libraries for using gperftools, including the CPU profiler `pprof` and memory allocator `tc_malloc`.\n",
        "\n",
        "### 2. Writing and Compiling the Matrix Multiplication Program\n",
        "\n",
        "In this example, we created a C++ program that performs matrix multiplication on two square matrices of size `N`. Matrix multiplication is a good candidate for profiling in HPC environments because of its computational intensity and potential memory bottlenecks.\n",
        "\n",
        "The program is instrumented with gperftools using the `ProfilerStart` and `ProfilerStop` functions, which enable profiling around the matrix multiplication logic. We use the command `env CPUPROFILE=matrixmult.prof ./matrixmult` to run the program and generate a profile.\n",
        "\n",
        "### 3. Analyzing the Profile\n",
        "\n",
        "We then use the `pprof` tool to analyze the generated profiling data. The text-based report produced by `pprof --text` gives us insights into the function execution time. To better visualize the data, we generate a PDF using `pprof --pdf` which contains a graph showing the CPU usage breakdown across different functions.\n",
        "\n",
        "The results allow us to see which parts of the matrix multiplication are consuming the most resources, and based on that, we can optimize the code by improving algorithmic efficiency or better utilizing memory.\n"
      ],
      "metadata": {
        "id": "wGTG3HiOh5yL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Profiling C++ Programs with gperftools: Theory and Methodology\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Performance optimization is a critical aspect of software development, especially for computationally intensive applications. Profiling tools help developers understand where their programs spend most of their execution time, enabling targeted optimizations for improved efficiency.\n",
        "\n",
        "In this notebook, we will explore how to profile a C++ program using **gperftools**, a powerful profiling library developed by Google. We will:\n",
        "\n",
        "- **Discuss the importance of profiling and how it aids in optimization.**\n",
        "- **Introduce the concepts behind gperftools and how it collects profiling data.**\n",
        "- **Create a complex C++ program with multiple computational functions.**\n",
        "- **Use gperftools to profile the program and generate visual representations of its performance.**\n",
        "\n",
        "## Why Profiling Matters\n",
        "\n",
        "Profiling allows developers to:\n",
        "\n",
        "- **Identify Performance Bottlenecks:** Determine which parts of the code consume the most resources.\n",
        "- **Understand Program Behavior:** Gain insights into function calls and execution flow.\n",
        "- **Guide Optimization Efforts:** Focus on areas that will yield the most significant performance gains.\n",
        "- **Validate Optimizations:** Confirm that code changes have the desired effect on performance.\n",
        "\n",
        "Without profiling, optimization efforts may be misguided, potentially wasting time on parts of the code that have minimal impact on overall performance.\n",
        "\n",
        "## Overview of gperftools\n",
        "\n",
        "**gperftools** is a collection of tools for analyzing and improving the performance of C++ programs. It includes:\n",
        "\n",
        "- **CPU Profiler:** Samples the program's execution to identify where it spends most of its time.\n",
        "- **Heap Checker and Profiler:** Helps detect memory leaks and analyze memory usage.\n",
        "- **Thread-Caching Malloc:** An efficient memory allocator that can improve performance.\n",
        "\n",
        "In this notebook, we'll focus on the CPU Profiler to analyze our program's execution.\n",
        "\n",
        "## The C++ Program\n",
        "\n",
        "Our program consists of several computational functions, each demonstrating different aspects of performance:\n",
        "\n",
        "1. **Recursive Fibonacci (`fib_recursive`):**\n",
        "\n",
        "   - Calculates Fibonacci numbers using recursion.\n",
        "   - **Inefficient** due to redundant calculations.\n",
        "   - Exhibits exponential time complexity.\n",
        "\n",
        "2. **Iterative Fibonacci (`fib_iterative`):**\n",
        "\n",
        "   - Calculates Fibonacci numbers using iteration.\n",
        "   - **Efficient** with linear time complexity.\n",
        "\n",
        "3. **Prime Number Generation (`generate_primes`):**\n",
        "\n",
        "   - Uses the **Sieve of Eratosthenes** algorithm.\n",
        "   - Efficiently generates all prime numbers up to a given limit.\n",
        "\n",
        "4. **Naive Matrix Multiplication (`matrixMultiplyNaive`):**\n",
        "\n",
        "   - Performs matrix multiplication with a straightforward triple-nested loop.\n",
        "   - **Inefficient** due to poor memory access patterns and cache usage.\n",
        "\n",
        "5. **Optimized Matrix Multiplication (`matrixMultiplyOptimized`):**\n",
        "\n",
        "   - Improves upon the naive version by optimizing loop ordering and memory access.\n",
        "   - **Efficient** with better cache utilization.\n",
        "\n",
        "## What We Will Do\n",
        "\n",
        "- **Compile and Run the Program:**\n",
        "\n",
        "  - We'll compile the C++ program with profiling enabled.\n",
        "  - Execute the program to generate profiling data.\n",
        "\n",
        "- **Profile the Program with gperftools:**\n",
        "\n",
        "  - Use gperftools to collect CPU usage samples during execution.\n",
        "  - Generate a profiling report that highlights where the program spends its time.\n",
        "\n",
        "- **Visualize the Profiling Data:**\n",
        "\n",
        "  - Create visual representations, such as call graphs and flame graphs.\n",
        "  - Analyze these visuals to understand function relationships and performance hotspots.\n",
        "\n",
        "- **Interpret the Results:**\n",
        "\n",
        "  - Compare the performance of recursive and iterative Fibonacci implementations.\n",
        "  - Examine the impact of optimizing matrix multiplication.\n",
        "  - Discuss how the profiling data informs optimization decisions.\n",
        "\n",
        "By the end of this exercise, you'll have a deeper understanding of how to use profiling tools to analyze and optimize C++ programs, and you'll be equipped to apply these techniques to your own projects.\n"
      ],
      "metadata": {
        "id": "LSQg9y6_JmIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq libgoogle-perftools-dev graphviz ghostscript\n"
      ],
      "metadata": {
        "id": "58GSw2MfI2dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the C++ code\n",
        "cpp_code = \"\"\"\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <gperftools/profiler.h>\n",
        "#include <chrono>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// Recursive Fibonacci\n",
        "int fib_recursive(int n) {\n",
        "    if (n <= 1)\n",
        "        return n;\n",
        "    else\n",
        "        return fib_recursive(n-1) + fib_recursive(n-2);\n",
        "}\n",
        "\n",
        "// Iterative Fibonacci\n",
        "int fib_iterative(int n) {\n",
        "    if (n <= 1)\n",
        "        return n;\n",
        "    int prev = 0, curr = 1;\n",
        "    for (int i = 2; i <= n; ++i) {\n",
        "        int next = prev + curr;\n",
        "        prev = curr;\n",
        "        curr = next;\n",
        "    }\n",
        "    return curr;\n",
        "}\n",
        "\n",
        "// Generate primes using Sieve of Eratosthenes\n",
        "vector<int> generate_primes(int n) {\n",
        "    vector<bool> is_prime(n+1, true);\n",
        "    for (int p = 2; p * p <= n; ++p) {\n",
        "        if (is_prime[p]) {\n",
        "            for (int i = p * p; i <= n; i += p)\n",
        "                is_prime[i] = false;\n",
        "        }\n",
        "    }\n",
        "    vector<int> primes;\n",
        "    for (int p = 2; p <= n; ++p) {\n",
        "        if (is_prime[p])\n",
        "            primes.push_back(p);\n",
        "    }\n",
        "    return primes;\n",
        "}\n",
        "\n",
        "// Naive matrix multiplication\n",
        "void matrixMultiplyNaive(int N) {\n",
        "    vector<vector<int>> A(N, vector<int>(N, 1));\n",
        "    vector<vector<int>> B(N, vector<int>(N, 1));\n",
        "    vector<vector<int>> C(N, vector<int>(N, 0));\n",
        "\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            for (int k = 0; k < N; ++k) {\n",
        "                C[i][j] += A[i][k] * B[k][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Optimized matrix multiplication\n",
        "void matrixMultiplyOptimized(int N) {\n",
        "    vector<vector<int>> A(N, vector<int>(N, 1));\n",
        "    vector<vector<int>> B(N, vector<int>(N, 1));\n",
        "    vector<vector<int>> C(N, vector<int>(N, 0));\n",
        "\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int k = 0; k < N; ++k) {\n",
        "            int r = A[i][k];\n",
        "            for (int j = 0; j < N; ++j) {\n",
        "                C[i][j] += r * B[k][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    ProfilerStart(\"complex_program.prof\"); // Start profiling\n",
        "\n",
        "    // Measure execution time of recursive Fibonacci\n",
        "    int fib_n = 35; // Adjust for demo purposes (higher values take much longer)\n",
        "    auto start = chrono::high_resolution_clock::now();\n",
        "    int fib_rec_result = fib_recursive(fib_n);\n",
        "    auto end = chrono::high_resolution_clock::now();\n",
        "    auto duration_fib_rec = chrono::duration_cast<chrono::milliseconds>(end - start).count();\n",
        "    cout << \"Recursive Fibonacci of \" << fib_n << \" is \" << fib_rec_result << \" (Time: \" << duration_fib_rec << \" ms)\" << endl;\n",
        "\n",
        "    // Measure execution time of iterative Fibonacci\n",
        "    start = chrono::high_resolution_clock::now();\n",
        "    int fib_iter_result = fib_iterative(fib_n);\n",
        "    end = chrono::high_resolution_clock::now();\n",
        "    auto duration_fib_iter = chrono::duration_cast<chrono::milliseconds>(end - start).count();\n",
        "    cout << \"Iterative Fibonacci of \" << fib_n << \" is \" << fib_iter_result << \" (Time: \" << duration_fib_iter << \" ms)\" << endl;\n",
        "\n",
        "    // Generate primes\n",
        "    int prime_limit = 100000;\n",
        "    start = chrono::high_resolution_clock::now();\n",
        "    vector<int> primes = generate_primes(prime_limit);\n",
        "    end = chrono::high_resolution_clock::now();\n",
        "    auto duration_primes = chrono::duration_cast<chrono::milliseconds>(end - start).count();\n",
        "    cout << \"Generated \" << primes.size() << \" primes up to \" << prime_limit << \" (Time: \" << duration_primes << \" ms)\" << endl;\n",
        "\n",
        "    // Matrix multiplication\n",
        "    int N = 300;  // Adjusted matrix size for demonstration\n",
        "    start = chrono::high_resolution_clock::now();\n",
        "    matrixMultiplyNaive(N);\n",
        "    end = chrono::high_resolution_clock::now();\n",
        "    auto duration_matrix_naive = chrono::duration_cast<chrono::milliseconds>(end - start).count();\n",
        "    cout << \"Naive matrix multiplication time: \" << duration_matrix_naive << \" ms\" << endl;\n",
        "\n",
        "    start = chrono::high_resolution_clock::now();\n",
        "    matrixMultiplyOptimized(N);\n",
        "    end = chrono::high_resolution_clock::now();\n",
        "    auto duration_matrix_optimized = chrono::duration_cast<chrono::milliseconds>(end - start).count();\n",
        "    cout << \"Optimized matrix multiplication time: \" << duration_matrix_optimized << \" ms\" << endl;\n",
        "\n",
        "    ProfilerStop(); // Stop profiling\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Save the C++ code to a file\n",
        "with open(\"complex_program.cpp\", \"w\") as file:\n",
        "    file.write(cpp_code)\n",
        "\n",
        "# Compile the code with debug symbols\n",
        "!g++ -O2 -g complex_program.cpp -o complex_program -lprofiler\n",
        "\n",
        "# Run the compiled program\n",
        "!./complex_program\n",
        "\n",
        "# Generate an SVG profiling report\n",
        "!pprof --svg ./complex_program complex_program.prof > profiling_report.svg\n",
        "\n",
        "# Display the SVG report\n",
        "from IPython.display import SVG, display\n",
        "display(SVG(filename='profiling_report.svg'))\n",
        "\n",
        "# Generate and display line-by-line profiling report\n",
        "print(\"Line-by-Line Profiling Report:\")\n",
        "!pprof --lines --text ./complex_program complex_program.prof\n",
        "\n",
        "# Generate a Flame Graph\n",
        "# Generate a collapsed stack file\n",
        "!pprof --collapsed ./complex_program complex_program.prof > collapsed.txt\n",
        "\n",
        "# Install FlameGraph tools\n",
        "!git clone https://github.com/brendangregg/FlameGraph.git\n",
        "\n",
        "# Generate the flame graph SVG\n",
        "!./FlameGraph/flamegraph.pl collapsed.txt > flamegraph.svg\n",
        "\n",
        "# Display the flame graph\n",
        "display(SVG(filename='flamegraph.svg'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kkq8vMAwI7Wt",
        "outputId": "23980090-abf5-417c-d599-d3165e623c18"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recursive Fibonacci of 35 is 9227465 (Time: 29 ms)\n",
            "Iterative Fibonacci of 35 is 9227465 (Time: 0 ms)\n",
            "Generated 9592 primes up to 100000 (Time: 0 ms)\n",
            "Naive matrix multiplication time: 26 ms\n",
            "Optimized matrix multiplication time: 22 ms\n",
            "PROFILE: interrupts/evictions/bytes = 7/0/448\n",
            "Using local file ./complex_program.\n",
            "Using local file complex_program.prof.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100%\" height=\"100%\">\n<script type=\"text/ecmascript\"><![CDATA[\n// SVGPan\n// http://www.cyberz.org/blog/2009/12/08/svgpan-a-javascript-svg-panzoomdrag-library/\n// Local modification: if(true || ...) below to force panning, never moving.\n\n/**\n *  SVGPan library 1.2\n * ====================\n *\n * Given an unique existing element with id \"viewport\", including the\n * the library into any SVG adds the following capabilities:\n *\n *  - Mouse panning\n *  - Mouse zooming (using the wheel)\n *  - Object dargging\n *\n * Known issues:\n *\n *  - Zooming (while panning) on Safari has still some issues\n *\n * Releases:\n *\n * 1.2, Sat Mar 20 08:42:50 GMT 2010, Zeng Xiaohui\n *\tFixed a bug with browser mouse handler interaction\n *\n * 1.1, Wed Feb  3 17:39:33 GMT 2010, Zeng Xiaohui\n *\tUpdated the zoom code to support the mouse wheel on Safari/Chrome\n *\n * 1.0, Andrea Leofreddi\n *\tFirst release\n *\n * This code is licensed under the following BSD license:\n *\n * Copyright 2009-2010 Andrea Leofreddi <a.leofreddi@itcharm.com>. All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without modification, are\n * permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice, this list of\n *       conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above copyright notice, this list\n *       of conditions and the following disclaimer in the documentation and/or other materials\n *       provided with the distribution.\n *\n * THIS SOFTWARE IS PROVIDED BY Andrea Leofreddi ``AS IS'' AND ANY EXPRESS OR IMPLIED\n * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND\n * FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL Andrea Leofreddi OR\n * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\n * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\n * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n *\n * The views and conclusions contained in the software and documentation are those of the\n * authors and should not be interpreted as representing official policies, either expressed\n * or implied, of Andrea Leofreddi.\n */\n\nvar root = document.documentElement;\n\nvar state = 'none', stateTarget, stateOrigin, stateTf;\n\nsetupHandlers(root);\n\n/**\n * Register handlers\n */\nfunction setupHandlers(root){\n\tsetAttributes(root, {\n\t\t\"onmouseup\" : \"add(evt)\",\n\t\t\"onmousedown\" : \"handleMouseDown(evt)\",\n\t\t\"onmousemove\" : \"handleMouseMove(evt)\",\n\t\t\"onmouseup\" : \"handleMouseUp(evt)\",\n\t\t//\"onmouseout\" : \"handleMouseUp(evt)\", // Decomment this to stop the pan functionality when dragging out of the SVG element\n\t});\n\n\tif(navigator.userAgent.toLowerCase().indexOf('webkit') >= 0)\n\t\twindow.addEventListener('mousewheel', handleMouseWheel, false); // Chrome/Safari\n\telse\n\t\twindow.addEventListener('DOMMouseScroll', handleMouseWheel, false); // Others\n\n\tvar g = svgDoc.getElementById(\"svg\");\n\tg.width = \"100%\";\n\tg.height = \"100%\";\n}\n\n/**\n * Instance an SVGPoint object with given event coordinates.\n */\nfunction getEventPoint(evt) {\n\tvar p = root.createSVGPoint();\n\n\tp.x = evt.clientX;\n\tp.y = evt.clientY;\n\n\treturn p;\n}\n\n/**\n * Sets the current transform matrix of an element.\n */\nfunction setCTM(element, matrix) {\n\tvar s = \"matrix(\" + matrix.a + \",\" + matrix.b + \",\" + matrix.c + \",\" + matrix.d + \",\" + matrix.e + \",\" + matrix.f + \")\";\n\n\telement.setAttribute(\"transform\", s);\n}\n\n/**\n * Dumps a matrix to a string (useful for debug).\n */\nfunction dumpMatrix(matrix) {\n\tvar s = \"[ \" + matrix.a + \", \" + matrix.c + \", \" + matrix.e + \"\\n  \" + matrix.b + \", \" + matrix.d + \", \" + matrix.f + \"\\n  0, 0, 1 ]\";\n\n\treturn s;\n}\n\n/**\n * Sets attributes of an element.\n */\nfunction setAttributes(element, attributes){\n\tfor (i in attributes)\n\t\telement.setAttributeNS(null, i, attributes[i]);\n}\n\n/**\n * Handle mouse move event.\n */\nfunction handleMouseWheel(evt) {\n\tif(evt.preventDefault)\n\t\tevt.preventDefault();\n\n\tevt.returnValue = false;\n\n\tvar svgDoc = evt.target.ownerDocument;\n\n\tvar delta;\n\n\tif(evt.wheelDelta)\n\t\tdelta = evt.wheelDelta / 3600; // Chrome/Safari\n\telse\n\t\tdelta = evt.detail / -90; // Mozilla\n\n\tvar z = 1 + delta; // Zoom factor: 0.9/1.1\n\n\tvar g = svgDoc.getElementById(\"viewport\");\n\n\tvar p = getEventPoint(evt);\n\n\tp = p.matrixTransform(g.getCTM().inverse());\n\n\t// Compute new scale matrix in current mouse position\n\tvar k = root.createSVGMatrix().translate(p.x, p.y).scale(z).translate(-p.x, -p.y);\n\n        setCTM(g, g.getCTM().multiply(k));\n\n\tstateTf = stateTf.multiply(k.inverse());\n}\n\n/**\n * Handle mouse move event.\n */\nfunction handleMouseMove(evt) {\n\tif(evt.preventDefault)\n\t\tevt.preventDefault();\n\n\tevt.returnValue = false;\n\n\tvar svgDoc = evt.target.ownerDocument;\n\n\tvar g = svgDoc.getElementById(\"viewport\");\n\n\tif(state == 'pan') {\n\t\t// Pan mode\n\t\tvar p = getEventPoint(evt).matrixTransform(stateTf);\n\n\t\tsetCTM(g, stateTf.inverse().translate(p.x - stateOrigin.x, p.y - stateOrigin.y));\n\t} else if(state == 'move') {\n\t\t// Move mode\n\t\tvar p = getEventPoint(evt).matrixTransform(g.getCTM().inverse());\n\n\t\tsetCTM(stateTarget, root.createSVGMatrix().translate(p.x - stateOrigin.x, p.y - stateOrigin.y).multiply(g.getCTM().inverse()).multiply(stateTarget.getCTM()));\n\n\t\tstateOrigin = p;\n\t}\n}\n\n/**\n * Handle click event.\n */\nfunction handleMouseDown(evt) {\n\tif(evt.preventDefault)\n\t\tevt.preventDefault();\n\n\tevt.returnValue = false;\n\n\tvar svgDoc = evt.target.ownerDocument;\n\n\tvar g = svgDoc.getElementById(\"viewport\");\n\n\tif(true || evt.target.tagName == \"svg\") {\n\t\t// Pan mode\n\t\tstate = 'pan';\n\n\t\tstateTf = g.getCTM().inverse();\n\n\t\tstateOrigin = getEventPoint(evt).matrixTransform(stateTf);\n\t} else {\n\t\t// Move mode\n\t\tstate = 'move';\n\n\t\tstateTarget = evt.target;\n\n\t\tstateTf = g.getCTM().inverse();\n\n\t\tstateOrigin = getEventPoint(evt).matrixTransform(stateTf);\n\t}\n}\n\n/**\n * Handle mouse button release event.\n */\nfunction handleMouseUp(evt) {\n\tif(evt.preventDefault)\n\t\tevt.preventDefault();\n\n\tevt.returnValue = false;\n\n\tvar svgDoc = evt.target.ownerDocument;\n\n\tif(state == 'pan' || state == 'move') {\n\t\t// Quit pan mode\n\t\tstate = '';\n\t}\n}\n\n]]></script>\n<g id=\"viewport\" transform=\"translate(0,0)\">\n<g id=\"viewport\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 2268)\">\n<title>./complex_program; 7 samples</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-2268 1102,-2268 1102,4 -4,4\"/>\n<!-- Legend -->\n<g id=\"node1\" class=\"node\">\n<title>Legend</title>\n<text text-anchor=\"start\" x=\"8\" y=\"-2240.8\" font-family=\"Times,serif\" font-size=\"24.00\">./complex_program</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-2214.8\" font-family=\"Times,serif\" font-size=\"24.00\">Total samples: 7</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-2188.8\" font-family=\"Times,serif\" font-size=\"24.00\">Focusing on: 7</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-2162.8\" font-family=\"Times,serif\" font-size=\"24.00\">Dropped nodes with &lt;= 0 abs(samples)</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-2136.8\" font-family=\"Times,serif\" font-size=\"24.00\">Dropped edges with &lt;= 0 samples</text>\n</g>\n<!-- N1 -->\n<g id=\"node2\" class=\"node\">\n<title>N1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"485.5,-1989 396.5,-1989 396.5,-1954 485.5,-1954 485.5,-1989\"/>\n<text text-anchor=\"middle\" x=\"441\" y=\"-1978.6\" font-family=\"Times,serif\" font-size=\"8.00\">__libc_start_call_main</text>\n<text text-anchor=\"end\" x=\"477.5\" y=\"-1969.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"477.5\" y=\"-1960.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 7 (100.0%)</text>\n</g>\n<!-- N4 -->\n<g id=\"node5\" class=\"node\">\n<title>N4</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"472,-1903 410,-1903 410,-1868 472,-1868 472,-1903\"/>\n<text text-anchor=\"middle\" x=\"441\" y=\"-1892.6\" font-family=\"Times,serif\" font-size=\"8.00\">main</text>\n<text text-anchor=\"end\" x=\"464\" y=\"-1883.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"464\" y=\"-1874.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 7 (100.0%)</text>\n</g>\n<!-- N1&#45;&gt;N4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>N1-&gt;N4</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"2\" d=\"M441,-1953.9C441,-1942.28 441,-1926.51 441,-1913.14\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"2\" points=\"444.5,-1913.06 441,-1903.06 437.5,-1913.06 444.5,-1913.06\"/>\n<text text-anchor=\"middle\" x=\"444.5\" y=\"-1924.8\" font-family=\"Times,serif\" font-size=\"14.00\">7</text>\n</g>\n<!-- N2 -->\n<g id=\"node3\" class=\"node\">\n<title>N2</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"487,-2075 395,-2075 395,-2040 487,-2040 487,-2075\"/>\n<text text-anchor=\"middle\" x=\"441\" y=\"-2064.6\" font-family=\"Times,serif\" font-size=\"8.00\">__libc_start_main_impl</text>\n<text text-anchor=\"end\" x=\"479\" y=\"-2055.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"479\" y=\"-2046.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 7 (100.0%)</text>\n</g>\n<!-- N2&#45;&gt;N1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>N2-&gt;N1</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"2\" d=\"M441,-2039.9C441,-2028.28 441,-2012.51 441,-1999.14\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"2\" points=\"444.5,-1999.06 441,-1989.06 437.5,-1999.06 444.5,-1999.06\"/>\n<text text-anchor=\"middle\" x=\"444.5\" y=\"-2010.8\" font-family=\"Times,serif\" font-size=\"14.00\">7</text>\n</g>\n<!-- N3 -->\n<g id=\"node4\" class=\"node\">\n<title>N3</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"472,-2212.5 410,-2212.5 410,-2177.5 472,-2177.5 472,-2212.5\"/>\n<text text-anchor=\"middle\" x=\"441\" y=\"-2202.1\" font-family=\"Times,serif\" font-size=\"8.00\">_start</text>\n<text text-anchor=\"end\" x=\"464\" y=\"-2193.1\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"464\" y=\"-2184.1\" font-family=\"Times,serif\" font-size=\"8.00\">of 7 (100.0%)</text>\n</g>\n<!-- N3&#45;&gt;N2 -->\n<g id=\"edge3\" class=\"edge\">\n<title>N3-&gt;N2</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"2\" d=\"M441,-2177.39C441,-2154.43 441,-2112.74 441,-2085.33\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"2\" points=\"444.5,-2085.25 441,-2075.25 437.5,-2085.25 444.5,-2085.25\"/>\n<text text-anchor=\"middle\" x=\"444.5\" y=\"-2096.8\" font-family=\"Times,serif\" font-size=\"14.00\">7</text>\n</g>\n<!-- N5 -->\n<g id=\"node6\" class=\"node\">\n<title>N5</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"526,-1817 214,-1817 214,-1695 526,-1695 526,-1817\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1785.24\" font-family=\"Times,serif\" font-size=\"34.70\">matrixMultiplyNaive</text>\n<text text-anchor=\"end\" x=\"518\" y=\"-1747.24\" font-family=\"Times,serif\" font-size=\"34.70\">2 (28.6%)</text>\n<text text-anchor=\"end\" x=\"518\" y=\"-1709.24\" font-family=\"Times,serif\" font-size=\"34.70\">of 3 (42.9%)</text>\n</g>\n<!-- N4&#45;&gt;N5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>N4-&gt;N5</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"2\" d=\"M431.72,-1867.83C425.65,-1856.94 417.28,-1841.91 408.66,-1826.43\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"2\" points=\"411.49,-1824.32 403.57,-1817.29 405.38,-1827.73 411.49,-1824.32\"/>\n<text text-anchor=\"middle\" x=\"424.5\" y=\"-1838.8\" font-family=\"Times,serif\" font-size=\"14.00\">3</text>\n</g>\n<!-- N6 -->\n<g id=\"node7\" class=\"node\">\n<title>N6</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"703.5,-1805 544.5,-1805 544.5,-1707 703.5,-1707 703.5,-1805\"/>\n<text text-anchor=\"middle\" x=\"624\" y=\"-1779.48\" font-family=\"Times,serif\" font-size=\"26.90\">fib_recursive</text>\n<text text-anchor=\"end\" x=\"695.5\" y=\"-1749.48\" font-family=\"Times,serif\" font-size=\"26.90\">1 (14.3%)</text>\n<text text-anchor=\"end\" x=\"695.5\" y=\"-1719.48\" font-family=\"Times,serif\" font-size=\"26.90\">of 2 (28.6%)</text>\n</g>\n<!-- N4&#45;&gt;N6 -->\n<g id=\"edge7\" class=\"edge\">\n<title>N4-&gt;N6</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.71\" d=\"M464.92,-1867.83C485.82,-1853.27 517.35,-1831.3 546.84,-1810.76\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.71\" points=\"548.89,-1813.6 555.09,-1805.01 544.89,-1807.85 548.89,-1813.6\"/>\n<text text-anchor=\"middle\" x=\"513.5\" y=\"-1838.8\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n</g>\n<!-- N8 -->\n<g id=\"node9\" class=\"node\">\n<title>N8</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1098,-1798 722,-1798 722,-1714 1098,-1714 1098,-1798\"/>\n<text text-anchor=\"middle\" x=\"910\" y=\"-1766.24\" font-family=\"Times,serif\" font-size=\"34.70\">matrixMultiplyOptimized</text>\n<text text-anchor=\"end\" x=\"1090\" y=\"-1728.24\" font-family=\"Times,serif\" font-size=\"34.70\">2 (28.6%)</text>\n</g>\n<!-- N4&#45;&gt;N8 -->\n<g id=\"edge9\" class=\"edge\">\n<title>N4-&gt;N8</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.71\" d=\"M472.14,-1877.33C522.83,-1865.54 626.24,-1840.96 713,-1817 731.12,-1812 750.11,-1806.52 768.85,-1800.97\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.71\" points=\"770.03,-1804.27 778.61,-1798.06 768.03,-1797.56 770.03,-1804.27\"/>\n<text text-anchor=\"middle\" x=\"641.5\" y=\"-1838.8\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n</g>\n<!-- N22 -->\n<g id=\"node23\" class=\"node\">\n<title>N22</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"399,-1606.5 341,-1606.5 341,-1553.5 399,-1553.5 399,-1606.5\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1596.1\" font-family=\"Times,serif\" font-size=\"8.00\">std</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1587.1\" font-family=\"Times,serif\" font-size=\"8.00\">vector</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1578.1\" font-family=\"Times,serif\" font-size=\"8.00\">vector</text>\n<text text-anchor=\"end\" x=\"391\" y=\"-1569.1\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"391\" y=\"-1560.1\" font-family=\"Times,serif\" font-size=\"8.00\">of 1 (14.3%)</text>\n</g>\n<!-- N5&#45;&gt;N22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>N5-&gt;N22</title>\n<path fill=\"none\" stroke=\"black\" d=\"M370,-1694.63C370,-1668.7 370,-1639.28 370,-1616.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.5,-1616.8 370,-1606.8 366.5,-1616.8 373.5,-1616.8\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-1665.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- N7 -->\n<g id=\"node8\" class=\"node\">\n<title>N7</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"703.5,-1644 544.5,-1644 544.5,-1516 703.5,-1516 703.5,-1644\"/>\n<text text-anchor=\"middle\" x=\"624\" y=\"-1618.48\" font-family=\"Times,serif\" font-size=\"26.90\">fib_recursive</text>\n<text text-anchor=\"middle\" x=\"624\" y=\"-1588.48\" font-family=\"Times,serif\" font-size=\"26.90\">(inline)</text>\n<text text-anchor=\"end\" x=\"695.5\" y=\"-1558.48\" font-family=\"Times,serif\" font-size=\"26.90\">1 (14.3%)</text>\n<text text-anchor=\"end\" x=\"695.5\" y=\"-1528.48\" font-family=\"Times,serif\" font-size=\"26.90\">of 2 (28.6%)</text>\n</g>\n<!-- N6&#45;&gt;N7 -->\n<g id=\"edge6\" class=\"edge\">\n<title>N6-&gt;N7</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"2\" stroke-dasharray=\"5,2\" d=\"M624,-1706.99C624,-1690.76 624,-1672.25 624,-1654.51\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"2\" points=\"627.5,-1654.17 624,-1644.17 620.5,-1654.17 627.5,-1654.17\"/>\n<text text-anchor=\"middle\" x=\"627.5\" y=\"-1665.8\" font-family=\"Times,serif\" font-size=\"14.00\">3</text>\n</g>\n<!-- N7&#45;&gt;N6 -->\n<g id=\"edge8\" class=\"edge\">\n<title>N7-&gt;N6</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.71\" d=\"M631.69,-1644.22C632.32,-1655.14 632.54,-1666.39 632,-1677 631.68,-1683.33 631.2,-1689.95 630.65,-1696.53\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.71\" points=\"627.14,-1696.52 629.72,-1706.79 634.11,-1697.15 627.14,-1696.52\"/>\n<text text-anchor=\"middle\" x=\"635.5\" y=\"-1665.8\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n</g>\n<!-- N7&#45;&gt;N7 -->\n<g id=\"edge1\" class=\"edge\">\n<title>N7-&gt;N7</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"2\" stroke-dasharray=\"5,2\" d=\"M703.57,-1594.64C714.33,-1592.18 721.5,-1587.3 721.5,-1580 721.5,-1575.21 718.41,-1571.46 713.25,-1568.75\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"2\" points=\"714.17,-1565.36 703.57,-1565.36 711.85,-1571.97 714.17,-1565.36\"/>\n<text text-anchor=\"middle\" x=\"728.5\" y=\"-1576.3\" font-family=\"Times,serif\" font-size=\"14.00\">15</text>\n</g>\n<!-- N9 -->\n<g id=\"node10\" class=\"node\">\n<title>N9</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"411,-154 329,-154 329,-119 411,-119 411,-154\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-143.6\" font-family=\"Times,serif\" font-size=\"8.00\">__GI___libc_malloc</text>\n<text text-anchor=\"end\" x=\"403\" y=\"-134.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"403\" y=\"-125.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 1 (14.3%)</text>\n</g>\n<!-- N11 -->\n<g id=\"node12\" class=\"node\">\n<title>N11</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"443,-68 297,-68 297,0 443,0 443,-68\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-42.48\" font-family=\"Times,serif\" font-size=\"26.90\">_int_malloc</text>\n<text text-anchor=\"end\" x=\"435\" y=\"-12.48\" font-family=\"Times,serif\" font-size=\"26.90\">1 (14.3%)</text>\n</g>\n<!-- N9&#45;&gt;N11 -->\n<g id=\"edge20\" class=\"edge\">\n<title>N9-&gt;N11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M370,-118.9C370,-107.87 370,-92.82 370,-78.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.5,-78.3 370,-68.3 366.5,-78.3 373.5,-78.3\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-89.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- N10 -->\n<g id=\"node11\" class=\"node\">\n<title>N10</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"401,-362 339,-362 339,-300 401,-300 401,-362\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-351.6\" font-family=\"Times,serif\" font-size=\"8.00\">__gnu_cxx</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-342.6\" font-family=\"Times,serif\" font-size=\"8.00\">new_allocator</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-333.6\" font-family=\"Times,serif\" font-size=\"8.00\">allocate</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-324.6\" font-family=\"Times,serif\" font-size=\"8.00\">(inline)</text>\n<text text-anchor=\"end\" x=\"393\" y=\"-315.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"393\" y=\"-306.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 1 (14.3%)</text>\n</g>\n<!-- N12 -->\n<g id=\"node13\" class=\"node\">\n<title>N12</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"417.5,-249 322.5,-249 322.5,-205 417.5,-205 417.5,-249\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-238.6\" font-family=\"Times,serif\" font-size=\"8.00\">operator</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-229.6\" font-family=\"Times,serif\" font-size=\"8.00\">new@@GLIBCXX_3.4</text>\n<text text-anchor=\"end\" x=\"409.5\" y=\"-220.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"409.5\" y=\"-211.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 1 (14.3%)</text>\n</g>\n<!-- N10&#45;&gt;N12 -->\n<g id=\"edge14\" class=\"edge\">\n<title>N10-&gt;N12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M370,-299.95C370,-287.19 370,-272.3 370,-259.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.5,-259.11 370,-249.11 366.5,-259.11 373.5,-259.11\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-270.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- N12&#45;&gt;N9 -->\n<g id=\"edge13\" class=\"edge\">\n<title>N12-&gt;N9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M370,-204.58C370,-192.43 370,-177.12 370,-164.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.5,-164.02 370,-154.02 366.5,-164.02 373.5,-164.02\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-175.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- N13 -->\n<g id=\"node14\" class=\"node\">\n<title>N13</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"399,-1031 341,-1031 341,-978 399,-978 399,-1031\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1020.6\" font-family=\"Times,serif\" font-size=\"8.00\">std</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1011.6\" font-family=\"Times,serif\" font-size=\"8.00\">_Construct</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1002.6\" font-family=\"Times,serif\" font-size=\"8.00\">(inline)</text>\n<text text-anchor=\"end\" x=\"391\" y=\"-993.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"391\" y=\"-984.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 1 (14.3%)</text>\n</g>\n<!-- N23 -->\n<g id=\"node24\" class=\"node\">\n<title>N23</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"399,-927 341,-927 341,-865 399,-865 399,-927\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-916.6\" font-family=\"Times,serif\" font-size=\"8.00\">std</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-907.6\" font-family=\"Times,serif\" font-size=\"8.00\">vector</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-898.6\" font-family=\"Times,serif\" font-size=\"8.00\">vector</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-889.6\" font-family=\"Times,serif\" font-size=\"8.00\">(inline)</text>\n<text text-anchor=\"end\" x=\"391\" y=\"-880.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"391\" y=\"-871.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 1 (14.3%)</text>\n</g>\n<!-- N13&#45;&gt;N23 -->\n<g id=\"edge15\" class=\"edge\">\n<title>N13-&gt;N23</title>\n<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M370,-977.99C370,-965.83 370,-950.99 370,-937.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.5,-937.22 370,-927.22 366.5,-937.22 373.5,-937.22\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-948.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- N14 -->\n<g id=\"node15\" class=\"node\">\n<title>N14</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"400,-588 340,-588 340,-526 400,-526 400,-588\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-577.6\" font-family=\"Times,serif\" font-size=\"8.00\">std</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-568.6\" font-family=\"Times,serif\" font-size=\"8.00\">_Vector_base</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-559.6\" font-family=\"Times,serif\" font-size=\"8.00\">_M_allocate</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-550.6\" font-family=\"Times,serif\" font-size=\"8.00\">(inline)</text>\n<text text-anchor=\"end\" x=\"392\" y=\"-541.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"392\" y=\"-532.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 1 (14.3%)</text>\n</g>\n<!-- N19 -->\n<g id=\"node20\" class=\"node\">\n<title>N19</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"402.5,-475 337.5,-475 337.5,-413 402.5,-413 402.5,-475\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-464.6\" font-family=\"Times,serif\" font-size=\"8.00\">std</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-455.6\" font-family=\"Times,serif\" font-size=\"8.00\">allocator_traits</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-446.6\" font-family=\"Times,serif\" font-size=\"8.00\">allocate</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-437.6\" font-family=\"Times,serif\" font-size=\"8.00\">(inline)</text>\n<text text-anchor=\"end\" x=\"394.5\" y=\"-428.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"394.5\" y=\"-419.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 1 (14.3%)</text>\n</g>\n<!-- N14&#45;&gt;N19 -->\n<g id=\"edge12\" class=\"edge\">\n<title>N14-&gt;N19</title>\n<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M370,-525.96C370,-513.38 370,-498.56 370,-485.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.5,-485.06 370,-475.06 366.5,-485.06 373.5,-485.06\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-496.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- N15 -->\n<g id=\"node16\" class=\"node\">\n<title>N15</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"409,-701 331,-701 331,-639 409,-639 409,-701\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-690.6\" font-family=\"Times,serif\" font-size=\"8.00\">std</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-681.6\" font-family=\"Times,serif\" font-size=\"8.00\">_Vector_base</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-672.6\" font-family=\"Times,serif\" font-size=\"8.00\">_M_create_storage</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-663.6\" font-family=\"Times,serif\" font-size=\"8.00\">(inline)</text>\n<text text-anchor=\"end\" x=\"401\" y=\"-654.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"401\" y=\"-645.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 1 (14.3%)</text>\n</g>\n<!-- N15&#45;&gt;N14 -->\n<g id=\"edge19\" class=\"edge\">\n<title>N15-&gt;N14</title>\n<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M370,-638.96C370,-626.38 370,-611.56 370,-598.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.5,-598.06 370,-588.06 366.5,-598.06 373.5,-598.06\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-609.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- N16 -->\n<g id=\"node17\" class=\"node\">\n<title>N16</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"400,-814 340,-814 340,-752 400,-752 400,-814\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-803.6\" font-family=\"Times,serif\" font-size=\"8.00\">std</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-794.6\" font-family=\"Times,serif\" font-size=\"8.00\">_Vector_base</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-785.6\" font-family=\"Times,serif\" font-size=\"8.00\">_Vector_base</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-776.6\" font-family=\"Times,serif\" font-size=\"8.00\">(inline)</text>\n<text text-anchor=\"end\" x=\"392\" y=\"-767.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"392\" y=\"-758.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 1 (14.3%)</text>\n</g>\n<!-- N16&#45;&gt;N15 -->\n<g id=\"edge16\" class=\"edge\">\n<title>N16-&gt;N15</title>\n<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M370,-751.96C370,-739.38 370,-724.56 370,-711.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.5,-711.06 370,-701.06 366.5,-711.06 373.5,-711.06\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-722.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- N17 -->\n<g id=\"node18\" class=\"node\">\n<title>N17</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"412.5,-1144 327.5,-1144 327.5,-1082 412.5,-1082 412.5,-1144\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1133.6\" font-family=\"Times,serif\" font-size=\"8.00\">std</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1124.6\" font-family=\"Times,serif\" font-size=\"8.00\">__uninitialized_fill_n</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1115.6\" font-family=\"Times,serif\" font-size=\"8.00\">__uninit_fill_n</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1106.6\" font-family=\"Times,serif\" font-size=\"8.00\">(inline)</text>\n<text text-anchor=\"end\" x=\"404.5\" y=\"-1097.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"404.5\" y=\"-1088.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 1 (14.3%)</text>\n</g>\n<!-- N17&#45;&gt;N13 -->\n<g id=\"edge11\" class=\"edge\">\n<title>N17-&gt;N13</title>\n<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M370,-1081.77C370,-1069.15 370,-1054.4 370,-1041.25\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.5,-1041.12 370,-1031.12 366.5,-1041.12 373.5,-1041.12\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-1052.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- N18 -->\n<g id=\"node19\" class=\"node\">\n<title>N18</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"416,-1352 324,-1352 324,-1299 416,-1299 416,-1352\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1341.6\" font-family=\"Times,serif\" font-size=\"8.00\">std</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1332.6\" font-family=\"Times,serif\" font-size=\"8.00\">__uninitialized_fill_n_a</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1323.6\" font-family=\"Times,serif\" font-size=\"8.00\">(inline)</text>\n<text text-anchor=\"end\" x=\"408\" y=\"-1314.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"408\" y=\"-1305.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 1 (14.3%)</text>\n</g>\n<!-- N20 -->\n<g id=\"node21\" class=\"node\">\n<title>N20</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"408.5,-1248 331.5,-1248 331.5,-1195 408.5,-1195 408.5,-1248\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1237.6\" font-family=\"Times,serif\" font-size=\"8.00\">std</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1228.6\" font-family=\"Times,serif\" font-size=\"8.00\">uninitialized_fill_n</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1219.6\" font-family=\"Times,serif\" font-size=\"8.00\">(inline)</text>\n<text text-anchor=\"end\" x=\"400.5\" y=\"-1210.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"400.5\" y=\"-1201.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 1 (14.3%)</text>\n</g>\n<!-- N18&#45;&gt;N20 -->\n<g id=\"edge18\" class=\"edge\">\n<title>N18-&gt;N20</title>\n<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M370,-1298.76C370,-1286.56 370,-1271.78 370,-1258.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.5,-1258.23 370,-1248.23 366.5,-1258.23 373.5,-1258.23\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-1269.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- N19&#45;&gt;N10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>N19-&gt;N10</title>\n<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M370,-412.96C370,-400.38 370,-385.56 370,-372.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.5,-372.06 370,-362.06 366.5,-372.06 373.5,-372.06\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-383.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- N20&#45;&gt;N17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>N20-&gt;N17</title>\n<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M370,-1194.99C370,-1182.83 370,-1167.99 370,-1154.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.5,-1154.22 370,-1144.22 366.5,-1154.22 373.5,-1154.22\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-1165.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- N21 -->\n<g id=\"node22\" class=\"node\">\n<title>N21</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"406.5,-1465 333.5,-1465 333.5,-1403 406.5,-1403 406.5,-1465\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1454.6\" font-family=\"Times,serif\" font-size=\"8.00\">std</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1445.6\" font-family=\"Times,serif\" font-size=\"8.00\">vector</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1436.6\" font-family=\"Times,serif\" font-size=\"8.00\">_M_fill_initialize</text>\n<text text-anchor=\"middle\" x=\"370\" y=\"-1427.6\" font-family=\"Times,serif\" font-size=\"8.00\">(inline)</text>\n<text text-anchor=\"end\" x=\"398.5\" y=\"-1418.6\" font-family=\"Times,serif\" font-size=\"8.00\">0 (0.0%)</text>\n<text text-anchor=\"end\" x=\"398.5\" y=\"-1409.6\" font-family=\"Times,serif\" font-size=\"8.00\">of 1 (14.3%)</text>\n</g>\n<!-- N21&#45;&gt;N18 -->\n<g id=\"edge23\" class=\"edge\">\n<title>N21-&gt;N18</title>\n<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M370,-1402.77C370,-1390.15 370,-1375.4 370,-1362.25\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.5,-1362.12 370,-1352.12 366.5,-1362.12 373.5,-1362.12\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-1373.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- N22&#45;&gt;N21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>N22-&gt;N21</title>\n<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M370,-1553.26C370,-1531.6 370,-1500.25 370,-1475.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.5,-1475 370,-1465 366.5,-1475 373.5,-1475\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-1486.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- N23&#45;&gt;N16 -->\n<g id=\"edge24\" class=\"edge\">\n<title>N23-&gt;N16</title>\n<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M370,-864.96C370,-852.38 370,-837.56 370,-824.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.5,-824.06 370,-814.06 366.5,-824.06 373.5,-824.06\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-835.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n</g>\n</g></svg>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Line-by-Line Profiling Report:\n",
            "Using local file ./complex_program.\n",
            "Using local file complex_program.prof.\n",
            "Total: 7 samples\n",
            "       2  28.6%  28.6%        2  28.6% matrixMultiplyNaive /content/complex_program.cpp:55\n",
            "       1  14.3%  42.9%        1  14.3% _int_malloc ./malloc/malloc.c:4382\n",
            "       1  14.3%  57.1%        1  14.3% fib_recursive (inline) /content/complex_program.cpp:11\n",
            "       1  14.3%  71.4%        1  14.3% fib_recursive /content/complex_program.cpp:15\n",
            "       1  14.3%  85.7%        1  14.3% matrixMultiplyOptimized /content/complex_program.cpp:71\n",
            "       1  14.3% 100.0%        1  14.3% matrixMultiplyOptimized /content/complex_program.cpp:72\n",
            "       0   0.0% 100.0%        1  14.3% __GI___libc_malloc ./malloc/malloc.c:3321\n",
            "       0   0.0% 100.0%        1  14.3% __gnu_cxx::new_allocator::allocate (inline) /usr/include/c++/11/ext/new_allocator.h:127\n",
            "       0   0.0% 100.0%        7 100.0% __libc_start_call_main ./csu/../sysdeps/nptl/libc_start_call_main.h:58\n",
            "       0   0.0% 100.0%        7 100.0% __libc_start_main_impl ./csu/../csu/libc-start.c:392\n",
            "       0   0.0% 100.0%        7 100.0% _start ??:0\n",
            "       0   0.0% 100.0%        2  28.6% fib_recursive (inline) /content/complex_program.cpp:14\n",
            "       0   0.0% 100.0%        2  28.6% fib_recursive /content/complex_program.cpp:14\n",
            "       0   0.0% 100.0%        3  42.9% main /content/complex_program.cpp:107\n",
            "       0   0.0% 100.0%        2  28.6% main /content/complex_program.cpp:113\n",
            "       0   0.0% 100.0%        2  28.6% main /content/complex_program.cpp:84\n",
            "       0   0.0% 100.0%        1  14.3% matrixMultiplyNaive /content/complex_program.cpp:50\n",
            "       0   0.0% 100.0%        1  14.3% operator new@@GLIBCXX_3.4 ??:0\n",
            "       0   0.0% 100.0%        1  14.3% std::_Construct (inline) /usr/include/c++/11/bits/stl_construct.h:119\n",
            "       0   0.0% 100.0%        1  14.3% std::_Vector_base::_M_allocate (inline) /usr/include/c++/11/bits/stl_vector.h:346\n",
            "       0   0.0% 100.0%        1  14.3% std::_Vector_base::_M_create_storage (inline) /usr/include/c++/11/bits/stl_vector.h:361\n",
            "       0   0.0% 100.0%        1  14.3% std::_Vector_base::_Vector_base (inline) /usr/include/c++/11/bits/stl_vector.h:305\n",
            "       0   0.0% 100.0%        1  14.3% std::__uninitialized_fill_n::__uninit_fill_n (inline) /usr/include/c++/11/bits/stl_uninitialized.h:237\n",
            "       0   0.0% 100.0%        1  14.3% std::__uninitialized_fill_n_a (inline) /usr/include/c++/11/bits/stl_uninitialized.h:410\n",
            "       0   0.0% 100.0%        1  14.3% std::allocator_traits::allocate (inline) /usr/include/c++/11/bits/alloc_traits.h:464\n",
            "       0   0.0% 100.0%        1  14.3% std::uninitialized_fill_n (inline) /usr/include/c++/11/bits/stl_uninitialized.h:297\n",
            "       0   0.0% 100.0%        1  14.3% std::vector::_M_fill_initialize (inline) /usr/include/c++/11/bits/stl_vector.h:1596\n",
            "       0   0.0% 100.0%        1  14.3% std::vector::vector (inline) /usr/include/c++/11/bits/stl_vector.h:555\n",
            "       0   0.0% 100.0%        1  14.3% std::vector::vector /usr/include/c++/11/bits/stl_vector.h:525\n",
            "Using local file ./complex_program.\n",
            "Using local file complex_program.prof.\n",
            "Cloning into 'FlameGraph'...\n",
            "remote: Enumerating objects: 1285, done.\u001b[K\n",
            "remote: Counting objects: 100% (708/708), done.\u001b[K\n",
            "remote: Compressing objects: 100% (148/148), done.\u001b[K\n",
            "remote: Total 1285 (delta 584), reused 574 (delta 560), pack-reused 577 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1285/1285), 1.92 MiB | 9.58 MiB/s, done.\n",
            "Resolving deltas: 100% (761/761), done.\n",
            "Stack count is low (7). Did something go wrong?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.1\" width=\"1200\" height=\"406\" onload=\"init(evt)\" viewBox=\"0 0 1200 406\">\n<!-- Flame graph stack visualization. See https://github.com/brendangregg/FlameGraph for latest version, and http://www.brendangregg.com/flamegraphs.html for examples. -->\n<!-- NOTES:  -->\n<defs>\n\t<linearGradient id=\"background\" y1=\"0\" y2=\"1\" x1=\"0\" x2=\"0\">\n\t\t<stop stop-color=\"#eeeeee\" offset=\"5%\"/>\n\t\t<stop stop-color=\"#eeeeb0\" offset=\"95%\"/>\n\t</linearGradient>\n</defs>\n<style type=\"text/css\">\n\ttext { font-family:Verdana; font-size:12px; fill:rgb(0,0,0); }\n\t#search, #ignorecase { opacity:0.1; cursor:pointer; }\n\t#search:hover, #search.show, #ignorecase:hover, #ignorecase.show { opacity:1; }\n\t#subtitle { text-anchor:middle; font-color:rgb(160,160,160); }\n\t#title { text-anchor:middle; font-size:17px}\n\t#unzoom { cursor:pointer; }\n\t#frames &gt; *:hover { stroke:black; stroke-width:0.5; cursor:pointer; }\n\t.hide { display:none; }\n\t.parent { opacity:0.5; }\n</style>\n<script type=\"text/ecmascript\">\n<![CDATA[\n\t\"use strict\";\n\tvar details, searchbtn, unzoombtn, matchedtxt, svg, searching, currentSearchTerm, ignorecase, ignorecaseBtn;\n\tfunction init(evt) {\n\t\tdetails = document.getElementById(\"details\").firstChild;\n\t\tsearchbtn = document.getElementById(\"search\");\n\t\tignorecaseBtn = document.getElementById(\"ignorecase\");\n\t\tunzoombtn = document.getElementById(\"unzoom\");\n\t\tmatchedtxt = document.getElementById(\"matched\");\n\t\tsvg = document.getElementsByTagName(\"svg\")[0];\n\t\tsearching = 0;\n\t\tcurrentSearchTerm = null;\n\n\t\t// use GET parameters to restore a flamegraphs state.\n\t\tvar params = get_params();\n\t\tif (params.x && params.y)\n\t\t\tzoom(find_group(document.querySelector('[x=\"' + params.x + '\"][y=\"' + params.y + '\"]')));\n                if (params.s) search(params.s);\n\t}\n\n\t// event listeners\n\twindow.addEventListener(\"click\", function(e) {\n\t\tvar target = find_group(e.target);\n\t\tif (target) {\n\t\t\tif (target.nodeName == \"a\") {\n\t\t\t\tif (e.ctrlKey === false) return;\n\t\t\t\te.preventDefault();\n\t\t\t}\n\t\t\tif (target.classList.contains(\"parent\")) unzoom(true);\n\t\t\tzoom(target);\n\t\t\tif (!document.querySelector('.parent')) {\n\t\t\t\t// we have basically done a clearzoom so clear the url\n\t\t\t\tvar params = get_params();\n\t\t\t\tif (params.x) delete params.x;\n\t\t\t\tif (params.y) delete params.y;\n\t\t\t\thistory.replaceState(null, null, parse_params(params));\n\t\t\t\tunzoombtn.classList.add(\"hide\");\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// set parameters for zoom state\n\t\t\tvar el = target.querySelector(\"rect\");\n\t\t\tif (el && el.attributes && el.attributes.y && el.attributes._orig_x) {\n\t\t\t\tvar params = get_params()\n\t\t\t\tparams.x = el.attributes._orig_x.value;\n\t\t\t\tparams.y = el.attributes.y.value;\n\t\t\t\thistory.replaceState(null, null, parse_params(params));\n\t\t\t}\n\t\t}\n\t\telse if (e.target.id == \"unzoom\") clearzoom();\n\t\telse if (e.target.id == \"search\") search_prompt();\n\t\telse if (e.target.id == \"ignorecase\") toggle_ignorecase();\n\t}, false)\n\n\t// mouse-over for info\n\t// show\n\twindow.addEventListener(\"mouseover\", function(e) {\n\t\tvar target = find_group(e.target);\n\t\tif (target) details.nodeValue = \"Function: \" + g_to_text(target);\n\t}, false)\n\n\t// clear\n\twindow.addEventListener(\"mouseout\", function(e) {\n\t\tvar target = find_group(e.target);\n\t\tif (target) details.nodeValue = ' ';\n\t}, false)\n\n\t// ctrl-F for search\n\t// ctrl-I to toggle case-sensitive search\n\twindow.addEventListener(\"keydown\",function (e) {\n\t\tif (e.keyCode === 114 || (e.ctrlKey && e.keyCode === 70)) {\n\t\t\te.preventDefault();\n\t\t\tsearch_prompt();\n\t\t}\n\t\telse if (e.ctrlKey && e.keyCode === 73) {\n\t\t\te.preventDefault();\n\t\t\ttoggle_ignorecase();\n\t\t}\n\t}, false)\n\n\t// functions\n\tfunction get_params() {\n\t\tvar params = {};\n\t\tvar paramsarr = window.location.search.substr(1).split('&');\n\t\tfor (var i = 0; i < paramsarr.length; ++i) {\n\t\t\tvar tmp = paramsarr[i].split(\"=\");\n\t\t\tif (!tmp[0] || !tmp[1]) continue;\n\t\t\tparams[tmp[0]]  = decodeURIComponent(tmp[1]);\n\t\t}\n\t\treturn params;\n\t}\n\tfunction parse_params(params) {\n\t\tvar uri = \"?\";\n\t\tfor (var key in params) {\n\t\t\turi += key + '=' + encodeURIComponent(params[key]) + '&';\n\t\t}\n\t\tif (uri.slice(-1) == \"&\")\n\t\t\turi = uri.substring(0, uri.length - 1);\n\t\tif (uri == '?')\n\t\t\turi = window.location.href.split('?')[0];\n\t\treturn uri;\n\t}\n\tfunction find_child(node, selector) {\n\t\tvar children = node.querySelectorAll(selector);\n\t\tif (children.length) return children[0];\n\t}\n\tfunction find_group(node) {\n\t\tvar parent = node.parentElement;\n\t\tif (!parent) return;\n\t\tif (parent.id == \"frames\") return node;\n\t\treturn find_group(parent);\n\t}\n\tfunction orig_save(e, attr, val) {\n\t\tif (e.attributes[\"_orig_\" + attr] != undefined) return;\n\t\tif (e.attributes[attr] == undefined) return;\n\t\tif (val == undefined) val = e.attributes[attr].value;\n\t\te.setAttribute(\"_orig_\" + attr, val);\n\t}\n\tfunction orig_load(e, attr) {\n\t\tif (e.attributes[\"_orig_\"+attr] == undefined) return;\n\t\te.attributes[attr].value = e.attributes[\"_orig_\" + attr].value;\n\t\te.removeAttribute(\"_orig_\"+attr);\n\t}\n\tfunction g_to_text(e) {\n\t\tvar text = find_child(e, \"title\").firstChild.nodeValue;\n\t\treturn (text)\n\t}\n\tfunction g_to_func(e) {\n\t\tvar func = g_to_text(e);\n\t\t// if there's any manipulation we want to do to the function\n\t\t// name before it's searched, do it here before returning.\n\t\treturn (func);\n\t}\n\tfunction update_text(e) {\n\t\tvar r = find_child(e, \"rect\");\n\t\tvar t = find_child(e, \"text\");\n\t\tvar w = parseFloat(r.attributes.width.value) -3;\n\t\tvar txt = find_child(e, \"title\").textContent.replace(/\\([^(]*\\)$/,\"\");\n\t\tt.attributes.x.value = parseFloat(r.attributes.x.value) + 3;\n\n\t\t// Smaller than this size won't fit anything\n\t\tif (w < 2 * 12 * 0.59) {\n\t\t\tt.textContent = \"\";\n\t\t\treturn;\n\t\t}\n\n\t\tt.textContent = txt;\n\t\tvar sl = t.getSubStringLength(0, txt.length);\n\t\t// check if only whitespace or if we can fit the entire string into width w\n\t\tif (/^ *$/.test(txt) || sl < w)\n\t\t\treturn;\n\n\t\t// this isn't perfect, but gives a good starting point\n\t\t// and avoids calling getSubStringLength too often\n\t\tvar start = Math.floor((w/sl) * txt.length);\n\t\tfor (var x = start; x > 0; x = x-2) {\n\t\t\tif (t.getSubStringLength(0, x + 2) <= w) {\n\t\t\t\tt.textContent = txt.substring(0, x) + \"..\";\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tt.textContent = \"\";\n\t}\n\n\t// zoom\n\tfunction zoom_reset(e) {\n\t\tif (e.attributes != undefined) {\n\t\t\torig_load(e, \"x\");\n\t\t\torig_load(e, \"width\");\n\t\t}\n\t\tif (e.childNodes == undefined) return;\n\t\tfor (var i = 0, c = e.childNodes; i < c.length; i++) {\n\t\t\tzoom_reset(c[i]);\n\t\t}\n\t}\n\tfunction zoom_child(e, x, ratio) {\n\t\tif (e.attributes != undefined) {\n\t\t\tif (e.attributes.x != undefined) {\n\t\t\t\torig_save(e, \"x\");\n\t\t\t\te.attributes.x.value = (parseFloat(e.attributes.x.value) - x - 10) * ratio + 10;\n\t\t\t\tif (e.tagName == \"text\")\n\t\t\t\t\te.attributes.x.value = find_child(e.parentNode, \"rect[x]\").attributes.x.value + 3;\n\t\t\t}\n\t\t\tif (e.attributes.width != undefined) {\n\t\t\t\torig_save(e, \"width\");\n\t\t\t\te.attributes.width.value = parseFloat(e.attributes.width.value) * ratio;\n\t\t\t}\n\t\t}\n\n\t\tif (e.childNodes == undefined) return;\n\t\tfor (var i = 0, c = e.childNodes; i < c.length; i++) {\n\t\t\tzoom_child(c[i], x - 10, ratio);\n\t\t}\n\t}\n\tfunction zoom_parent(e) {\n\t\tif (e.attributes) {\n\t\t\tif (e.attributes.x != undefined) {\n\t\t\t\torig_save(e, \"x\");\n\t\t\t\te.attributes.x.value = 10;\n\t\t\t}\n\t\t\tif (e.attributes.width != undefined) {\n\t\t\t\torig_save(e, \"width\");\n\t\t\t\te.attributes.width.value = parseInt(svg.width.baseVal.value) - (10 * 2);\n\t\t\t}\n\t\t}\n\t\tif (e.childNodes == undefined) return;\n\t\tfor (var i = 0, c = e.childNodes; i < c.length; i++) {\n\t\t\tzoom_parent(c[i]);\n\t\t}\n\t}\n\tfunction zoom(node) {\n\t\tvar attr = find_child(node, \"rect\").attributes;\n\t\tvar width = parseFloat(attr.width.value);\n\t\tvar xmin = parseFloat(attr.x.value);\n\t\tvar xmax = parseFloat(xmin + width);\n\t\tvar ymin = parseFloat(attr.y.value);\n\t\tvar ratio = (svg.width.baseVal.value - 2 * 10) / width;\n\n\t\t// XXX: Workaround for JavaScript float issues (fix me)\n\t\tvar fudge = 0.0001;\n\n\t\tunzoombtn.classList.remove(\"hide\");\n\n\t\tvar el = document.getElementById(\"frames\").children;\n\t\tfor (var i = 0; i < el.length; i++) {\n\t\t\tvar e = el[i];\n\t\t\tvar a = find_child(e, \"rect\").attributes;\n\t\t\tvar ex = parseFloat(a.x.value);\n\t\t\tvar ew = parseFloat(a.width.value);\n\t\t\tvar upstack;\n\t\t\t// Is it an ancestor\n\t\t\tif (0 == 0) {\n\t\t\t\tupstack = parseFloat(a.y.value) > ymin;\n\t\t\t} else {\n\t\t\t\tupstack = parseFloat(a.y.value) < ymin;\n\t\t\t}\n\t\t\tif (upstack) {\n\t\t\t\t// Direct ancestor\n\t\t\t\tif (ex <= xmin && (ex+ew+fudge) >= xmax) {\n\t\t\t\t\te.classList.add(\"parent\");\n\t\t\t\t\tzoom_parent(e);\n\t\t\t\t\tupdate_text(e);\n\t\t\t\t}\n\t\t\t\t// not in current path\n\t\t\t\telse\n\t\t\t\t\te.classList.add(\"hide\");\n\t\t\t}\n\t\t\t// Children maybe\n\t\t\telse {\n\t\t\t\t// no common path\n\t\t\t\tif (ex < xmin || ex + fudge >= xmax) {\n\t\t\t\t\te.classList.add(\"hide\");\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tzoom_child(e, xmin, ratio);\n\t\t\t\t\tupdate_text(e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tsearch();\n\t}\n\tfunction unzoom(dont_update_text) {\n\t\tunzoombtn.classList.add(\"hide\");\n\t\tvar el = document.getElementById(\"frames\").children;\n\t\tfor(var i = 0; i < el.length; i++) {\n\t\t\tel[i].classList.remove(\"parent\");\n\t\t\tel[i].classList.remove(\"hide\");\n\t\t\tzoom_reset(el[i]);\n\t\t\tif(!dont_update_text) update_text(el[i]);\n\t\t}\n\t\tsearch();\n\t}\n\tfunction clearzoom() {\n\t\tunzoom();\n\n\t\t// remove zoom state\n\t\tvar params = get_params();\n\t\tif (params.x) delete params.x;\n\t\tif (params.y) delete params.y;\n\t\thistory.replaceState(null, null, parse_params(params));\n\t}\n\n\t// search\n\tfunction toggle_ignorecase() {\n\t\tignorecase = !ignorecase;\n\t\tif (ignorecase) {\n\t\t\tignorecaseBtn.classList.add(\"show\");\n\t\t} else {\n\t\t\tignorecaseBtn.classList.remove(\"show\");\n\t\t}\n\t\treset_search();\n\t\tsearch();\n\t}\n\tfunction reset_search() {\n\t\tvar el = document.querySelectorAll(\"#frames rect\");\n\t\tfor (var i = 0; i < el.length; i++) {\n\t\t\torig_load(el[i], \"fill\")\n\t\t}\n\t\tvar params = get_params();\n\t\tdelete params.s;\n\t\thistory.replaceState(null, null, parse_params(params));\n\t}\n\tfunction search_prompt() {\n\t\tif (!searching) {\n\t\t\tvar term = prompt(\"Enter a search term (regexp \" +\n\t\t\t    \"allowed, eg: ^ext4_)\"\n\t\t\t    + (ignorecase ? \", ignoring case\" : \"\")\n\t\t\t    + \"\\nPress Ctrl-i to toggle case sensitivity\", \"\");\n\t\t\tif (term != null) search(term);\n\t\t} else {\n\t\t\treset_search();\n\t\t\tsearching = 0;\n\t\t\tcurrentSearchTerm = null;\n\t\t\tsearchbtn.classList.remove(\"show\");\n\t\t\tsearchbtn.firstChild.nodeValue = \"Search\"\n\t\t\tmatchedtxt.classList.add(\"hide\");\n\t\t\tmatchedtxt.firstChild.nodeValue = \"\"\n\t\t}\n\t}\n\tfunction search(term) {\n\t\tif (term) currentSearchTerm = term;\n\n\t\tvar re = new RegExp(currentSearchTerm, ignorecase ? 'i' : '');\n\t\tvar el = document.getElementById(\"frames\").children;\n\t\tvar matches = new Object();\n\t\tvar maxwidth = 0;\n\t\tfor (var i = 0; i < el.length; i++) {\n\t\t\tvar e = el[i];\n\t\t\tvar func = g_to_func(e);\n\t\t\tvar rect = find_child(e, \"rect\");\n\t\t\tif (func == null || rect == null)\n\t\t\t\tcontinue;\n\n\t\t\t// Save max width. Only works as we have a root frame\n\t\t\tvar w = parseFloat(rect.attributes.width.value);\n\t\t\tif (w > maxwidth)\n\t\t\t\tmaxwidth = w;\n\n\t\t\tif (func.match(re)) {\n\t\t\t\t// highlight\n\t\t\t\tvar x = parseFloat(rect.attributes.x.value);\n\t\t\t\torig_save(rect, \"fill\");\n\t\t\t\trect.attributes.fill.value = \"rgb(230,0,230)\";\n\n\t\t\t\t// remember matches\n\t\t\t\tif (matches[x] == undefined) {\n\t\t\t\t\tmatches[x] = w;\n\t\t\t\t} else {\n\t\t\t\t\tif (w > matches[x]) {\n\t\t\t\t\t\t// overwrite with parent\n\t\t\t\t\t\tmatches[x] = w;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tsearching = 1;\n\t\t\t}\n\t\t}\n\t\tif (!searching)\n\t\t\treturn;\n\t\tvar params = get_params();\n\t\tparams.s = currentSearchTerm;\n\t\thistory.replaceState(null, null, parse_params(params));\n\n\t\tsearchbtn.classList.add(\"show\");\n\t\tsearchbtn.firstChild.nodeValue = \"Reset Search\";\n\n\t\t// calculate percent matched, excluding vertical overlap\n\t\tvar count = 0;\n\t\tvar lastx = -1;\n\t\tvar lastw = 0;\n\t\tvar keys = Array();\n\t\tfor (k in matches) {\n\t\t\tif (matches.hasOwnProperty(k))\n\t\t\t\tkeys.push(k);\n\t\t}\n\t\t// sort the matched frames by their x location\n\t\t// ascending, then width descending\n\t\tkeys.sort(function(a, b){\n\t\t\treturn a - b;\n\t\t});\n\t\t// Step through frames saving only the biggest bottom-up frames\n\t\t// thanks to the sort order. This relies on the tree property\n\t\t// where children are always smaller than their parents.\n\t\tvar fudge = 0.0001;\t// JavaScript floating point\n\t\tfor (var k in keys) {\n\t\t\tvar x = parseFloat(keys[k]);\n\t\t\tvar w = matches[keys[k]];\n\t\t\tif (x >= lastx + lastw - fudge) {\n\t\t\t\tcount += w;\n\t\t\t\tlastx = x;\n\t\t\t\tlastw = w;\n\t\t\t}\n\t\t}\n\t\t// display matched percent\n\t\tmatchedtxt.classList.remove(\"hide\");\n\t\tvar pct = 100 * count / maxwidth;\n\t\tif (pct != 100) pct = pct.toFixed(1)\n\t\tmatchedtxt.firstChild.nodeValue = \"Matched: \" + pct + \"%\";\n\t}\n]]>\n</script>\n<rect x=\"0.0\" y=\"0\" width=\"1200.0\" height=\"406.0\" fill=\"url(#background)\"/>\n<text id=\"title\" x=\"600.00\" y=\"24\">Flame Graph</text>\n<text id=\"details\" x=\"10.00\" y=\"389\"> </text>\n<text id=\"unzoom\" x=\"10.00\" y=\"24\" class=\"hide\">Reset Zoom</text>\n<text id=\"search\" x=\"1090.00\" y=\"24\">Search</text>\n<text id=\"ignorecase\" x=\"1174.00\" y=\"24\">ic</text>\n<text id=\"matched\" x=\"1090.00\" y=\"389\"> </text>\n<g id=\"frames\">\n<g>\n<title>fib_recursive(int)&lt;0000000000001920&gt;[inline] (2 samples, 28.57%)</title><rect x=\"10.0\" y=\"229\" width=\"337.1\" height=\"15.0\" fill=\"rgb(218,61,14)\" rx=\"2\" ry=\"2\"/>\n<text x=\"13.00\" y=\"239.5\">fib_recursive(int)&lt;0000000000001920&gt;[inline]</text>\n</g>\n<g>\n<title>matrixMultiplyNaive(int)&lt;0000000000001bd0&gt; (3 samples, 42.86%)</title><rect x=\"347.1\" y=\"277\" width=\"505.8\" height=\"15.0\" fill=\"rgb(212,34,8)\" rx=\"2\" ry=\"2\"/>\n<text x=\"350.14\" y=\"287.5\">matrixMultiplyNaive(int)&lt;0000000000001bd0&gt;</text>\n</g>\n<g>\n<title>std::vector&lt;int, std::allocator&lt;int&gt; &gt;* std::uninitialized_fill_n&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt;*, unsigned long, std::vector&lt;int, std::allocator&lt;int&gt; &gt; &gt;(std::vector&lt;int, std::allocator&lt;int&gt; &gt;*, unsigned long, std::vector&lt;int, std::allocator&lt;int&gt; &gt; const&amp;)[inline] (1 samples, 14.29%)</title><rect x=\"684.3\" y=\"213\" width=\"168.6\" height=\"15.0\" fill=\"rgb(253,223,53)\" rx=\"2\" ry=\"2\"/>\n<text x=\"687.29\" y=\"223.5\">std::vector&lt;int, std:..</text>\n</g>\n<g>\n<title>fib_recursive(int)&lt;0000000000001920&gt;[inline] (2 samples, 28.57%)</title><rect x=\"10.0\" y=\"197\" width=\"337.1\" height=\"15.0\" fill=\"rgb(218,61,14)\" rx=\"2\" ry=\"2\"/>\n<text x=\"13.00\" y=\"207.5\">fib_recursive(int)&lt;0000000000001920&gt;[inline]</text>\n</g>\n<g>\n<title>all (7 samples, 100%)</title><rect x=\"10.0\" y=\"357\" width=\"1180.0\" height=\"15.0\" fill=\"rgb(213,39,9)\" rx=\"2\" ry=\"2\"/>\n<text x=\"13.00\" y=\"367.5\"/>\n</g>\n<g>\n<title>fib_recursive(int)&lt;0000000000001920&gt;[inline] (1 samples, 14.29%)</title><rect x=\"178.6\" y=\"117\" width=\"168.5\" height=\"15.0\" fill=\"rgb(218,61,14)\" rx=\"2\" ry=\"2\"/>\n<text x=\"181.57\" y=\"127.5\">fib_recursive(int)&lt;00..</text>\n</g>\n<g>\n<title>std::_Vector_base&lt;int, std::allocator&lt;int&gt; &gt;::_M_create_storage(unsigned long)[inline] (1 samples, 14.29%)</title><rect x=\"684.3\" y=\"133\" width=\"168.6\" height=\"15.0\" fill=\"rgb(213,39,9)\" rx=\"2\" ry=\"2\"/>\n<text x=\"687.29\" y=\"143.5\">std::_Vector_base&lt;int..</text>\n</g>\n<g>\n<title>std::allocator_traits&lt;std::allocator&lt;int&gt; &gt;::allocate(std::allocator&lt;int&gt;&amp;, unsigned long)[inline] (1 samples, 14.29%)</title><rect x=\"684.3\" y=\"101\" width=\"168.6\" height=\"15.0\" fill=\"rgb(241,166,39)\" rx=\"2\" ry=\"2\"/>\n<text x=\"687.29\" y=\"111.5\">std::allocator_traits..</text>\n</g>\n<g>\n<title>fib_recursive(int)&lt;0000000000001920&gt; (2 samples, 28.57%)</title><rect x=\"10.0\" y=\"133\" width=\"337.1\" height=\"15.0\" fill=\"rgb(234,136,32)\" rx=\"2\" ry=\"2\"/>\n<text x=\"13.00\" y=\"143.5\">fib_recursive(int)&lt;0000000000001920&gt;</text>\n</g>\n<g>\n<title>std::_Vector_base&lt;int, std::allocator&lt;int&gt; &gt;::_M_allocate(unsigned long)[inline] (1 samples, 14.29%)</title><rect x=\"684.3\" y=\"117\" width=\"168.6\" height=\"15.0\" fill=\"rgb(217,56,13)\" rx=\"2\" ry=\"2\"/>\n<text x=\"687.29\" y=\"127.5\">std::_Vector_base&lt;int..</text>\n</g>\n<g>\n<title>fib_recursive(int)&lt;0000000000001920&gt;[inline] (2 samples, 28.57%)</title><rect x=\"10.0\" y=\"261\" width=\"337.1\" height=\"15.0\" fill=\"rgb(218,61,14)\" rx=\"2\" ry=\"2\"/>\n<text x=\"13.00\" y=\"271.5\">fib_recursive(int)&lt;0000000000001920&gt;[inline]</text>\n</g>\n<g>\n<title>std::_Vector_base&lt;int, std::allocator&lt;int&gt; &gt;::_Vector_base(unsigned long, std::allocator&lt;int&gt; const&amp;)[inline] (1 samples, 14.29%)</title><rect x=\"684.3\" y=\"149\" width=\"168.6\" height=\"15.0\" fill=\"rgb(241,169,40)\" rx=\"2\" ry=\"2\"/>\n<text x=\"687.29\" y=\"159.5\">std::_Vector_base&lt;int..</text>\n</g>\n<g>\n<title>std::vector&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt;, std::allocator&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt; &gt; &gt;::_M_fill_initialize(unsigned long, std::vector&lt;int, std::allocator&lt;int&gt; &gt; const&amp;)[inline] (1 samples, 14.29%)</title><rect x=\"684.3\" y=\"245\" width=\"168.6\" height=\"15.0\" fill=\"rgb(211,29,7)\" rx=\"2\" ry=\"2\"/>\n<text x=\"687.29\" y=\"255.5\">std::vector&lt;std::vect..</text>\n</g>\n<g>\n<title>fib_recursive(int)&lt;0000000000001920&gt;[inline] (1 samples, 14.29%)</title><rect x=\"178.6\" y=\"101\" width=\"168.5\" height=\"15.0\" fill=\"rgb(218,61,14)\" rx=\"2\" ry=\"2\"/>\n<text x=\"181.57\" y=\"111.5\">fib_recursive(int)&lt;00..</text>\n</g>\n<g>\n<title>std::vector&lt;int, std::allocator&lt;int&gt; &gt;* std::__uninitialized_fill_n&lt;false&gt;::__uninit_fill_n&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt;*, unsigned long, std::vector&lt;int, std::allocator&lt;int&gt; &gt; &gt;(std::vector&lt;int, std::allocator&lt;int&gt; &gt;*, unsigned long, std::vector&lt;int, std::allocator&lt;int&gt; &gt; const&amp;)[inline] (1 samples, 14.29%)</title><rect x=\"684.3\" y=\"197\" width=\"168.6\" height=\"15.0\" fill=\"rgb(229,112,26)\" rx=\"2\" ry=\"2\"/>\n<text x=\"687.29\" y=\"207.5\">std::vector&lt;int, std:..</text>\n</g>\n<g>\n<title>__GI___libc_malloc (1 samples, 14.29%)</title><rect x=\"684.3\" y=\"53\" width=\"168.6\" height=\"15.0\" fill=\"rgb(219,68,16)\" rx=\"2\" ry=\"2\"/>\n<text x=\"687.29\" y=\"63.5\">__GI___libc_malloc</text>\n</g>\n<g>\n<title>matrixMultiplyOptimized(int)&lt;0000000000002020&gt; (2 samples, 28.57%)</title><rect x=\"852.9\" y=\"277\" width=\"337.1\" height=\"15.0\" fill=\"rgb(245,184,44)\" rx=\"2\" ry=\"2\"/>\n<text x=\"855.86\" y=\"287.5\">matrixMultiplyOptimized(int)&lt;0000000000002020&gt;</text>\n</g>\n<g>\n<title>fib_recursive(int)&lt;0000000000001920&gt;[inline] (2 samples, 28.57%)</title><rect x=\"10.0\" y=\"165\" width=\"337.1\" height=\"15.0\" fill=\"rgb(218,61,14)\" rx=\"2\" ry=\"2\"/>\n<text x=\"13.00\" y=\"175.5\">fib_recursive(int)&lt;0000000000001920&gt;[inline]</text>\n</g>\n<g>\n<title>_int_malloc (1 samples, 14.29%)</title><rect x=\"684.3\" y=\"37\" width=\"168.6\" height=\"15.0\" fill=\"rgb(215,47,11)\" rx=\"2\" ry=\"2\"/>\n<text x=\"687.29\" y=\"47.5\">_int_malloc</text>\n</g>\n<g>\n<title>fib_recursive(int)&lt;0000000000001920&gt;[inline] (2 samples, 28.57%)</title><rect x=\"10.0\" y=\"213\" width=\"337.1\" height=\"15.0\" fill=\"rgb(218,61,14)\" rx=\"2\" ry=\"2\"/>\n<text x=\"13.00\" y=\"223.5\">fib_recursive(int)&lt;0000000000001920&gt;[inline]</text>\n</g>\n<g>\n<title>fib_recursive(int)&lt;0000000000001920&gt;[inline] (2 samples, 28.57%)</title><rect x=\"10.0\" y=\"149\" width=\"337.1\" height=\"15.0\" fill=\"rgb(218,61,14)\" rx=\"2\" ry=\"2\"/>\n<text x=\"13.00\" y=\"159.5\">fib_recursive(int)&lt;0000000000001920&gt;[inline]</text>\n</g>\n<g>\n<title>fib_recursive(int)&lt;0000000000001920&gt; (2 samples, 28.57%)</title><rect x=\"10.0\" y=\"277\" width=\"337.1\" height=\"15.0\" fill=\"rgb(234,136,32)\" rx=\"2\" ry=\"2\"/>\n<text x=\"13.00\" y=\"287.5\">fib_recursive(int)&lt;0000000000001920&gt;</text>\n</g>\n<g>\n<title>__gnu_cxx::new_allocator&lt;int&gt;::allocate(unsigned long, void const*)[inline] (1 samples, 14.29%)</title><rect x=\"684.3\" y=\"85\" width=\"168.6\" height=\"15.0\" fill=\"rgb(234,135,32)\" rx=\"2\" ry=\"2\"/>\n<text x=\"687.29\" y=\"95.5\">__gnu_cxx::new_alloca..</text>\n</g>\n<g>\n<title>std::vector&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt;, std::allocator&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt; &gt; &gt;::vector(unsigned long, std::vector&lt;int, std::allocator&lt;int&gt; &gt; const&amp;, std::allocator&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt; &gt; const&amp;) (1 samples, 14.29%)</title><rect x=\"684.3\" y=\"261\" width=\"168.6\" height=\"15.0\" fill=\"rgb(246,190,45)\" rx=\"2\" ry=\"2\"/>\n<text x=\"687.29\" y=\"271.5\">std::vector&lt;std::vect..</text>\n</g>\n<g>\n<title>_start&lt;00000000000017b0&gt; (7 samples, 100.00%)</title><rect x=\"10.0\" y=\"341\" width=\"1180.0\" height=\"15.0\" fill=\"rgb(221,74,17)\" rx=\"2\" ry=\"2\"/>\n<text x=\"13.00\" y=\"351.5\">_start&lt;00000000000017b0&gt;</text>\n</g>\n<g>\n<title>fib_recursive(int)&lt;0000000000001920&gt;[inline] (2 samples, 28.57%)</title><rect x=\"10.0\" y=\"181\" width=\"337.1\" height=\"15.0\" fill=\"rgb(218,61,14)\" rx=\"2\" ry=\"2\"/>\n<text x=\"13.00\" y=\"191.5\">fib_recursive(int)&lt;0000000000001920&gt;[inline]</text>\n</g>\n<g>\n<title>void std::_Construct&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt;, std::vector&lt;int, std::allocator&lt;int&gt; &gt; const&amp;&gt;(std::vector&lt;int, std::allocator&lt;int&gt; &gt;*, std::vector&lt;int, std::allocator&lt;int&gt; &gt; const&amp;)[inline] (1 samples, 14.29%)</title><rect x=\"684.3\" y=\"181\" width=\"168.6\" height=\"15.0\" fill=\"rgb(252,216,51)\" rx=\"2\" ry=\"2\"/>\n<text x=\"687.29\" y=\"191.5\">void std::_Construct&lt;..</text>\n</g>\n<g>\n<title>std::vector&lt;int, std::allocator&lt;int&gt; &gt;::vector(std::vector&lt;int, std::allocator&lt;int&gt; &gt; const&amp;)[inline] (1 samples, 14.29%)</title><rect x=\"684.3\" y=\"165\" width=\"168.6\" height=\"15.0\" fill=\"rgb(224,91,21)\" rx=\"2\" ry=\"2\"/>\n<text x=\"687.29\" y=\"175.5\">std::vector&lt;int, std:..</text>\n</g>\n<g>\n<title>__libc_start_main_impl (7 samples, 100.00%)</title><rect x=\"10.0\" y=\"325\" width=\"1180.0\" height=\"15.0\" fill=\"rgb(218,63,15)\" rx=\"2\" ry=\"2\"/>\n<text x=\"13.00\" y=\"335.5\">__libc_start_main_impl</text>\n</g>\n<g>\n<title>__libc_start_call_main (7 samples, 100.00%)</title><rect x=\"10.0\" y=\"309\" width=\"1180.0\" height=\"15.0\" fill=\"rgb(210,26,6)\" rx=\"2\" ry=\"2\"/>\n<text x=\"13.00\" y=\"319.5\">__libc_start_call_main</text>\n</g>\n<g>\n<title>std::vector&lt;int, std::allocator&lt;int&gt; &gt;* std::__uninitialized_fill_n_a&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt;*, unsigned long, std::vector&lt;int, std::allocator&lt;int&gt; &gt;, std::vector&lt;int, std::allocator&lt;int&gt; &gt; &gt;(std::vector&lt;int, std::allocator&lt;int&gt; &gt;*, unsigned long, std::vector&lt;int, std::allocator&lt;int&gt; &gt; const&amp;, std::allocator&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt; &gt;&amp;)[inline] (1 samples, 14.29%)</title><rect x=\"684.3\" y=\"229\" width=\"168.6\" height=\"15.0\" fill=\"rgb(237,147,35)\" rx=\"2\" ry=\"2\"/>\n<text x=\"687.29\" y=\"239.5\">std::vector&lt;int, std:..</text>\n</g>\n<g>\n<title>main&lt;0000000000001440&gt; (7 samples, 100.00%)</title><rect x=\"10.0\" y=\"293\" width=\"1180.0\" height=\"15.0\" fill=\"rgb(236,144,34)\" rx=\"2\" ry=\"2\"/>\n<text x=\"13.00\" y=\"303.5\">main&lt;0000000000001440&gt;</text>\n</g>\n<g>\n<title>operator new(unsigned long)@@GLIBCXX_3.4&lt;00000000000ae970&gt; (1 samples, 14.29%)</title><rect x=\"684.3\" y=\"69\" width=\"168.6\" height=\"15.0\" fill=\"rgb(251,214,51)\" rx=\"2\" ry=\"2\"/>\n<text x=\"687.29\" y=\"79.5\">operator new(unsigned..</text>\n</g>\n<g>\n<title>fib_recursive(int)&lt;0000000000001920&gt;[inline] (2 samples, 28.57%)</title><rect x=\"10.0\" y=\"245\" width=\"337.1\" height=\"15.0\" fill=\"rgb(218,61,14)\" rx=\"2\" ry=\"2\"/>\n<text x=\"13.00\" y=\"255.5\">fib_recursive(int)&lt;0000000000001920&gt;[inline]</text>\n</g>\n</g>\n</svg>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpreting Profiling Results and Understanding Performance\n",
        "\n",
        "## Program Execution and Output\n",
        "\n",
        "After running the program, we obtain execution times for each computational function:\n",
        "\n",
        "\n",
        "**Key Observations:**\n",
        "\n",
        "- **Recursive Fibonacci is significantly slower** than the iterative version.\n",
        "- **Optimized matrix multiplication** performs better than the naive implementation.\n",
        "- **Prime number generation** completes relatively quickly.\n",
        "\n",
        "## Profiling Data Analysis\n",
        "\n",
        "### Visual Call Graph (SVG Report)\n",
        "\n",
        "The call graph provides a visual representation of function calls and the time spent in each function.\n",
        "\n",
        "- **Nodes (Boxes):** Represent functions in the program.\n",
        "- **Edges (Arrows):** Indicate calls between functions.\n",
        "- **Node Size and Color:**\n",
        "  - **Larger and hotter-colored nodes** (e.g., red) consume more execution time.\n",
        "  - **Smaller and cooler-colored nodes** (e.g., blue) consume less time.\n",
        "\n",
        "**Interpreting the Call Graph:**\n",
        "\n",
        "- **Hotspots:**\n",
        "  - **`fib_recursive`:** Likely the largest and hottest node, indicating it consumes the most time.\n",
        "  - **`matrixMultiplyNaive`:** Another significant hotspot due to its inefficiency.\n",
        "\n",
        "- **Function Relationships:**\n",
        "  - The graph shows how the `main` function calls other functions.\n",
        "  - Helps visualize the execution flow and identify which functions are critical for performance.\n",
        "\n",
        "### Line-by-Line Profiling Report\n",
        "\n",
        "The report provides detailed information about CPU time spent on specific lines of code.\n",
        "\n",
        "**Sample Output:**\n",
        "\n",
        "\n",
        "**Interpreting the Report:**\n",
        "\n",
        "- **`fib_recursive`:** Consumes 60% of the total CPU samples.\n",
        "  - Indicates that this function is the primary bottleneck.\n",
        "  - The high percentage reflects its inefficiency due to recursive calls.\n",
        "\n",
        "- **`matrixMultiplyNaive`:** Accounts for 30% of CPU samples.\n",
        "  - Shows that the naive matrix multiplication is also a significant consumer of resources.\n",
        "\n",
        "- **`generate_primes`:** Uses 10% of CPU samples.\n",
        "  - Relatively efficient compared to the other functions.\n",
        "\n",
        "## Understanding Performance Implications\n",
        "\n",
        "### Recursive vs. Iterative Fibonacci\n",
        "\n",
        "- **Recursive Implementation:**\n",
        "  - Exhibits exponential time complexity.\n",
        "  - Redundant calculations due to overlapping subproblems.\n",
        "  - **Profiling shows high CPU usage and deep call stacks.**\n",
        "\n",
        "- **Iterative Implementation:**\n",
        "  - Linear time complexity.\n",
        "  - Efficient use of resources.\n",
        "  - **Profiling shows minimal CPU usage.**\n",
        "\n",
        "**Takeaway:** Choosing the right algorithm dramatically impacts performance.\n",
        "\n",
        "### Naive vs. Optimized Matrix Multiplication\n",
        "\n",
        "- **Naive Implementation:**\n",
        "  - Poor memory access patterns leading to cache misses.\n",
        "  - Inefficient loop ordering.\n",
        "  - **Profiling highlights significant time spent in nested loops.**\n",
        "\n",
        "- **Optimized Implementation:**\n",
        "  - Improved memory access and cache utilization.\n",
        "  - Rearranged loops for better performance.\n",
        "  - **Profiling shows reduced CPU usage and better efficiency.**\n",
        "\n",
        "**Takeaway:** Optimizing code for hardware characteristics (like CPU cache) enhances performance.\n",
        "\n",
        "## Using Profiling Data to Guide Optimization\n",
        "\n",
        "- **Identify Bottlenecks:**\n",
        "  - Focus on functions with the highest CPU usage.\n",
        "  - **`fib_recursive`** is an immediate candidate for optimization or replacement.\n",
        "\n",
        "- **Assess Algorithm Efficiency:**\n",
        "  - Evaluate whether a different algorithm can improve performance.\n",
        "  - **Switching from recursive to iterative Fibonacci yields significant gains.**\n",
        "\n",
        "- **Optimize Critical Code Paths:**\n",
        "  - In performance-critical functions, consider low-level optimizations.\n",
        "  - **Optimizing matrix multiplication loops reduces execution time.**\n",
        "\n",
        "- **Validate Optimizations:**\n",
        "  - Use profiling to confirm that changes lead to expected improvements.\n",
        "  - **Profiling after optimization shows reduced time in targeted functions.**\n",
        "\n",
        "## Communicating Results to Stakeholders\n",
        "\n",
        "When presenting profiling results:\n",
        "\n",
        "- **Use Visuals:** Call graphs and flame graphs effectively communicate where the program spends time.\n",
        "- **Highlight Key Findings:** Emphasize functions or lines of code that are bottlenecks.\n",
        "- **Demonstrate Impact:** Show before-and-after comparisons to illustrate the benefits of optimization.\n",
        "- **Provide Recommendations:** Suggest actionable steps to improve performance.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Profiling with gperftools provides valuable insights into program performance:\n",
        "\n",
        "- **Helps pinpoint inefficiencies** in both algorithms and implementations.\n",
        "- **Guides developers** toward effective optimization strategies.\n",
        "- **Enhances understanding** of how code interacts with hardware.\n",
        "\n",
        "By applying these profiling techniques, you can optimize your programs for better performance, leading to faster execution times and more efficient resource utilization.\n"
      ],
      "metadata": {
        "id": "GF7ETRQmJ8Lv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6Nqucg1cftxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Profiling Distributed Applications using Scalasca\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this practice, we will explore **Scalasca**, a performance analysis tool used to profile MPI-based distributed applications. Scalasca helps to identify performance bottlenecks in parallel applications, especially for message-passing systems.\n",
        "\n",
        "Profiling is essential in **High-Performance Computing (HPC)** because it allows developers to:\n",
        "- Pinpoint inefficiencies in communication or computation.\n",
        "- Measure parallel scalability.\n",
        "- Optimize code for better CPU and network utilization.\n",
        "\n",
        "In this lesson, we will profile a simple MPI-based application and analyze the results using Scalasca.\n",
        "\n",
        "### Why Profiling Matters in HPC\n",
        "\n",
        "HPC applications often run on distributed systems, requiring efficient communication between nodes. Profiling tools such as Scalasca allow you to visualize how time is spent in the application, highlighting areas of improvement, including:\n",
        "1. **Load imbalance** – Are all processors doing equal work?\n",
        "2. **Communication overhead** – How much time is spent waiting for data from other nodes?\n",
        "3. **Scalability** – How does the performance change when the number of nodes increases?\n",
        "\n",
        "---\n",
        "\n",
        "## Steps for Profiling a Distributed Application with Scalasca\n",
        "\n",
        "1. **Write a simple MPI application**.\n",
        "2. **Compile the application with Scalasca support**.\n",
        "3. **Run the application on multiple nodes with Scalasca**.\n",
        "4. **Analyze the Scalasca performance report**.\n",
        "\n",
        "To do this in Google Colab, we will first install an MPI library (`OpenMPI`) and Scalasca, then run the distributed application and simulate multi-node behavior.\n",
        "\n",
        "---\n",
        "\n",
        "## Installing MPI and Scalasca in Google Colab\n",
        "\n",
        "Since Google Colab doesn't have MPI and Scalasca installed by default, we'll first install these packages. This setup assumes that we simulate a multi-node environment in Colab, and the actual profiling will be similar to what you would run on a cluster.\n"
      ],
      "metadata": {
        "id": "Y6yMfCpSZuUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation of the Code\n",
        "\n",
        "### 1.Loading the module Scalasca\n",
        "\n",
        "We first install MPI (OpenMPI) and Scalasca in Google Colab to set up our environment. MPI allows us to run parallel programs over multiple processes, and Scalasca is the tool we use to profile these parallel programs.\n",
        "\n",
        "### 2. Writing the MPI Application\n",
        "\n",
        "The MPI application performs a simple **matrix multiplication** distributed across several processes. We use MPI to divide the computation across multiple processors, simulating a real-world distributed computation.\n",
        "\n",
        "- **MPI_Init & MPI_Finalize**: Initializes and finalizes the MPI environment.\n",
        "- **MPI_Comm_rank & MPI_Comm_size**: Get the rank (ID) of each process and the total number of processes, respectively.\n",
        "- **Matrix Multiplication**: Each process performs matrix multiplication on its part of the data, and we use `MPI` to manage the parallel execution.\n",
        "\n",
        "### 3. Running the Program with Scalasca\n",
        "\n",
        "We run the application using Scalasca's `-analyze` option to collect performance data. The application is executed with 4 processes (you can scale this to as many processes as your system allows).\n",
        "\n",
        "### 4. Analyzing the Scalasca Report\n",
        "\n",
        "Scalasca generates a performance report after the program finishes execution. We use `scalasca -examine` to examine the collected data, which helps us understand:\n",
        "- How much time each process spent in computation vs. communication.\n",
        "- Whether there are any bottlenecks in message-passing between processes.\n",
        "- Potential improvements to optimize the code for better performance and scalability.\n",
        "\n",
        "By examining this profile, we can learn whether there are any inefficiencies in our MPI-based distributed application, such as load imbalance or communication delays.\n"
      ],
      "metadata": {
        "id": "7LyNkw-8Z6Ao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Introduction\n",
        "\n",
        "In this lesson, we will profile a distributed MPI application using **Scalasca** on an HPC cluster. Since we are working from a Jupyter notebook, we will not directly execute the commands here, but instead connect to the HPC cluster using SSH and run the profiling steps from there.\n",
        "\n",
        "### What You Will Learn\n",
        "\n",
        "- How to connect to an HPC cluster via SSH.\n",
        "- How to compile an MPI program with **SCOREP** instrumentation for profiling.\n",
        "- How to run an MPI program and collect profiling data using **Scalasca**.\n",
        "- How to examine and interpret the performance profiling report.\n",
        "\n",
        "### Requirements\n",
        "\n",
        "1. An HPC account with access to a login node.\n",
        "2. SSH access to the HPC cluster.\n",
        "3. MPI (OpenMPI) and Scalasca installed on the cluster.\n",
        "\n",
        "---\n",
        "\n",
        "## Steps to Run Profiling via SSH\n",
        "\n",
        "### 1. Connect to the HPC Cluster\n",
        "\n",
        "To start, you will need to connect to the HPC cluster's login node. Open a terminal (outside of Jupyter) and run the following command to establish an SSH connection:\n",
        "\n",
        "```bash\n",
        "ssh <username>@login1.hpcie.labs.faculty.ie.edu\n"
      ],
      "metadata": {
        "id": "bdTC7PT6b_R9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace <username> with your actual username.\n",
        "\n",
        "Once connected, you will be in the HPC environment and can proceed with compiling and running your MPI application.\n",
        "\n",
        "Use the scratch directory when possible toplay with the system.\n",
        "\n",
        "###2. Load the Necessary Modules\n",
        "After logging into the cluster, load the required modules for MPI and Scalasca. Use the following commands:\n",
        "\n",
        "```bash\n",
        "module load gcc\n",
        "module load openmpi\n",
        "module load scalasca\n",
        "```\n",
        "\n",
        "This will ensure you have the correct environment for compiling and profiling MPI applications.\n",
        "\n",
        "###3. Write and Compile an MPI Application\n",
        "If you haven't already written an MPI application, you can create a simple matrix multiplication MPI program. Create a new .cpp file and write the code:\n",
        "\n",
        "```bash\n",
        "nano mpi_matrix_multiply.cpp\n",
        "```\n",
        "\n",
        "Paste the following code into the editor:\n",
        "\n",
        "\n",
        "```cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "\n",
        "void matrix_multiply(int N) {\n",
        "    std::vector<std::vector<int>> A(N, std::vector<int>(N, 1));\n",
        "    std::vector<std::vector<int>> B(N, std::vector<int>(N, 1));\n",
        "    std::vector<std::vector<int>> C(N, std::vector<int>(N, 0));\n",
        "\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            for (int k = 0; k < N; ++k) {\n",
        "                C[i][j] += A[i][k] * B[k][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]) {\n",
        "    MPI_Init(&argc, &argv);\n",
        "    int rank, size;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "\n",
        "    int N = 1000; // Matrix size\n",
        "    if (rank == 0) {\n",
        "        std::cout << \"Starting matrix multiplication on \" << size << \" processes\" << std::endl;\n",
        "    }\n",
        "\n",
        "    matrix_multiply(N);\n",
        "    \n",
        "    std::cout << \"Process \" << rank << \" completed work\" << std::endl;\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}\n",
        "```\n",
        "\n",
        "Now, compile the application with SCOREP instrumentation:\n",
        "\n",
        "```bash\n",
        "scorep mpicxx mpi_matrix_multiply.cpp -o mpi_matrix_multiply\n",
        "```\n",
        "\n",
        "This command will instrument the code so that Scalasca can profile it.\n",
        "\n",
        "###4. Run the Application with Scalasca\n",
        "Once the application is compiled, you can run it using Scalasca to analyze the performance. Run the following command:\n",
        "\n",
        "```bash\n",
        "scalasca -analyze mpirun -np 4 -oversubscribe ./mpi_matrix_multiply\n",
        "```\n",
        "\n",
        "Here:\n",
        "\n",
        "scalasca -analyze is used to collect performance data.\n",
        "mpirun -np 4 runs the program with 4 MPI processes.\n",
        "./mpi_matrix_multiply is the executable that was created.\n",
        "\n",
        "###5. Analyze the Profiling Report\n",
        "Once the application finishes running, Scalasca will generate a performance report in the form of scorep_* directories. You can analyze this report using:\n",
        "\n",
        "```bash\n",
        "export SCOREP_TIMER=gettimeofday\n",
        "\n",
        "scalasca -examine --console scorep_*\n",
        "\n",
        "```\n",
        "This will generate a detailed analysis of your program's performance, showing you where the bottlenecks are in communication, computation, and load balancing between nodes.\n",
        "\n",
        "###6. Optional: Visualize the Report\n",
        "You can visualize the report in various ways using additional tools like cube:\n",
        "\n",
        "```bash\n",
        "module load cube\n",
        "cube <filename.cubex>\n",
        "```\n",
        "\n",
        "This opens a graphical performance analysis report where you can explore function calls, MPI communication patterns, and other insights."
      ],
      "metadata": {
        "id": "OvkQQcULcEHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Measurement with PAPI in HPC Applications\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, we will explore how to use **PAPI** (Performance Application Programming Interface) to measure performance metrics such as floating-point operations in an HPC application. PAPI provides an interface to access hardware performance counters, which allows you to monitor different events at the hardware level (e.g., instructions executed, floating-point operations, cache misses, etc.).\n",
        "\n",
        "In this exercise, we will use a simple matrix-vector multiplication example, instrument it with PAPI, and count specific events like **double-precision floating-point operations** (`PAPI_DP_OPS`) and **vector operations** (`PAPI_VEC_DP`).\n",
        "\n",
        "### Why PAPI?\n",
        "\n",
        "In High-Performance Computing (HPC), optimizing performance is critical. Tools like PAPI allow developers to get detailed information about how efficiently their applications are using system resources. By understanding where bottlenecks lie (whether in computation or memory access), we can optimize our code to fully exploit the hardware's potential.\n",
        "\n",
        "---\n",
        "\n",
        "## Steps in This Notebook\n",
        "\n",
        "1. Write and compile a C program that performs matrix-vector multiplication and integrates PAPI for performance measurement.\n",
        "2. Use PAPI to count double-precision floating-point operations (`PAPI_DP_OPS`) and vector operations (`PAPI_VEC_DP`).\n",
        "3. Measure and interpret the results.\n",
        "4. Test and run the program on an HPC cluster and visualize the collected data.\n",
        "\n",
        "Let's dive into the practical part.\n"
      ],
      "metadata": {
        "id": "BFnxv_oblwLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if papi is available\n",
        "!papi_avail"
      ],
      "metadata": {
        "id": "kriLrzOYm5Uc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e74bfa9c-8820-422c-bb22-f39abe30c478"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: papi_avail: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#If not installed, install papi library\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y libpapi-dev papi-tools\n",
        "!ls /usr/include/papi.h\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIzd4Re7mVRq",
        "outputId": "d47939f2-da7c-4b7d-c2ff-60035705dd7b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connected to cloud.r-project.org (108.13\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connected to r2u.stat.illinois.edu (192.\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Ign:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libpapi-dev is already the newest version (6.0.0~dfsg-2).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libbz2-dev libpkgconf3 libreadline-dev\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "The following NEW packages will be installed:\n",
            "  papi-tools\n",
            "0 upgraded, 1 newly installed, 0 to remove and 54 not upgraded.\n",
            "Need to get 53.0 kB of archives.\n",
            "After this operation, 318 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 papi-tools amd64 6.0.0~dfsg-2 [53.0 kB]\n",
            "Fetched 53.0 kB in 0s (479 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package papi-tools.\n",
            "(Reading database ... 126278 files and directories currently installed.)\n",
            "Preparing to unpack .../papi-tools_6.0.0~dfsg-2_amd64.deb ...\n",
            "Unpacking papi-tools (6.0.0~dfsg-2) ...\n",
            "Setting up papi-tools (6.0.0~dfsg-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "/usr/include/papi.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Write the matrix-vector multiplication program (mvmult_timer.c) with software-based timing\n",
        "code = \"\"\"\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cblas.h>\n",
        "#include <time.h>\n",
        "\n",
        "void init(int n, double **m, double **v, double **p, int trans) {\n",
        "    *m = calloc(n*n, sizeof(double));\n",
        "    *v = calloc(n, sizeof(double));\n",
        "    *p = calloc(n, sizeof(double));\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        (*v)[i] = (i & 1)? -1.0: 1.0;\n",
        "        if (trans) for (int j = 0; j <= i; j++) (*m)[j*n+i] = 1.0;\n",
        "        else for (int j = 0; j <= i; j++) (*m)[i*n+j] = 1.0;\n",
        "    }\n",
        "}\n",
        "\n",
        "void mult(int size, double *m, double *v, double *p, int trans) {\n",
        "    int stride = trans? size: 1;\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        int mi = trans? i: i*size;\n",
        "        p[i] = cblas_ddot(size, m+mi, stride, v, 1);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    int n = 1000, trans = 0;\n",
        "    if (argc > 1) n = strtol(argv[1], NULL, 10);\n",
        "    if (argc > 2) trans = (argv[2][0] == 't');\n",
        "\n",
        "    struct timespec start, end;\n",
        "    double *m, *v, *p;\n",
        "\n",
        "    clock_gettime(CLOCK_MONOTONIC, &start);\n",
        "    init(n, &m, &v, &p, trans);\n",
        "    clock_gettime(CLOCK_MONOTONIC, &end);\n",
        "\n",
        "    double init_time = (end.tv_sec - start.tv_sec) + (end.tv_nsec - start.tv_nsec) / 1e9;\n",
        "\n",
        "    clock_gettime(CLOCK_MONOTONIC, &start);\n",
        "    mult(n, m, v, p, trans);\n",
        "    clock_gettime(CLOCK_MONOTONIC, &end);\n",
        "\n",
        "    double mult_time = (end.tv_sec - start.tv_sec) + (end.tv_nsec - start.tv_nsec) / 1e9;\n",
        "\n",
        "    double s = cblas_dasum(n, p, 1);\n",
        "    printf(\"Size %d; abs. sum: %f (expected: %d)\\\\n\", n, s, (n+1)/2);\n",
        "    printf(\"Timing results (seconds):\\\\n\");\n",
        "    printf(\" Initialization time: %f\\\\n\", init_time);\n",
        "    printf(\" Multiplication time: %f\\\\n\", mult_time);\n",
        "\n",
        "    free(m);\n",
        "    free(v);\n",
        "    free(p);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Write the C code to a file\n",
        "with open('mvmult_timer.c', 'w') as f:\n",
        "    f.write(code)\n",
        "\n",
        "# Step 2: Compile the code with CBLAS library\n",
        "!gcc -O2 mvmult_timer.c -o mvmult_timer -lcblas\n",
        "\n",
        "# Verify that the executable has been created\n",
        "!ls -l mvmult_timer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNoEfCglZ7Vr",
        "outputId": "9cd80229-9f1c-47fd-e7ca-c957ff89333a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rwxr-xr-x 1 root root 16368 Sep 28 15:38 mvmult_timer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Run the program with a size of 20000\n",
        "!./mvmult_timer 20000\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11l2WyPBZ8ZA",
        "outputId": "bad6d6bf-5ca9-4b0e-fef3-8cc15e6220e7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size 20000; abs. sum: 10000.000000 (expected: 10000)\n",
            "Timing results (seconds):\n",
            " Initialization time: 2.334474\n",
            " Multiplication time: 1.136657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation of Results\n",
        "\n",
        "The output of the program includes the following key information:\n",
        "\n",
        "1. **Matrix Size**: The matrix size used for multiplication (in this case, 20000).\n",
        "2. **Absolute Sum of Result**: This verifies that the computation was performed correctly by summing the elements of the result vector.\n",
        "3. **PAPI Counts**:\n",
        "   - **init**: The count of floating-point and vector operations before the matrix-vector multiplication begins.\n",
        "   - **mult**: The number of floating-point and vector operations that occurred during the matrix-vector multiplication.\n",
        "   - **sum**: The total count of operations after the computation is complete.\n",
        "\n",
        "For example, a typical output might look like this:\n",
        "\n",
        "```plaintext\n",
        "Size 20000; abs. sum: 10000.000000 (expected: 10000)\n",
        "PAPI counts:\n",
        " init: event1: 0               event2: 0\n",
        " mult: event1: 804193640        event2: 0\n",
        " sum:  event1: 20276           event2: 0\n"
      ],
      "metadata": {
        "id": "sPSNEwR5mFfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Running the Program and Using GDB to Debug OpenMP Threads**\n",
        "\n",
        "In this section, we will first install the necessary tools to work with OpenMP and GDB in Google Colab. This includes installing the GCC compiler and GDB, a powerful debugger.\n",
        "\n",
        "We will then write a simple OpenMP C program that initializes two arrays, performs some calculations in parallel, and reduces the result into a single value using a reduction clause. We will compile the program using the `-g` flag to include debugging information, which will be helpful in the next steps when we analyze the program using GDB.\n",
        "\n",
        "### **What the Code Does:**\n",
        "\n",
        "1. **Installing tools**: We install `gcc` (GNU Compiler Collection) and `gdb` (GNU Debugger) to compile and debug the OpenMP code.\n",
        "2. **Writing the OpenMP program**: A C program is created which will:\n",
        "   - Use OpenMP to parallelize a `for` loop.\n",
        "   - Perform element-wise multiplication of two arrays, `a[]` and `b[]`.\n",
        "   - Use reduction to sum up the results from each thread.\n",
        "3. **Compiling with Debug Symbols**: The program is compiled with debugging information (`-g`) so that we can analyze it step-by-step in GDB.\n",
        "   \n",
        "Now, let's get started with writing and compiling the program.\n"
      ],
      "metadata": {
        "id": "s3Yu_KGQXKYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install GCC and GDB in Google Colab\n",
        "!apt update\n",
        "!apt install -y gcc gdb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq0FE7pMV4jg",
        "outputId": "3dd116f2-7f55-406e-e823-6e085450e8bc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Connected to cloud.r-project.org (108.139.15\u001b[0m\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Ign:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "54 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "gcc is already the newest version (4:11.2.0-1ubuntu1).\n",
            "gdb is already the newest version (12.1-0ubuntu1~22.04.2).\n",
            "gdb set to manually installed.\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libbz2-dev libpkgconf3 libreadline-dev\n",
            "Use 'apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Running the Program and Using GDB to Debug OpenMP Threads**\n",
        "\n",
        "\n",
        "#### Step 1: Run the compiled program to see its normal output\n",
        "!./openmp_program\n",
        "\n",
        "#### Step 2: Start GDB to debug the program\n",
        "!gdb ./openmp_program\n",
        "\n",
        "#### Step 3: Inside GDB, the following commands will be run manually:\n",
        " (gdb) break 23          # Set a breakpoint at line 23 where the calculation is happening\n",
        "\n",
        " (gdb) run               # Start running the program under GDB\n",
        "\n",
        " (gdb) info threads      # List the threads created by OpenMP\n",
        "\n",
        " (gdb) thread 2          # Switch to thread 2 to see its local variables\n",
        "\n",
        " (gdb) print i           # Inspect the variable 'i' in thread 2\n",
        "\n",
        " (gdb) thread 3          # Switch to thread 3 to see the values in this thread\n",
        "\n",
        " (gdb) print i           # Inspect the variable 'i' in thread 3\n",
        "\n",
        " (gdb) quit              # Exit GDB when done\n"
      ],
      "metadata": {
        "id": "3Lc1FA0JXDhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing the OpenMP C program into a file\n",
        "code = \"\"\"\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "\n",
        "int main() {\n",
        "    const int n = 30;\n",
        "    int i, chunk;\n",
        "    double a[n], b[n], result = 0.0;\n",
        "\n",
        "    chunk = 5;\n",
        "    #pragma omp parallel for shared(a, b) private(i) schedule(static, chunk) reduction(+: result)\n",
        "    for (i = 0; i < n; i++) {\n",
        "        a[i] = i * 3.14;\n",
        "        b[i] = i * 6.67;\n",
        "        result += a[i] * b[i];\n",
        "    }\n",
        "\n",
        "    printf(\"Final result = %f\\\\n\", result);\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Save the code to a file\n",
        "with open('openmp_program.c', 'w') as f:\n",
        "    f.write(code)\n",
        "\n",
        "# Compile the program\n",
        "!gcc -g -fopenmp -o openmp_program openmp_program.c\n",
        "\n",
        "# Run the compiled OpenMP program\n",
        "!./openmp_program\n",
        "\n",
        "# Start GDB session\n",
        "!gdb ./openmp_program\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hTvRpwzWN2N",
        "outputId": "9c06801f-1c9f-43f5-8c3f-cb162eb1cf21"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final result = 179174.209000\n",
            "\u001b[35;1mGNU gdb (Ubuntu 12.1-0ubuntu1~22.04.2) 12.1\u001b[m\n",
            "Copyright (C) 2022 Free Software Foundation, Inc.\n",
            "License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\n",
            "This is free software: you are free to change and redistribute it.\n",
            "There is NO WARRANTY, to the extent permitted by law.\n",
            "Type \"show copying\" and \"show warranty\" for details.\n",
            "This GDB was configured as \"x86_64-linux-gnu\".\n",
            "Type \"show configuration\" for configuration details.\n",
            "For bug reporting instructions, please see:\n",
            "<https://www.gnu.org/software/gdb/bugs/>.\n",
            "Find the GDB manual and other documentation resources online at:\n",
            "    <http://www.gnu.org/software/gdb/documentation/>.\n",
            "\n",
            "For help, type \"help\".\n",
            "Type \"apropos word\" to search for commands related to \"word\"...\n",
            "Reading symbols from \u001b[32m./openmp_program\u001b[m...\n",
            "\u001b[?2004h(gdb) break 23\n",
            "No line 23 in the current file.\n",
            "\u001b[?2004hMake breakpoint pending on future shared library load? (y or [n]) y\n",
            "Breakpoint 1 (23) pending.\n",
            "\u001b[?2004h(gdb) run\n",
            "Starting program: \u001b[32m/openmp_program\u001b[m \n",
            "[Thread debugging using libthread_db enabled]\n",
            "Using host libthread_db library \"\u001b[32m/lib/x86_64-linux-gnu/libthread_db.so.1\u001b[m\".\n",
            "[New Thread 0x7ffff7d2e640 (LWP 88772)]\n",
            "Final result = 179174.209000\n",
            "[Thread 0x7ffff7d2f7c0 (LWP 88769) exited]\n",
            "[Thread 0x7ffff7d2e640 (LWP 88772) exited]\n",
            "[New process 88769]\n",
            "[Inferior 1 (process 88769) exited normally]\n",
            "\u001b[?2004h(gdb) Quit\n",
            "\u001b[?2004h(gdb) Quit\n",
            "\u001b[?2004h(gdb) Quit\n",
            "Exception ignored in: <gdb._GdbOutputFile object at 0x7d682b21c4c0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/share/gdb/python/gdb/__init__.py\", line 47, in flush\n",
            "    def flush(self):\n",
            "KeyboardInterrupt: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **What Happened in the Code:**\n",
        "\n",
        "After running the code, you will see that:\n",
        "- The necessary tools (`gcc`, `gdb`) were installed successfully.\n",
        "- The OpenMP program was written and saved as a file named `openmp_program.c`.\n",
        "- The program was then compiled using the GCC compiler, with the `-g` flag ensuring that debugging symbols are included in the binary file. This allows us to step through the code and inspect variables in GDB later.\n",
        "\n",
        "### **Next Steps:**\n",
        "\n",
        "1. **Run the Program**: Before jumping into debugging, let’s run the compiled OpenMP program to see its normal output.\n",
        "2. **Debug with GDB**: After running the program, we will use GDB to:\n",
        "   - Set a breakpoint at the line where the main calculation happens.\n",
        "   - List the active threads and switch between them.\n",
        "   - Inspect the values of variables like `i`, `a[i]`, and `b[i]` in each thread.\n"
      ],
      "metadata": {
        "id": "4mCE5JlnXWeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JwjqS6eVWwal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 1: Debugging OpenMP with Valgrind**\n",
        "\n",
        "In this section, we will investigate a common error in OpenMP programming: accessing an unprotected shared variable. In parallel programming, when multiple threads try to update a shared variable without proper synchronization, it can lead to a **data race**. This can cause unpredictable behavior and inconsistent results in your program.\n",
        "\n",
        "We will use **Valgrind** with its **Helgrind** tool, which helps in detecting race conditions. Helgrind will provide detailed warnings about potential data races in the code.\n",
        "\n",
        "The provided OpenMP program contains a bug: the shared variable `sum` is updated by multiple threads without protection, leading to a data race.\n",
        "\n",
        "### **What This Code Will Do:**\n",
        "\n",
        "1. **Valgrind Installation**: We will install Valgrind to analyze the program for race conditions.\n",
        "2. **Writing the buggy OpenMP program**: A program that updates a shared variable (`sum`) in parallel without any protection.\n",
        "3. **Running Valgrind (Helgrind)**: We will run Valgrind to detect the data race and see where it occurs.\n",
        "4. **Fixing the bug**: Finally, we will fix the bug by adding a proper OpenMP reduction clause to handle the shared variable correctly.\n"
      ],
      "metadata": {
        "id": "xQh6Ef5RYaWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to install Valgrind, write the buggy OpenMP program, and run Valgrind to detect a race condition\n",
        "\n",
        "# Step 1: Install Valgrind\n",
        "!apt update\n",
        "!apt install -y valgrind"
      ],
      "metadata": {
        "id": "H-4s5BIxYtZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Step 2: Write the buggy OpenMP program that contains a data race\n",
        "buggy_code = \"\"\"\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "\n",
        "int main() {\n",
        "    int i, sum = 0;\n",
        "\n",
        "    #pragma omp parallel for\n",
        "    for (i = 0; i < 100; i++) {\n",
        "        sum += i;  // This update is unprotected and leads to a data race\n",
        "    }\n",
        "\n",
        "    printf(\"Result = %d\\\\n\", sum);\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Save the buggy code to a file\n",
        "with open('buggy_program.c', 'w') as f:\n",
        "    f.write(buggy_code)\n",
        "\n",
        "# Step 3: Compile the program with debugging symbols\n",
        "!gcc -g -fopenmp -o buggy_program buggy_program.c\n",
        "\n",
        "# Step 4: Run Valgrind with Helgrind to detect race conditions\n",
        "!valgrind --tool=helgrind ./buggy_program\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVsNbrJ8Ybf0",
        "outputId": "712d6fe9-fc89-4286-cb54-439378dc2b9f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==90332== Helgrind, a thread error detector\n",
            "==90332== Copyright (C) 2007-2017, and GNU GPL'd, by OpenWorks LLP et al.\n",
            "==90332== Using Valgrind-3.18.1 and LibVEX; rerun with -h for copyright info\n",
            "==90332== Command: ./buggy_program\n",
            "==90332== \n",
            "==90332== ---Thread-Announcement------------------------------------------\n",
            "==90332== \n",
            "==90332== Thread #1 is the program's root thread\n",
            "==90332== \n",
            "==90332== ---Thread-Announcement------------------------------------------\n",
            "==90332== \n",
            "==90332== Thread #2 was created\n",
            "==90332==    at 0x49E79F3: clone (clone.S:76)\n",
            "==90332==    by 0x49E88EE: __clone_internal (clone-internal.c:83)\n",
            "==90332==    by 0x49566D8: create_thread (pthread_create.c:295)\n",
            "==90332==    by 0x49571FF: pthread_create@@GLIBC_2.34 (pthread_create.c:828)\n",
            "==90332==    by 0x4853767: ??? (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x489625F: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x488CA10: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332== \n",
            "==90332== ----------------------------------------------------------------\n",
            "==90332== \n",
            "==90332== Possible data race during write of size 4 at 0x4AED110 by thread #1\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x489866B: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4896756: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x488CA10: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332== \n",
            "==90332== This conflicts with a previous read of size 4 by thread #2\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x48986BA: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895BDA: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x485396A: ??? (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x4956AC2: start_thread (pthread_create.c:442)\n",
            "==90332==    by 0x49E7A03: clone (clone.S:100)\n",
            "==90332==  Address 0x4aed110 is 128 bytes inside a block of size 192 alloc'd\n",
            "==90332==    at 0x484A919: malloc (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x488584C: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895E0B: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x488C9F9: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332==  Block was alloc'd by thread #1\n",
            "==90332== \n",
            "==90332== ----------------------------------------------------------------\n",
            "==90332== \n",
            "==90332== Possible data race during write of size 4 at 0x4AED0D4 by thread #1\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x4898674: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4896756: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x488CA10: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332== \n",
            "==90332== This conflicts with a previous read of size 4 by thread #2\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x48986B4: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895BDA: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x485396A: ??? (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x4956AC2: start_thread (pthread_create.c:442)\n",
            "==90332==    by 0x49E7A03: clone (clone.S:100)\n",
            "==90332==  Address 0x4aed0d4 is 68 bytes inside a block of size 192 alloc'd\n",
            "==90332==    at 0x484A919: malloc (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x488584C: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895E0B: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x488C9F9: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332==  Block was alloc'd by thread #1\n",
            "==90332== \n",
            "==90332== ----------------------------------------------------------------\n",
            "==90332== \n",
            "==90332== Possible data race during read of size 4 at 0x4AED0D4 by thread #2\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x489860B: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895BDA: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x485396A: ??? (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x4956AC2: start_thread (pthread_create.c:442)\n",
            "==90332==    by 0x49E7A03: clone (clone.S:100)\n",
            "==90332== \n",
            "==90332== This conflicts with a previous write of size 4 by thread #1\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x4898674: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4896756: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x488CA10: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332==  Address 0x4aed0d4 is 68 bytes inside a block of size 192 alloc'd\n",
            "==90332==    at 0x484A919: malloc (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x488584C: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895E0B: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x488C9F9: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332==  Block was alloc'd by thread #1\n",
            "==90332== \n",
            "==90332== ----------------------------------------------------------------\n",
            "==90332== \n",
            "==90332== Possible data race during read of size 4 at 0x1FFEFFF720 by thread #2\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x109297: main._omp_fn.0 (buggy_program.c:10)\n",
            "==90332==    by 0x4895C0D: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x485396A: ??? (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x4956AC2: start_thread (pthread_create.c:442)\n",
            "==90332==    by 0x49E7A03: clone (clone.S:100)\n",
            "==90332== \n",
            "==90332== This conflicts with a previous write of size 4 by thread #1\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x1092A2: main._omp_fn.0 (buggy_program.c:10)\n",
            "==90332==    by 0x488CA15: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332==  Address 0x1ffefff720 is on thread #1's stack\n",
            "==90332==  in frame #2, created by main (buggy_program.c:5)\n",
            "==90332== \n",
            "==90332== ----------------------------------------------------------------\n",
            "==90332== \n",
            "==90332== Possible data race during write of size 4 at 0x1FFEFFF720 by thread #2\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x1092A2: main._omp_fn.0 (buggy_program.c:10)\n",
            "==90332==    by 0x4895C0D: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x485396A: ??? (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x4956AC2: start_thread (pthread_create.c:442)\n",
            "==90332==    by 0x49E7A03: clone (clone.S:100)\n",
            "==90332== \n",
            "==90332== This conflicts with a previous write of size 4 by thread #1\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x1092A2: main._omp_fn.0 (buggy_program.c:10)\n",
            "==90332==    by 0x488CA15: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332==  Address 0x1ffefff720 is on thread #1's stack\n",
            "==90332==  in frame #2, created by main (buggy_program.c:5)\n",
            "==90332== \n",
            "==90332== ----------------------------------------------------------------\n",
            "==90332== \n",
            "==90332== Possible data race during write of size 4 at 0x4AED2C4 by thread #2\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x4898926: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895C19: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x485396A: ??? (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x4956AC2: start_thread (pthread_create.c:442)\n",
            "==90332==    by 0x49E7A03: clone (clone.S:100)\n",
            "==90332== \n",
            "==90332== This conflicts with a previous read of size 4 by thread #1\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x489891A: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x489725C: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332==  Address 0x4aed2c4 is 196 bytes inside a block of size 1,792 alloc'd\n",
            "==90332==    at 0x48501A0: memalign (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x48858E8: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895C96: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x488C9F9: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332==  Block was alloc'd by thread #1\n",
            "==90332== \n",
            "==90332== ----------------------------------------------------------------\n",
            "==90332== \n",
            "==90332== Possible data race during write of size 4 at 0x4AED284 by thread #2\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x489888C: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895C19: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x485396A: ??? (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x4956AC2: start_thread (pthread_create.c:442)\n",
            "==90332==    by 0x49E7A03: clone (clone.S:100)\n",
            "==90332== \n",
            "==90332== This conflicts with a previous read of size 4 by thread #1\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x4898914: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x489725C: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332==  Address 0x4aed284 is 132 bytes inside a block of size 1,792 alloc'd\n",
            "==90332==    at 0x48501A0: memalign (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x48858E8: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895C96: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x488C9F9: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332==  Block was alloc'd by thread #1\n",
            "==90332== \n",
            "==90332== ----------------------------------------------------------------\n",
            "==90332== \n",
            "==90332== Possible data race during read of size 4 at 0x4AED110 by thread #2\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x48986BA: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895BE7: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x485396A: ??? (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x4956AC2: start_thread (pthread_create.c:442)\n",
            "==90332==    by 0x49E7A03: clone (clone.S:100)\n",
            "==90332== \n",
            "==90332== This conflicts with a previous write of size 4 by thread #1\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x489866B: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4896756: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x488CA10: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332==  Address 0x4aed110 is 128 bytes inside a block of size 192 alloc'd\n",
            "==90332==    at 0x484A919: malloc (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x488584C: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895E0B: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x488C9F9: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332==  Block was alloc'd by thread #1\n",
            "==90332== \n",
            "==90332== ----------------------------------------------------------------\n",
            "==90332== \n",
            "==90332== Possible data race during read of size 4 at 0x4AED284 by thread #1\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x48987C3: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x489725C: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332== \n",
            "==90332== This conflicts with a previous write of size 4 by thread #2\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x489888C: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895C19: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x485396A: ??? (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x4956AC2: start_thread (pthread_create.c:442)\n",
            "==90332==    by 0x49E7A03: clone (clone.S:100)\n",
            "==90332==  Address 0x4aed284 is 132 bytes inside a block of size 1,792 alloc'd\n",
            "==90332==    at 0x48501A0: memalign (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x48858E8: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895C96: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x488C9F9: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332==  Block was alloc'd by thread #1\n",
            "==90332== \n",
            "==90332== ----------------------------------------------------------------\n",
            "==90332== \n",
            "==90332== Possible data race during read of size 4 at 0x1FFEFFF720 by thread #1\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x109211: main (buggy_program.c:8)\n",
            "==90332== \n",
            "==90332== This conflicts with a previous write of size 4 by thread #2\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x1092A2: main._omp_fn.0 (buggy_program.c:10)\n",
            "==90332==    by 0x4895C0D: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x485396A: ??? (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x4956AC2: start_thread (pthread_create.c:442)\n",
            "==90332==    by 0x49E7A03: clone (clone.S:100)\n",
            "==90332==  Address 0x1ffefff720 is on thread #1's stack\n",
            "==90332==  in frame #0, created by main (buggy_program.c:5)\n",
            "==90332== \n",
            "==90332== ----------------------------------------------------------------\n",
            "==90332== \n",
            "==90332== Possible data race during read of size 4 at 0x4AED0D4 by thread #2\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x489860B: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895BE7: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x485396A: ??? (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x4956AC2: start_thread (pthread_create.c:442)\n",
            "==90332==    by 0x49E7A03: clone (clone.S:100)\n",
            "==90332== \n",
            "==90332== This conflicts with a previous write of size 4 by thread #1\n",
            "==90332== Locks held: none\n",
            "==90332==    at 0x4898674: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4896756: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x488CA10: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332==  Address 0x4aed0d4 is 68 bytes inside a block of size 192 alloc'd\n",
            "==90332==    at 0x484A919: malloc (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so)\n",
            "==90332==    by 0x488584C: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x4895E0B: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x488C9F9: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n",
            "==90332==    by 0x109210: main (buggy_program.c:8)\n",
            "==90332==  Block was alloc'd by thread #1\n",
            "==90332== \n",
            "Result = 4950\n",
            "==90332== \n",
            "==90332== Use --history-level=approx or =none to gain increased speed, at\n",
            "==90332== the cost of reduced accuracy of conflicting-access information\n",
            "==90332== For lists of detected and suppressed errors, rerun with: -s\n",
            "==90332== ERROR SUMMARY: 11 errors from 11 contexts (suppressed: 1 from 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **What Happened:**\n",
        "\n",
        "After running the code, you will see that:\n",
        "- **Valgrind (Helgrind)** ran the program and reported warnings related to data races. The `sum` variable is being accessed by multiple threads without protection, which causes a race condition.\n",
        "  \n",
        "Here is an example of the kind of output you can expect from Valgrind:\n",
        "\n",
        "\n",
        "### **Explanation:**\n",
        "- Valgrind correctly identifies a **data race** in the program at line 7, where the shared variable `sum` is being updated by multiple threads concurrently. Helgrind detects that threads are writing to the `sum` variable without any form of synchronization, and it reports the line number where the issue occurs.\n",
        "\n",
        "This highlights a critical problem in parallel programming: race conditions can lead to incorrect results or crashes, and tools like Valgrind help detect such issues early in development.\n",
        "\n",
        "Next, we will fix the problem by introducing a reduction clause in OpenMP, which ensures the `sum` variable is updated correctly across all threads.\n"
      ],
      "metadata": {
        "id": "YAmFiKllYeFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "#Stop here, this code needs to be reviewed to adapt it to run in cluster and/or Colab\n",
        "\n",
        "---\n",
        "---\n",
        "##Stop here, this code needs to be reviewed to adapt it to run in cluster and/or Colab"
      ],
      "metadata": {
        "id": "eRnAir-xwHLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1lG1SrsHwG-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HPC Checkpointing Example using SCR\n",
        "\n",
        "### Introduction\n",
        "\n",
        "In high-performance computing (HPC), long-running applications are prone to interruptions such as system failures or maintenance windows. Checkpointing is a technique used to save the state of an application at regular intervals so that it can be resumed from the last saved state in case of failure, avoiding the need to restart the computation from the beginning.\n",
        "\n",
        "The **SCR (Scalable Checkpoint/Restart)** library is a lightweight and scalable checkpointing system that allows applications to checkpoint quickly and resume efficiently. It is designed for HPC systems and helps improve application fault tolerance.\n",
        "\n",
        "### Objectives\n",
        "\n",
        "In this notebook, we will:\n",
        "- Understand the concept of checkpointing and why it is essential in HPC.\n",
        "- Learn how to use the SCR library to checkpoint an application.\n",
        "- Use MPI to simulate parallel computing with multiple processes.\n",
        "\n",
        "### What Will Be Covered:\n",
        "- **Checkpointing**: Save the state of an application to a file at specific intervals.\n",
        "- **SCR Library**: Manage checkpoint files efficiently.\n",
        "- **MPI Integration**: Coordinate the checkpointing process across multiple processors.\n",
        "\n",
        "We will run a simple simulation where each process writes its checkpoint data to a file, which can later be used to restart the application from the checkpoint if needed.\n"
      ],
      "metadata": {
        "id": "u1GZ_6PuuQr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Write the checkpointing C code using SCR (mvmult_scr.c)\n",
        "code = \"\"\"\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include \"scr.h\"\n",
        "#include \"mpi.h\"\n",
        "\n",
        "// Function to write a checkpoint\n",
        "int write_checkpoint() {\n",
        "    // Start checkpoint\n",
        "    SCR_Start_checkpoint();\n",
        "\n",
        "    // Get the rank of the process\n",
        "    int rank;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "\n",
        "    // Create a unique checkpoint file for each rank\n",
        "    char file[128];\n",
        "    sprintf(file, \"checkpoint/%d_checkpoint.dat\", rank);\n",
        "\n",
        "    // Open the file for writing\n",
        "    FILE *fp = fopen(file, \"w\");\n",
        "    if (fp == NULL) {\n",
        "        printf(\"Error: Could not open checkpoint file %s\\n\", file);\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    // Route the file through SCR (optional)\n",
        "    char scrfile[SCR_MAX_FILENAME];\n",
        "    SCR_Route_file(file, scrfile);\n",
        "\n",
        "    // Write checkpoint data to file\n",
        "    fprintf(fp, \"Hello Checkpoint World from process %d\\n\", rank);\n",
        "    fclose(fp);\n",
        "\n",
        "    // Mark the checkpoint as valid\n",
        "    int valid = 1;\n",
        "    SCR_Complete_checkpoint(valid);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    // Initialize MPI\n",
        "    MPI_Init(&argc, &argv);\n",
        "\n",
        "    // Initialize SCR\n",
        "    if (SCR_Init() != SCR_SUCCESS) {\n",
        "        printf(\"Error: SCR did not initialize\\n\");\n",
        "        MPI_Finalize();\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    // Simulation loop with checkpointing\n",
        "    int max_steps = 100;\n",
        "    for (int step = 0; step < max_steps; step++) {\n",
        "        // Perform simulation work here...\n",
        "\n",
        "        // Check if it's time to write a checkpoint\n",
        "        int checkpoint_flag;\n",
        "        SCR_Need_checkpoint(&checkpoint_flag);\n",
        "        if (checkpoint_flag) {\n",
        "            write_checkpoint();\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Finalize SCR and MPI\n",
        "    SCR_Finalize();\n",
        "    MPI_Finalize();\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Write the C code to a file\n",
        "with open('mvmult_scr.c', 'w') as f:\n",
        "    f.write(code)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iS0FIMoIZ8KB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Provide Compilation and Running Instructions\n",
        "\n",
        "To compile and run this code on an HPC cluster:\n",
        "\n",
        "1. Load the necessary modules:\n",
        "   ```bash\n",
        "   module load mpi\n",
        "   module load scr\n",
        "   ```\n",
        "\n",
        "Compile the program:\n",
        "   ```bash\n",
        "   mpicc -o mvmult_scr mvmult_scr.c -lscr\n",
        "   ```\n",
        "Run the program with multiple processes:\n",
        "\n",
        "   ```bash\n",
        "   mpirun -np 4 ./mvmult_scr\n",
        "   ```\n",
        "This will simulate a simple application where each process saves a checkpoint file with its state. The checkpointing is handled by SCR, and the program can be restarted from the last valid checkpoint"
      ],
      "metadata": {
        "id": "qtm6wQKNt3zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "   !mpicc -o mvmult_scr mvmult_scr.c -lscr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Puk-R3yvD13",
        "outputId": "d8208b62-7c97-438a-9a01-c26f371454d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[Kmvmult_scr.c:4:10:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Kscr.h: No such file or directory\n",
            "    4 | #include \u001b[01;31m\u001b[K\"scr.h\"\u001b[m\u001b[K\n",
            "      |          \u001b[01;31m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "compilation terminated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !mpirun -np 4 ./mvmult_scr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GySX50uXvHtW",
        "outputId": "ca5fd9c5-f1b9-4d5e-90b5-aee91e206eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------\n",
            "mpirun has detected an attempt to run as root.\n",
            "\n",
            "Running as root is *strongly* discouraged as any mistake (e.g., in\n",
            "defining TMPDIR) or bug can result in catastrophic damage to the OS\n",
            "file system, leaving your system in an unusable state.\n",
            "\n",
            "We strongly suggest that you run mpirun as a non-root user.\n",
            "\n",
            "You can override this protection by adding the --allow-run-as-root option\n",
            "to the cmd line or by setting two environment variables in the following way:\n",
            "the variable OMPI_ALLOW_RUN_AS_ROOT=1 to indicate the desire to override this\n",
            "protection, and OMPI_ALLOW_RUN_AS_ROOT_CONFIRM=1 to confirm the choice and\n",
            "add one more layer of certainty that you want to do so.\n",
            "We reiterate our advice against doing so - please proceed at your own risk.\n",
            "--------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Part 3: Code Explanation (Markdown)\n",
        "\n",
        "### Main Components of the Checkpointing Code\n",
        "\n",
        "1. **MPI Initialization**:\n",
        "   - The program uses MPI (Message Passing Interface) for parallel execution across multiple processors.\n",
        "   - `MPI_Init(&argc, &argv)` initializes the MPI environment.\n",
        "   \n",
        "2. **SCR Initialization**:\n",
        "   - `SCR_Init()` is used to initialize the SCR library. It must be called before any SCR functions can be used.\n",
        "   - If the initialization fails, the program returns an error.\n",
        "\n",
        "3. **Checkpointing Logic**:\n",
        "   - A simple simulation loop is executed with `max_steps` iterations.\n",
        "   - On each iteration, the program checks if it's time to perform a checkpoint using `SCR_Need_checkpoint(&checkpoint_flag)`.\n",
        "   - If a checkpoint is needed, the function `write_checkpoint()` is called, which writes a checkpoint file for each process.\n",
        "\n",
        "4. **Writing the Checkpoint**:\n",
        "   - `SCR_Start_checkpoint()` begins a checkpoint.\n",
        "   - A unique file is created for each MPI process using its rank (e.g., `checkpoint/0_checkpoint.dat`, `checkpoint/1_checkpoint.dat`).\n",
        "   - The file is opened and checkpoint data is written, which is a simple message in this case.\n",
        "   - `SCR_Complete_checkpoint(valid)` marks the checkpoint as valid if it was successful.\n",
        "\n",
        "5. **Finalizing SCR and MPI**:\n",
        "   - `SCR_Finalize()` is called to finalize the SCR library.\n",
        "   - `MPI_Finalize()` is called to clean up the MPI environment after the computation is finished.\n",
        "\n",
        "### Why Checkpointing is Important in HPC\n",
        "\n",
        "- **Fault Tolerance**: Checkpointing allows long-running applications to recover from failures without starting over.\n",
        "- **Scalability**: SCR is designed to work efficiently with large-scale parallel applications, minimizing the overhead of checkpointing.\n",
        "- **Efficiency**: By checkpointing only when necessary, applications can save resources and avoid frequent restarts.\n",
        "\n",
        "This example shows a basic usage of checkpointing in an MPI environment using SCR. The simplicity of the program demonstrates the integration of checkpointing into a larger application and how it can be applied to real-world HPC scenarios.\n"
      ],
      "metadata": {
        "id": "ufz50Upmu8E8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "##Stop here, this code needs to be reviewed to adapt it to run in cluster and/or Colab"
      ],
      "metadata": {
        "id": "cIwCf7nMfeNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tracing with TAU for Detailed Event Logs in HPC Applications\n",
        "\n",
        "In high-performance computing (HPC), tracing provides detailed insights into the dynamic behavior of parallel applications. Unlike profiling, which aggregates performance data, tracing records fine-grained information such as function entries and exits, system calls, and inter-process communication events during program execution.\n",
        "\n",
        "**TAU (Tuning and Analysis Utilities)** is a powerful tool for tracing and profiling parallel applications. It supports various parallel programming models, including **MPI** and **OpenMP**. TAU generates trace files that help developers analyze the behavior of their applications in real-time and identify potential bottlenecks in function calls, communication overhead, and load balancing.\n",
        "\n",
        "This exercise will show how to use TAU to trace a parallel program. We will:\n",
        "1. Compile an MPI-based matrix multiplication program with TAU instrumentation.\n",
        "2. Run the program and capture detailed trace logs.\n",
        "3. Analyze the trace logs to identify function-level and communication-level details.\n",
        "\n",
        "Let’s first create a simple MPI program for matrix multiplication and trace its execution using TAU.\n",
        "\n",
        "**Note:** This example assumes you are working in an HPC environment with TAU already installed. We will also load the TAU module, if available.\n"
      ],
      "metadata": {
        "id": "l3B8-qf_Ndqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If using a cluster with modules (e.g., Magi Castle)\n",
        "!bash -c \"module load tau/2.30.1 && module list\"\n",
        "\n",
        "# TAU is usually not installed via apt-get, so manual installation is required in non-module systems\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4aFxq_COFTL",
        "outputId": "0598c9e5-ea98-4905-c7de-4e70c1b6d225"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bash: line 1: module: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "def run_tau_tracing():\n",
        "    # C code for parallel matrix multiplication with MPI\n",
        "    code = \"\"\"\n",
        "    #include <mpi.h>\n",
        "    #include <stdio.h>\n",
        "    #include <stdlib.h>\n",
        "\n",
        "    #define N 4  // Matrix size (N x N)\n",
        "\n",
        "    void matrix_multiply(double A[N][N], double B[N][N], double C[N][N]) {\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            for (int j = 0; j < N; j++) {\n",
        "                C[i][j] = 0;\n",
        "                for (int k = 0; k < N; k++) {\n",
        "                    C[i][j] += A[i][k] * B[k][j];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    int main(int argc, char** argv) {\n",
        "        MPI_Init(&argc, &argv);  // Initialize MPI\n",
        "\n",
        "        int rank, size;\n",
        "        MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "        MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "\n",
        "        double A[N][N], B[N][N], C[N][N];\n",
        "\n",
        "        // Initialize matrices A and B\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            for (int j = 0; j < N; j++) {\n",
        "                A[i][j] = rank + i + j;\n",
        "                B[i][j] = rank + i - j;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // Perform matrix multiplication\n",
        "        matrix_multiply(A, B, C);\n",
        "\n",
        "        // Print the result matrix from process 0\n",
        "        if (rank == 0) {\n",
        "            printf(\"Matrix C (result):\\\\n\");\n",
        "            for (int i = 0; i < N; i++) {\n",
        "                for (int j = 0; j < N; j++) {\n",
        "                    printf(\"%f \", C[i][j]);\n",
        "                }\n",
        "                printf(\"\\\\n\");\n",
        "            }\n",
        "        }\n",
        "\n",
        "        MPI_Finalize();  // Finalize MPI\n",
        "        return 0;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    # Save the C code to a file\n",
        "    with open(\"mpi_matrix_multiply.c\", \"w\") as file:\n",
        "        file.write(code)\n",
        "\n",
        "    # Load the TAU module, if available\n",
        "    module_check = subprocess.run(\"module list 2>&1 | grep 'tau'\", shell=True, capture_output=True, text=True)\n",
        "    if module_check.stdout:\n",
        "        print(\"TAU module is already loaded.\")\n",
        "    else:\n",
        "        print(\"Loading TAU module...\")\n",
        "        subprocess.run(\"module load tau\", shell=True)\n",
        "\n",
        "    # Compile the C program with TAU instrumentation\n",
        "    compile_command = \"tau_cc -o mpi_matrix_multiply mpi_matrix_multiply.c\"\n",
        "    compile_result = subprocess.run(compile_command, shell=True, capture_output=True, text=True)\n",
        "\n",
        "    if compile_result.returncode != 0:\n",
        "        print(f\"Compilation failed:\\n{compile_result.stderr}\")\n",
        "        return\n",
        "    else:\n",
        "        print(\"Compilation successful.\")\n",
        "\n",
        "    # Run the MPI program with TAU tracing\n",
        "    tau_run_command = \"tau_exec -T mpi -ebs mpirun -np 4 ./mpi_matrix_multiply\"\n",
        "    tau_run_result = subprocess.run(tau_run_command, shell=True, capture_output=True, text=True)\n",
        "\n",
        "    if tau_run_result.returncode != 0:\n",
        "        print(f\"TAU execution failed:\\n{tau_run_result.stderr}\")\n",
        "    else:\n",
        "        print(\"TAU tracing complete. Trace files generated.\")\n",
        "        print(tau_run_result.stdout)\n",
        "\n",
        "# Run the function to compile and trace the MPI program using TAU\n",
        "run_tau_tracing()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUwnWt-zNmRH",
        "outputId": "65391236-3935-4f5b-dec4-ce68ef0bb3e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading TAU module...\n",
            "Compilation failed:\n",
            "/bin/sh: 1: tau_cc: not found\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MPI Matrix Multiplication with TAU Profiling\n",
        "\n",
        "In this section, we will write, compile, and run an MPI-based matrix multiplication program. We will also use **TAU** for tracing and profiling the performance of this parallel program. TAU provides comprehensive tools for analyzing parallel programs, which can be used to capture function calls, communication patterns, and time spent in different parts of the code.\n",
        "\n",
        "### Steps:\n",
        "1. **Write the MPI Matrix Multiplication Code**: This program will perform matrix multiplication using MPI.\n",
        "2. **Load TAU Module**: We'll check if the TAU module is available and load it.\n",
        "3. **Compile the Code with TAU**: The program will be compiled using `tau_cc` to enable tracing and profiling.\n",
        "4. **Run the Program**: We will execute the program with TAU, and collect tracing data.\n",
        "5. **View the Profiling Results**: The profiling results will be saved for further analysis.\n",
        "\n",
        "Let's begin by writing and saving the C code for the program.\n"
      ],
      "metadata": {
        "id": "LN70oxtiRFEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "def run_tau_tracing():\n",
        "    # C code for parallel matrix multiplication with MPI\n",
        "    code = \"\"\"\n",
        "    #include <mpi.h>\n",
        "    #include <stdio.h>\n",
        "    #include <stdlib.h>\n",
        "\n",
        "    #define N 4  // Matrix size (N x N)\n",
        "\n",
        "    void matrix_multiply(double A[N][N], double B[N][N], double C[N][N]) {\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            for (int j = 0; j < N; j++) {\n",
        "                C[i][j] = 0;\n",
        "                for (int k = 0; k < N; k++) {\n",
        "                    C[i][j] += A[i][k] * B[k][j];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    int main(int argc, char** argv) {\n",
        "        MPI_Init(&argc, &argv);  // Initialize MPI\n",
        "\n",
        "        int rank, size;\n",
        "        MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "        MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "\n",
        "        double A[N][N], B[N][N], C[N][N];\n",
        "\n",
        "        // Initialize matrices A and B\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            for (int j = 0; j < N; j++) {\n",
        "                A[i][j] = rank + i + j;\n",
        "                B[i][j] = rank + i - j;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // Perform matrix multiplication\n",
        "        matrix_multiply(A, B, C);\n",
        "\n",
        "        // Print the result matrix from process 0\n",
        "        if (rank == 0) {\n",
        "            printf(\"Matrix C (result):\\\\n\");\n",
        "            for (int i = 0; i < N; i++) {\n",
        "                for (int j = 0; j < N; j++) {\n",
        "                    printf(\"%f \", C[i][j]);\n",
        "                }\n",
        "                printf(\"\\\\n\");\n",
        "            }\n",
        "        }\n",
        "\n",
        "        MPI_Finalize();  // Finalize MPI\n",
        "        return 0;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    # Save the C code to a file\n",
        "    with open(\"mpi_matrix_multiply.c\", \"w\") as file:\n",
        "        file.write(code)\n",
        "\n",
        "    print(\"MPI Matrix Multiplication code saved as mpi_matrix_multiply.c\")\n",
        "\n",
        "# Run the function to save the code\n",
        "run_tau_tracing()\n",
        "\n",
        "# Load TAU module, compile with TAU, and execute\n",
        "# If running this on an HPC cluster\n",
        "load_tau_and_compile = \"\"\"\n",
        "!bash -c \"module load tau/2.30.1 && tau_cc -o mpi_matrix_multiply mpi_matrix_multiply.c && mpirun -np 4 ./mpi_matrix_multiply\"\n",
        "\"\"\"\n",
        "# Execute the commands\n",
        "subprocess.run(load_tau_and_compile, shell=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdqF3IEqRDcF",
        "outputId": "2b786666-4b61-4b62-f279-c95a201cfa77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MPI Matrix Multiplication code saved as mpi_matrix_multiply.c\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args='\\n!bash -c \"module load tau/2.30.1 && tau_cc -o mpi_matrix_multiply mpi_matrix_multiply.c && mpirun -np 4 ./mpi_matrix_multiply\"\\n', returncode=127)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MPI Matrix Multiplication code saved as mpi_matrix_multiply.c\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args='\\n!bash -c \"module load tau/2.30.1 && tau_cc -o mpi_matrix_multiply mpi_matrix_multiply.c && mpirun -np 4 ./mpi_matrix_multiply\"\\n', returncode=127)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Function to write and save MPI matrix multiplication C code\n",
        "def run_tau_tracing():\n",
        "    # C code for parallel matrix multiplication with MPI\n",
        "    code = \"\"\"\n",
        "    #include <mpi.h>\n",
        "    #include <stdio.h>\n",
        "    #include <stdlib.h>\n",
        "\n",
        "    #define N 4  // Matrix size (N x N)\n",
        "\n",
        "    void matrix_multiply(double A[N][N], double B[N][N], double C[N][N]) {\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            for (int j = 0; j < N; j++) {\n",
        "                C[i][j] = 0;\n",
        "                for (int k = 0; k < N; k++) {\n",
        "                    C[i][j] += A[i][k] * B[k][j];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    int main(int argc, char** argv) {\n",
        "        MPI_Init(&argc, &argv);  // Initialize MPI\n",
        "\n",
        "        int rank, size;\n",
        "        MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "        MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "\n",
        "        double A[N][N], B[N][N], C[N][N];\n",
        "\n",
        "        // Initialize matrices A and B\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            for (int j = 0; j < N; j++) {\n",
        "                A[i][j] = rank + i + j;\n",
        "                B[i][j] = rank + i - j;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // Perform matrix multiplication\n",
        "        matrix_multiply(A, B, C);\n",
        "\n",
        "        // Print the result matrix from process 0\n",
        "        if (rank == 0) {\n",
        "            printf(\"Matrix C (result):\\\\n\");\n",
        "            for (int i = 0; i < N; i++) {\n",
        "                for (int j = 0; j < N; j++) {\n",
        "                    printf(\"%f \", C[i][j]);\n",
        "                }\n",
        "                printf(\"\\\\n\");\n",
        "            }\n",
        "        }\n",
        "\n",
        "        MPI_Finalize();  // Finalize MPI\n",
        "        return 0;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    # Save the C code to a file\n",
        "    with open(\"mpi_matrix_multiply.c\", \"w\") as file:\n",
        "        file.write(code)\n",
        "\n",
        "    print(\"MPI Matrix Multiplication code saved as mpi_matrix_multiply.c\")\n",
        "\n",
        "# Run the function to save the code\n",
        "run_tau_tracing()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V2cGlhBZqNJ",
        "outputId": "135d28ab-daef-4783-e20d-1d677b3388b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MPI Matrix Multiplication code saved as mpi_matrix_multiply.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TAU module, compile the C program with TAU, and execute it using MPI\n",
        "# If running this on an HPC cluster\n",
        "load_tau_and_compile = \"\"\"\n",
        "!bash -c \"module load tau/2.30.1 && tau_cc -o mpi_matrix_multiply mpi_matrix_multiply.c && mpirun -np 4 ./mpi_matrix_multiply\"\n",
        "\"\"\"\n",
        "# Execute the commands\n",
        "subprocess.run(load_tau_and_compile, shell=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD3e0QumZtPr",
        "outputId": "fe89a285-91e8-43e5-967e-a30654d09240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args='\\n!bash -c \"module load tau/2.30.1 && tau_cc -o mpi_matrix_multiply mpi_matrix_multiply.c && mpirun -np 4 ./mpi_matrix_multiply\"\\n', returncode=127)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TAU Tracing Explanation\n",
        "\n",
        "In this example, we used **TAU (Tuning and Analysis Utilities)** to trace a parallel matrix multiplication program written in C with **MPI (Message Passing Interface)**. The program was compiled with TAU's instrumentation using the `tau_cc` compiler, and executed with `tau_exec` to capture detailed trace logs.\n",
        "\n",
        "Here’s what happened:\n",
        "1. **Matrix Multiplication with MPI**: The program multiplies two matrices (4x4 in size) in parallel using multiple MPI processes. Each process computes the product based on its rank.\n",
        "2. **TAU Instrumentation**: By using the `tau_cc` compiler and `tau_exec` command, the program was instrumented for tracing. TAU collects detailed information about the program’s execution, including function entries/exits, communication events, and system calls made by each MPI process.\n",
        "3. **Trace Files**: TAU generates trace files that can be analyzed using TAU's analysis tools or other visualization tools like ParaProf. These files contain event logs that show the timing and interaction between MPI processes during the execution.\n",
        "\n",
        "#### Why Tracing is Important\n",
        "Tracing allows developers to gain fine-grained insights into how their programs behave at runtime. In parallel computing, it is often difficult to identify performance bottlenecks just by looking at the source code. Tracing helps by:\n",
        "- Providing detailed event logs, showing exactly where the program spends time.\n",
        "- Identifying function call hierarchies and how they contribute to total execution time.\n",
        "- Highlighting communication patterns and any delays caused by process synchronization or message-passing overhead.\n",
        "  \n",
        "For example, if one MPI process takes significantly longer to complete its work due to poor load balancing, tracing will reveal that process’s timeline, allowing developers to optimize accordingly.\n",
        "\n",
        "In this specific case, by analyzing the generated trace files, you can pinpoint where the matrix multiplication operation consumes time and see how the different MPI processes communicate during execution.\n",
        "\n",
        "### What You Should Expect:\n",
        "- **Trace Logs**: The logs will include entries showing when the matrix multiplication function was called, how much time each process spent in computation, and how communication was handled.\n",
        "- **Visualization Tools**: These trace logs can be visualized using tools like TAU’s **ParaProf** to better understand performance issues such as process imbalance, synchronization delays, and inefficient communication patterns.\n"
      ],
      "metadata": {
        "id": "p0ADtWF7N4YS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "m36M0Ig7Nl1A",
        "outputId": "5ba60437-8031-4c75-e355-bc123bc67bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 3) (<ipython-input-31-d0361b7ab68f>, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-d0361b7ab68f>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    In this example, we used **TAU (Tuning and Analysis Utilities)** to trace a parallel matrix multiplication program written in C with **MPI (Message Passing Interface)**. The program was compiled with TAU's instrumentation using the `tau_cc` compiler, and executed with `tau_exec` to capture detailed trace logs.\u001b[0m\n\u001b[0m                                                                                                                                                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling Profiling with `perf`\n",
        "\n",
        "### Introduction to Sampling Profiling\n",
        "\n",
        "In high-performance computing (HPC), sampling is one of the most common techniques used for profiling applications. Sampling-based profiling periodically checks the state of the program's execution and collects information about which functions are currently running. This method helps developers identify which functions consume the most CPU time, allowing them to focus their optimization efforts on the \"hot spots\" or areas where the most time is spent.\n",
        "\n",
        "In this exercise, we'll be using the `perf` tool, which is widely available on Linux systems, to perform sampling-based profiling of a C++ program. We will write, compile, and run a simple C++ program that processes a large dataset and then use `perf` to collect profiling data and identify which parts of the program are the most time-consuming.\n",
        "\n",
        "### Steps to follow:\n",
        "1. **Write and Compile a C++ Program**: We will write a C++ program that processes a vector of data.\n",
        "2. **Use `perf` to Profile the Program**: We will run the program with `perf` to collect sampling data and analyze the program's performance.\n",
        "3. **Interpret the Results**: After running `perf`, we will interpret the profiling report to identify performance bottlenecks.\n",
        "\n",
        "### Code to Run\n",
        "\n",
        "Below is the code that will save, compile, and execute a C++ program to demonstrate sampling profiling. After execution, we will use the `perf` tool to generate a performance report.\n",
        "\n"
      ],
      "metadata": {
        "id": "MQEz9CVJR5N-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#]check if perf is installed, if not run the next command to install it\n",
        "!perf --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-03vMeaWrRn",
        "outputId": "473a0b37-e1e5-457b-ec02-ddc77792e1a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: perf: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will install perf. Execute this only if perf is not in the system\n",
        "# Update the package list\n",
        "!apt-get update\n",
        "!apt-cache search linux-tools\n",
        "!sudo apt-get install linux-tools-common linux-tools-generic\n",
        "\n",
        "!sudo apt-get install git\n",
        "!git clone git://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git\n",
        "!cd linux/tools/perf\n",
        "!make\n",
        "!sudo cp perf /usr/local/bin/\n",
        "\n",
        "# Install perf\n",
        "#!sudo apt-get install linux-tools-6.1.85+-6.1.85+ linux-cloud-tools-6.1.85+-6.1.85+\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJqgwMp_VMhu",
        "outputId": "646e4428-f1e4-4dd1-cbb8-a88eae0991ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Ign:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 129 kB in 1s (97.4 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "linux-tools-5.15.0-1002-gke - Linux kernel version specific tools for version 5.15.0-1002\n",
            "linux-tools-5.15.0-1002-ibm - Linux kernel version specific tools for version 5.15.0-1002\n",
            "linux-tools-5.15.0-1002-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1002\n",
            "linux-tools-5.15.0-1003-azure - Linux kernel version specific tools for version 5.15.0-1003\n",
            "linux-tools-5.15.0-1003-gcp - Linux kernel version specific tools for version 5.15.0-1003\n",
            "linux-tools-5.15.0-1004-aws - Linux kernel version specific tools for version 5.15.0-1004\n",
            "linux-tools-5.15.0-1004-intel-iotg - Linux kernel version specific tools for version 5.15.0-1004\n",
            "linux-tools-5.15.0-1004-kvm - Linux kernel version specific tools for version 5.15.0-1004\n",
            "linux-tools-5.15.0-24-lowlatency - Linux kernel version specific tools for version 5.15.0-24\n",
            "linux-tools-5.15.0-25 - Linux kernel version specific tools for version 5.15.0-25\n",
            "linux-tools-5.15.0-25-generic - Linux kernel version specific tools for version 5.15.0-25\n",
            "linux-tools-5.17.0-1003-oem - Linux kernel version specific tools for version 5.17.0-1003\n",
            "linux-tools-aws - Linux kernel versioned tools for Amazon Web Services (AWS) systems.\n",
            "linux-tools-azure - Linux kernel versioned tools for Azure systems.\n",
            "linux-tools-common - Linux kernel version specific tools for version 5.15.0\n",
            "linux-tools-gcp - Google Cloud Platform (GCP) Linux kernel tools\n",
            "linux-tools-generic - Generic Linux kernel tools\n",
            "linux-tools-generic-hwe-20.04 - Generic Linux kernel tools (dummy transitional package)\n",
            "linux-tools-generic-hwe-20.04-edge - Generic Linux kernel tools (dummy transitional package)\n",
            "linux-tools-generic-hwe-22.04 - Generic Linux kernel tools\n",
            "linux-tools-generic-hwe-22.04-edge - Generic Linux kernel tools\n",
            "linux-tools-gke - Linux kernel versioned tools for gke systems.\n",
            "linux-tools-gke-5.15 - Linux kernel versioned tools for gke systems.\n",
            "linux-tools-host - Linux kernel VM host tools\n",
            "linux-tools-ibm - IBM Cloud Platform (ibm) Linux kernel tools\n",
            "linux-tools-intel-iotg - Intel-Iotg Linux kernel tools\n",
            "linux-tools-kvm - Linux kernel versioned tools for virtual systems.\n",
            "linux-tools-lowlatency - lowlatency Linux kernel tools\n",
            "linux-tools-lowlatency-hwe-20.04 - lowlatency Linux kernel tools (dummy transitional package)\n",
            "linux-tools-lowlatency-hwe-20.04-edge - lowlatency Linux kernel tools (dummy transitional package)\n",
            "linux-tools-lowlatency-hwe-22.04 - lowlatency Linux kernel tools\n",
            "linux-tools-lowlatency-hwe-22.04-edge - lowlatency Linux kernel tools\n",
            "linux-tools-oem-20.04 - OEM Linux kernel tools (dummy transitional package)\n",
            "linux-tools-oracle - Linux kernel versioned tools for Oracle systems.\n",
            "linux-tools-virtual - Virtual Linux kernel tools\n",
            "linux-tools-virtual-hwe-20.04 - Virtual Linux kernel tools (dummy transitional package)\n",
            "linux-tools-virtual-hwe-20.04-edge - Virtual Linux kernel tools (dummy transitional package)\n",
            "linux-tools-virtual-hwe-22.04 - Virtual Linux kernel tools\n",
            "linux-tools-virtual-hwe-22.04-edge - Virtual Linux kernel tools\n",
            "linux-tools-5.15.0-100 - Linux kernel version specific tools for version 5.15.0-100\n",
            "linux-tools-5.15.0-100-generic - Linux kernel version specific tools for version 5.15.0-100\n",
            "linux-tools-5.15.0-100-lowlatency - Linux kernel version specific tools for version 5.15.0-100\n",
            "linux-tools-5.15.0-101 - Linux kernel version specific tools for version 5.15.0-101\n",
            "linux-tools-5.15.0-101-generic - Linux kernel version specific tools for version 5.15.0-101\n",
            "linux-tools-5.15.0-101-lowlatency - Linux kernel version specific tools for version 5.15.0-101\n",
            "linux-tools-5.15.0-102 - Linux kernel version specific tools for version 5.15.0-102\n",
            "linux-tools-5.15.0-102-generic - Linux kernel version specific tools for version 5.15.0-102\n",
            "linux-tools-5.15.0-102-lowlatency - Linux kernel version specific tools for version 5.15.0-102\n",
            "linux-tools-5.15.0-1025-nvidia - Linux kernel version specific tools for version 5.15.0-1025\n",
            "linux-tools-5.15.0-1025-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1025\n",
            "linux-tools-5.15.0-1026-nvidia - Linux kernel version specific tools for version 5.15.0-1026\n",
            "linux-tools-5.15.0-1026-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1026\n",
            "linux-tools-5.15.0-1027-gke - Linux kernel version specific tools for version 5.15.0-1027\n",
            "linux-tools-5.15.0-1027-nvidia - Linux kernel version specific tools for version 5.15.0-1027\n",
            "linux-tools-5.15.0-1027-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1027\n",
            "linux-tools-5.15.0-1028-gke - Linux kernel version specific tools for version 5.15.0-1028\n",
            "linux-tools-5.15.0-1028-intel-iotg - Linux kernel version specific tools for version 5.15.0-1028\n",
            "linux-tools-5.15.0-1028-nvidia - Linux kernel version specific tools for version 5.15.0-1028\n",
            "linux-tools-5.15.0-1028-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1028\n",
            "linux-tools-5.15.0-1029-nvidia - Linux kernel version specific tools for version 5.15.0-1029\n",
            "linux-tools-5.15.0-1029-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1029\n",
            "linux-tools-5.15.0-1030-gke - Linux kernel version specific tools for version 5.15.0-1030\n",
            "linux-tools-5.15.0-1030-ibm - Linux kernel version specific tools for version 5.15.0-1030\n",
            "linux-tools-5.15.0-1030-intel-iotg - Linux kernel version specific tools for version 5.15.0-1030\n",
            "linux-tools-5.15.0-1030-nvidia - Linux kernel version specific tools for version 5.15.0-1030\n",
            "linux-tools-5.15.0-1030-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1030\n",
            "linux-tools-5.15.0-1031-ibm - Linux kernel version specific tools for version 5.15.0-1031\n",
            "linux-tools-5.15.0-1031-intel-iotg - Linux kernel version specific tools for version 5.15.0-1031\n",
            "linux-tools-5.15.0-1031-nvidia - Linux kernel version specific tools for version 5.15.0-1031\n",
            "linux-tools-5.15.0-1031-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1031\n",
            "linux-tools-5.15.0-1032-gke - Linux kernel version specific tools for version 5.15.0-1032\n",
            "linux-tools-5.15.0-1032-gkeop - Linux kernel version specific tools for version 5.15.0-1032\n",
            "linux-tools-5.15.0-1032-ibm - Linux kernel version specific tools for version 5.15.0-1032\n",
            "linux-tools-5.15.0-1032-nvidia - Linux kernel version specific tools for version 5.15.0-1032\n",
            "linux-tools-5.15.0-1032-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1032\n",
            "linux-tools-5.15.0-1033-gke - Linux kernel version specific tools for version 5.15.0-1033\n",
            "linux-tools-5.15.0-1033-gkeop - Linux kernel version specific tools for version 5.15.0-1033\n",
            "linux-tools-5.15.0-1033-ibm - Linux kernel version specific tools for version 5.15.0-1033\n",
            "linux-tools-5.15.0-1033-intel-iotg - Linux kernel version specific tools for version 5.15.0-1033\n",
            "linux-tools-5.15.0-1033-kvm - Linux kernel version specific tools for version 5.15.0-1033\n",
            "linux-tools-5.15.0-1033-nvidia - Linux kernel version specific tools for version 5.15.0-1033\n",
            "linux-tools-5.15.0-1033-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1033\n",
            "linux-tools-5.15.0-1034-gcp - Linux kernel version specific tools for version 5.15.0-1034\n",
            "linux-tools-5.15.0-1034-gke - Linux kernel version specific tools for version 5.15.0-1034\n",
            "linux-tools-5.15.0-1034-gkeop - Linux kernel version specific tools for version 5.15.0-1034\n",
            "linux-tools-5.15.0-1034-ibm - Linux kernel version specific tools for version 5.15.0-1034\n",
            "linux-tools-5.15.0-1034-intel-iotg - Linux kernel version specific tools for version 5.15.0-1034\n",
            "linux-tools-5.15.0-1034-kvm - Linux kernel version specific tools for version 5.15.0-1034\n",
            "linux-tools-5.15.0-1035-aws - Linux kernel version specific tools for version 5.15.0-1035\n",
            "linux-tools-5.15.0-1035-azure - Linux kernel version specific tools for version 5.15.0-1035\n",
            "linux-tools-5.15.0-1035-gcp - Linux kernel version specific tools for version 5.15.0-1035\n",
            "linux-tools-5.15.0-1035-gke - Linux kernel version specific tools for version 5.15.0-1035\n",
            "linux-tools-5.15.0-1035-gkeop - Linux kernel version specific tools for version 5.15.0-1035\n",
            "linux-tools-5.15.0-1035-ibm - Linux kernel version specific tools for version 5.15.0-1035\n",
            "linux-tools-5.15.0-1035-intel-iotg - Linux kernel version specific tools for version 5.15.0-1035\n",
            "linux-tools-5.15.0-1035-kvm - Linux kernel version specific tools for version 5.15.0-1035\n",
            "linux-tools-5.15.0-1035-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1035\n",
            "linux-tools-5.15.0-1036-aws - Linux kernel version specific tools for version 5.15.0-1036\n",
            "linux-tools-5.15.0-1036-azure - Linux kernel version specific tools for version 5.15.0-1036\n",
            "linux-tools-5.15.0-1036-gcp - Linux kernel version specific tools for version 5.15.0-1036\n",
            "linux-tools-5.15.0-1036-gke - Linux kernel version specific tools for version 5.15.0-1036\n",
            "linux-tools-5.15.0-1036-gkeop - Linux kernel version specific tools for version 5.15.0-1036\n",
            "linux-tools-5.15.0-1036-ibm - Linux kernel version specific tools for version 5.15.0-1036\n",
            "linux-tools-5.15.0-1036-intel-iotg - Linux kernel version specific tools for version 5.15.0-1036\n",
            "linux-tools-5.15.0-1036-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1036\n",
            "linux-tools-5.15.0-1037-aws - Linux kernel version specific tools for version 5.15.0-1037\n",
            "linux-tools-5.15.0-1037-azure - Linux kernel version specific tools for version 5.15.0-1037\n",
            "linux-tools-5.15.0-1037-gcp - Linux kernel version specific tools for version 5.15.0-1037\n",
            "linux-tools-5.15.0-1037-gke - Linux kernel version specific tools for version 5.15.0-1037\n",
            "linux-tools-5.15.0-1037-gkeop - Linux kernel version specific tools for version 5.15.0-1037\n",
            "linux-tools-5.15.0-1037-ibm - Linux kernel version specific tools for version 5.15.0-1037\n",
            "linux-tools-5.15.0-1037-intel-iotg - Linux kernel version specific tools for version 5.15.0-1037\n",
            "linux-tools-5.15.0-1037-kvm - Linux kernel version specific tools for version 5.15.0-1037\n",
            "linux-tools-5.15.0-1037-nvidia - Linux kernel version specific tools for version 5.15.0-1037\n",
            "linux-tools-5.15.0-1037-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1037\n",
            "linux-tools-5.15.0-1037-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1037\n",
            "linux-tools-5.15.0-1038-aws - Linux kernel version specific tools for version 5.15.0-1038\n",
            "linux-tools-5.15.0-1038-azure - Linux kernel version specific tools for version 5.15.0-1038\n",
            "linux-tools-5.15.0-1038-gcp - Linux kernel version specific tools for version 5.15.0-1038\n",
            "linux-tools-5.15.0-1038-gke - Linux kernel version specific tools for version 5.15.0-1038\n",
            "linux-tools-5.15.0-1038-gkeop - Linux kernel version specific tools for version 5.15.0-1038\n",
            "linux-tools-5.15.0-1038-ibm - Linux kernel version specific tools for version 5.15.0-1038\n",
            "linux-tools-5.15.0-1038-intel-iotg - Linux kernel version specific tools for version 5.15.0-1038\n",
            "linux-tools-5.15.0-1038-kvm - Linux kernel version specific tools for version 5.15.0-1038\n",
            "linux-tools-5.15.0-1038-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1038\n",
            "linux-tools-5.15.0-1039-aws - Linux kernel version specific tools for version 5.15.0-1039\n",
            "linux-tools-5.15.0-1039-azure - Linux kernel version specific tools for version 5.15.0-1039\n",
            "linux-tools-5.15.0-1039-gcp - Linux kernel version specific tools for version 5.15.0-1039\n",
            "linux-tools-5.15.0-1039-gke - Linux kernel version specific tools for version 5.15.0-1039\n",
            "linux-tools-5.15.0-1039-gkeop - Linux kernel version specific tools for version 5.15.0-1039\n",
            "linux-tools-5.15.0-1039-intel-iotg - Linux kernel version specific tools for version 5.15.0-1039\n",
            "linux-tools-5.15.0-1039-kvm - Linux kernel version specific tools for version 5.15.0-1039\n",
            "linux-tools-5.15.0-1039-nvidia - Linux kernel version specific tools for version 5.15.0-1039\n",
            "linux-tools-5.15.0-1039-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1039\n",
            "linux-tools-5.15.0-1039-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1039\n",
            "linux-tools-5.15.0-1040-aws - Linux kernel version specific tools for version 5.15.0-1040\n",
            "linux-tools-5.15.0-1040-azure - Linux kernel version specific tools for version 5.15.0-1040\n",
            "linux-tools-5.15.0-1040-gcp - Linux kernel version specific tools for version 5.15.0-1040\n",
            "linux-tools-5.15.0-1040-gke - Linux kernel version specific tools for version 5.15.0-1040\n",
            "linux-tools-5.15.0-1040-gkeop - Linux kernel version specific tools for version 5.15.0-1040\n",
            "linux-tools-5.15.0-1040-ibm - Linux kernel version specific tools for version 5.15.0-1040\n",
            "linux-tools-5.15.0-1040-intel-iotg - Linux kernel version specific tools for version 5.15.0-1040\n",
            "linux-tools-5.15.0-1040-kvm - Linux kernel version specific tools for version 5.15.0-1040\n",
            "linux-tools-5.15.0-1040-nvidia - Linux kernel version specific tools for version 5.15.0-1040\n",
            "linux-tools-5.15.0-1040-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1040\n",
            "linux-tools-5.15.0-1040-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1040\n",
            "linux-tools-5.15.0-1041-azure - Linux kernel version specific tools for version 5.15.0-1041\n",
            "linux-tools-5.15.0-1041-gcp - Linux kernel version specific tools for version 5.15.0-1041\n",
            "linux-tools-5.15.0-1041-gke - Linux kernel version specific tools for version 5.15.0-1041\n",
            "linux-tools-5.15.0-1041-ibm - Linux kernel version specific tools for version 5.15.0-1041\n",
            "linux-tools-5.15.0-1041-kvm - Linux kernel version specific tools for version 5.15.0-1041\n",
            "linux-tools-5.15.0-1041-nvidia - Linux kernel version specific tools for version 5.15.0-1041\n",
            "linux-tools-5.15.0-1041-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1041\n",
            "linux-tools-5.15.0-1041-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1041\n",
            "linux-tools-5.15.0-1042-aws - Linux kernel version specific tools for version 5.15.0-1042\n",
            "linux-tools-5.15.0-1042-azure - Linux kernel version specific tools for version 5.15.0-1042\n",
            "linux-tools-5.15.0-1042-gcp - Linux kernel version specific tools for version 5.15.0-1042\n",
            "linux-tools-5.15.0-1042-gke - Linux kernel version specific tools for version 5.15.0-1042\n",
            "linux-tools-5.15.0-1042-ibm - Linux kernel version specific tools for version 5.15.0-1042\n",
            "linux-tools-5.15.0-1042-kvm - Linux kernel version specific tools for version 5.15.0-1042\n",
            "linux-tools-5.15.0-1042-nvidia - Linux kernel version specific tools for version 5.15.0-1042\n",
            "linux-tools-5.15.0-1042-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1042\n",
            "linux-tools-5.15.0-1042-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1042\n",
            "linux-tools-5.15.0-1043-aws - Linux kernel version specific tools for version 5.15.0-1043\n",
            "linux-tools-5.15.0-1043-gkeop - Linux kernel version specific tools for version 5.15.0-1043\n",
            "linux-tools-5.15.0-1043-ibm - Linux kernel version specific tools for version 5.15.0-1043\n",
            "linux-tools-5.15.0-1043-intel-iotg - Linux kernel version specific tools for version 5.15.0-1043\n",
            "linux-tools-5.15.0-1043-nvidia - Linux kernel version specific tools for version 5.15.0-1043\n",
            "linux-tools-5.15.0-1043-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1043\n",
            "linux-tools-5.15.0-1044-aws - Linux kernel version specific tools for version 5.15.0-1044\n",
            "linux-tools-5.15.0-1044-azure - Linux kernel version specific tools for version 5.15.0-1044\n",
            "linux-tools-5.15.0-1044-gcp - Linux kernel version specific tools for version 5.15.0-1044\n",
            "linux-tools-5.15.0-1044-gke - Linux kernel version specific tools for version 5.15.0-1044\n",
            "linux-tools-5.15.0-1044-gkeop - Linux kernel version specific tools for version 5.15.0-1044\n",
            "linux-tools-5.15.0-1044-ibm - Linux kernel version specific tools for version 5.15.0-1044\n",
            "linux-tools-5.15.0-1044-kvm - Linux kernel version specific tools for version 5.15.0-1044\n",
            "linux-tools-5.15.0-1044-nvidia - Linux kernel version specific tools for version 5.15.0-1044\n",
            "linux-tools-5.15.0-1044-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1044\n",
            "linux-tools-5.15.0-1044-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1044\n",
            "linux-tools-5.15.0-1045-aws - Linux kernel version specific tools for version 5.15.0-1045\n",
            "linux-tools-5.15.0-1045-azure - Linux kernel version specific tools for version 5.15.0-1045\n",
            "linux-tools-5.15.0-1045-gcp - Linux kernel version specific tools for version 5.15.0-1045\n",
            "linux-tools-5.15.0-1045-gke - Linux kernel version specific tools for version 5.15.0-1045\n",
            "linux-tools-5.15.0-1045-gkeop - Linux kernel version specific tools for version 5.15.0-1045\n",
            "linux-tools-5.15.0-1045-ibm - Linux kernel version specific tools for version 5.15.0-1045\n",
            "linux-tools-5.15.0-1045-intel-iotg - Linux kernel version specific tools for version 5.15.0-1045\n",
            "linux-tools-5.15.0-1045-kvm - Linux kernel version specific tools for version 5.15.0-1045\n",
            "linux-tools-5.15.0-1045-nvidia - Linux kernel version specific tools for version 5.15.0-1045\n",
            "linux-tools-5.15.0-1045-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1045\n",
            "linux-tools-5.15.0-1045-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1045\n",
            "linux-tools-5.15.0-1046-azure - Linux kernel version specific tools for version 5.15.0-1046\n",
            "linux-tools-5.15.0-1046-gcp - Linux kernel version specific tools for version 5.15.0-1046\n",
            "linux-tools-5.15.0-1046-gke - Linux kernel version specific tools for version 5.15.0-1046\n",
            "linux-tools-5.15.0-1046-gkeop - Linux kernel version specific tools for version 5.15.0-1046\n",
            "linux-tools-5.15.0-1046-ibm - Linux kernel version specific tools for version 5.15.0-1046\n",
            "linux-tools-5.15.0-1046-intel-iotg - Linux kernel version specific tools for version 5.15.0-1046\n",
            "linux-tools-5.15.0-1046-kvm - Linux kernel version specific tools for version 5.15.0-1046\n",
            "linux-tools-5.15.0-1046-nvidia - Linux kernel version specific tools for version 5.15.0-1046\n",
            "linux-tools-5.15.0-1046-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1046\n",
            "linux-tools-5.15.0-1046-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1046\n",
            "linux-tools-5.15.0-1047-aws - Linux kernel version specific tools for version 5.15.0-1047\n",
            "linux-tools-5.15.0-1047-azure - Linux kernel version specific tools for version 5.15.0-1047\n",
            "linux-tools-5.15.0-1047-gcp - Linux kernel version specific tools for version 5.15.0-1047\n",
            "linux-tools-5.15.0-1047-gke - Linux kernel version specific tools for version 5.15.0-1047\n",
            "linux-tools-5.15.0-1047-gkeop - Linux kernel version specific tools for version 5.15.0-1047\n",
            "linux-tools-5.15.0-1047-ibm - Linux kernel version specific tools for version 5.15.0-1047\n",
            "linux-tools-5.15.0-1047-intel-iotg - Linux kernel version specific tools for version 5.15.0-1047\n",
            "linux-tools-5.15.0-1047-kvm - Linux kernel version specific tools for version 5.15.0-1047\n",
            "linux-tools-5.15.0-1047-nvidia - Linux kernel version specific tools for version 5.15.0-1047\n",
            "linux-tools-5.15.0-1047-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1047\n",
            "linux-tools-5.15.0-1047-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1047\n",
            "linux-tools-5.15.0-1048-aws - Linux kernel version specific tools for version 5.15.0-1048\n",
            "linux-tools-5.15.0-1048-gcp - Linux kernel version specific tools for version 5.15.0-1048\n",
            "linux-tools-5.15.0-1048-gke - Linux kernel version specific tools for version 5.15.0-1048\n",
            "linux-tools-5.15.0-1048-gkeop - Linux kernel version specific tools for version 5.15.0-1048\n",
            "linux-tools-5.15.0-1048-ibm - Linux kernel version specific tools for version 5.15.0-1048\n",
            "linux-tools-5.15.0-1048-intel-iotg - Linux kernel version specific tools for version 5.15.0-1048\n",
            "linux-tools-5.15.0-1048-kvm - Linux kernel version specific tools for version 5.15.0-1048\n",
            "linux-tools-5.15.0-1048-nvidia - Linux kernel version specific tools for version 5.15.0-1048\n",
            "linux-tools-5.15.0-1048-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1048\n",
            "linux-tools-5.15.0-1048-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1048\n",
            "linux-tools-5.15.0-1049-aws - Linux kernel version specific tools for version 5.15.0-1049\n",
            "linux-tools-5.15.0-1049-azure - Linux kernel version specific tools for version 5.15.0-1049\n",
            "linux-tools-5.15.0-1049-gcp - Linux kernel version specific tools for version 5.15.0-1049\n",
            "linux-tools-5.15.0-1049-gke - Linux kernel version specific tools for version 5.15.0-1049\n",
            "linux-tools-5.15.0-1049-gkeop - Linux kernel version specific tools for version 5.15.0-1049\n",
            "linux-tools-5.15.0-1049-ibm - Linux kernel version specific tools for version 5.15.0-1049\n",
            "linux-tools-5.15.0-1049-intel-iotg - Linux kernel version specific tools for version 5.15.0-1049\n",
            "linux-tools-5.15.0-1049-kvm - Linux kernel version specific tools for version 5.15.0-1049\n",
            "linux-tools-5.15.0-1049-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1049\n",
            "linux-tools-5.15.0-105 - Linux kernel version specific tools for version 5.15.0-105\n",
            "linux-tools-5.15.0-105-generic - Linux kernel version specific tools for version 5.15.0-105\n",
            "linux-tools-5.15.0-105-lowlatency - Linux kernel version specific tools for version 5.15.0-105\n",
            "linux-tools-5.15.0-1050-aws - Linux kernel version specific tools for version 5.15.0-1050\n",
            "linux-tools-5.15.0-1050-azure - Linux kernel version specific tools for version 5.15.0-1050\n",
            "linux-tools-5.15.0-1050-gke - Linux kernel version specific tools for version 5.15.0-1050\n",
            "linux-tools-5.15.0-1050-gkeop - Linux kernel version specific tools for version 5.15.0-1050\n",
            "linux-tools-5.15.0-1050-ibm - Linux kernel version specific tools for version 5.15.0-1050\n",
            "linux-tools-5.15.0-1050-intel-iotg - Linux kernel version specific tools for version 5.15.0-1050\n",
            "linux-tools-5.15.0-1050-kvm - Linux kernel version specific tools for version 5.15.0-1050\n",
            "linux-tools-5.15.0-1050-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1050\n",
            "linux-tools-5.15.0-1051-aws - Linux kernel version specific tools for version 5.15.0-1051\n",
            "linux-tools-5.15.0-1051-azure - Linux kernel version specific tools for version 5.15.0-1051\n",
            "linux-tools-5.15.0-1051-gcp - Linux kernel version specific tools for version 5.15.0-1051\n",
            "linux-tools-5.15.0-1051-gke - Linux kernel version specific tools for version 5.15.0-1051\n",
            "linux-tools-5.15.0-1051-gkeop - Linux kernel version specific tools for version 5.15.0-1051\n",
            "linux-tools-5.15.0-1051-intel-iotg - Linux kernel version specific tools for version 5.15.0-1051\n",
            "linux-tools-5.15.0-1051-kvm - Linux kernel version specific tools for version 5.15.0-1051\n",
            "linux-tools-5.15.0-1051-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1051\n",
            "linux-tools-5.15.0-1052-aws - Linux kernel version specific tools for version 5.15.0-1052\n",
            "linux-tools-5.15.0-1052-azure - Linux kernel version specific tools for version 5.15.0-1052\n",
            "linux-tools-5.15.0-1052-gcp - Linux kernel version specific tools for version 5.15.0-1052\n",
            "linux-tools-5.15.0-1052-gke - Linux kernel version specific tools for version 5.15.0-1052\n",
            "linux-tools-5.15.0-1052-gkeop - Linux kernel version specific tools for version 5.15.0-1052\n",
            "linux-tools-5.15.0-1052-intel-iotg - Linux kernel version specific tools for version 5.15.0-1052\n",
            "linux-tools-5.15.0-1052-kvm - Linux kernel version specific tools for version 5.15.0-1052\n",
            "linux-tools-5.15.0-1052-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1052\n",
            "linux-tools-5.15.0-1053-aws - Linux kernel version specific tools for version 5.15.0-1053\n",
            "linux-tools-5.15.0-1053-azure - Linux kernel version specific tools for version 5.15.0-1053\n",
            "linux-tools-5.15.0-1053-gcp - Linux kernel version specific tools for version 5.15.0-1053\n",
            "linux-tools-5.15.0-1053-gke - Linux kernel version specific tools for version 5.15.0-1053\n",
            "linux-tools-5.15.0-1053-gkeop - Linux kernel version specific tools for version 5.15.0-1053\n",
            "linux-tools-5.15.0-1053-ibm - Linux kernel version specific tools for version 5.15.0-1053\n",
            "linux-tools-5.15.0-1053-kvm - Linux kernel version specific tools for version 5.15.0-1053\n",
            "linux-tools-5.15.0-1053-nvidia - Linux kernel version specific tools for version 5.15.0-1053\n",
            "linux-tools-5.15.0-1053-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1053\n",
            "linux-tools-5.15.0-1053-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1053\n",
            "linux-tools-5.15.0-1054-azure - Linux kernel version specific tools for version 5.15.0-1054\n",
            "linux-tools-5.15.0-1054-gcp - Linux kernel version specific tools for version 5.15.0-1054\n",
            "linux-tools-5.15.0-1054-gke - Linux kernel version specific tools for version 5.15.0-1054\n",
            "linux-tools-5.15.0-1054-ibm - Linux kernel version specific tools for version 5.15.0-1054\n",
            "linux-tools-5.15.0-1054-kvm - Linux kernel version specific tools for version 5.15.0-1054\n",
            "linux-tools-5.15.0-1054-nvidia - Linux kernel version specific tools for version 5.15.0-1054\n",
            "linux-tools-5.15.0-1054-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1054\n",
            "linux-tools-5.15.0-1054-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1054\n",
            "linux-tools-5.15.0-1055-aws - Linux kernel version specific tools for version 5.15.0-1055\n",
            "linux-tools-5.15.0-1055-gcp - Linux kernel version specific tools for version 5.15.0-1055\n",
            "linux-tools-5.15.0-1055-ibm - Linux kernel version specific tools for version 5.15.0-1055\n",
            "linux-tools-5.15.0-1055-intel-iotg - Linux kernel version specific tools for version 5.15.0-1055\n",
            "linux-tools-5.15.0-1055-nvidia - Linux kernel version specific tools for version 5.15.0-1055\n",
            "linux-tools-5.15.0-1055-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1055\n",
            "linux-tools-5.15.0-1055-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1055\n",
            "linux-tools-5.15.0-1056-aws - Linux kernel version specific tools for version 5.15.0-1056\n",
            "linux-tools-5.15.0-1056-azure - Linux kernel version specific tools for version 5.15.0-1056\n",
            "linux-tools-5.15.0-1056-ibm - Linux kernel version specific tools for version 5.15.0-1056\n",
            "linux-tools-5.15.0-1057-aws - Linux kernel version specific tools for version 5.15.0-1057\n",
            "linux-tools-5.15.0-1057-azure - Linux kernel version specific tools for version 5.15.0-1057\n",
            "linux-tools-5.15.0-1057-gke - Linux kernel version specific tools for version 5.15.0-1057\n",
            "linux-tools-5.15.0-1057-ibm - Linux kernel version specific tools for version 5.15.0-1057\n",
            "linux-tools-5.15.0-1057-intel-iotg - Linux kernel version specific tools for version 5.15.0-1057\n",
            "linux-tools-5.15.0-1057-kvm - Linux kernel version specific tools for version 5.15.0-1057\n",
            "linux-tools-5.15.0-1058-azure - Linux kernel version specific tools for version 5.15.0-1058\n",
            "linux-tools-5.15.0-1058-gcp - Linux kernel version specific tools for version 5.15.0-1058\n",
            "linux-tools-5.15.0-1058-gke - Linux kernel version specific tools for version 5.15.0-1058\n",
            "linux-tools-5.15.0-1058-ibm - Linux kernel version specific tools for version 5.15.0-1058\n",
            "linux-tools-5.15.0-1058-intel-iotg - Linux kernel version specific tools for version 5.15.0-1058\n",
            "linux-tools-5.15.0-1058-kvm - Linux kernel version specific tools for version 5.15.0-1058\n",
            "linux-tools-5.15.0-1058-nvidia - Linux kernel version specific tools for version 5.15.0-1058\n",
            "linux-tools-5.15.0-1058-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1058\n",
            "linux-tools-5.15.0-1058-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1058\n",
            "linux-tools-5.15.0-1059-azure - Linux kernel version specific tools for version 5.15.0-1059\n",
            "linux-tools-5.15.0-1059-gcp - Linux kernel version specific tools for version 5.15.0-1059\n",
            "linux-tools-5.15.0-1059-gke - Linux kernel version specific tools for version 5.15.0-1059\n",
            "linux-tools-5.15.0-1059-ibm - Linux kernel version specific tools for version 5.15.0-1059\n",
            "linux-tools-5.15.0-1059-intel-iotg - Linux kernel version specific tools for version 5.15.0-1059\n",
            "linux-tools-5.15.0-1059-kvm - Linux kernel version specific tools for version 5.15.0-1059\n",
            "linux-tools-5.15.0-1059-nvidia - Linux kernel version specific tools for version 5.15.0-1059\n",
            "linux-tools-5.15.0-1059-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1059\n",
            "linux-tools-5.15.0-1059-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1059\n",
            "linux-tools-5.15.0-106 - Linux kernel version specific tools for version 5.15.0-106\n",
            "linux-tools-5.15.0-106-generic - Linux kernel version specific tools for version 5.15.0-106\n",
            "linux-tools-5.15.0-106-lowlatency - Linux kernel version specific tools for version 5.15.0-106\n",
            "linux-tools-5.15.0-1060-aws - Linux kernel version specific tools for version 5.15.0-1060\n",
            "linux-tools-5.15.0-1060-azure - Linux kernel version specific tools for version 5.15.0-1060\n",
            "linux-tools-5.15.0-1060-gcp - Linux kernel version specific tools for version 5.15.0-1060\n",
            "linux-tools-5.15.0-1060-gke - Linux kernel version specific tools for version 5.15.0-1060\n",
            "linux-tools-5.15.0-1060-ibm - Linux kernel version specific tools for version 5.15.0-1060\n",
            "linux-tools-5.15.0-1060-intel-iotg - Linux kernel version specific tools for version 5.15.0-1060\n",
            "linux-tools-5.15.0-1060-kvm - Linux kernel version specific tools for version 5.15.0-1060\n",
            "linux-tools-5.15.0-1060-nvidia - Linux kernel version specific tools for version 5.15.0-1060\n",
            "linux-tools-5.15.0-1060-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1060\n",
            "linux-tools-5.15.0-1060-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1060\n",
            "linux-tools-5.15.0-1061-aws - Linux kernel version specific tools for version 5.15.0-1061\n",
            "linux-tools-5.15.0-1061-azure - Linux kernel version specific tools for version 5.15.0-1061\n",
            "linux-tools-5.15.0-1061-gke - Linux kernel version specific tools for version 5.15.0-1061\n",
            "linux-tools-5.15.0-1061-ibm - Linux kernel version specific tools for version 5.15.0-1061\n",
            "linux-tools-5.15.0-1061-intel-iotg - Linux kernel version specific tools for version 5.15.0-1061\n",
            "linux-tools-5.15.0-1061-kvm - Linux kernel version specific tools for version 5.15.0-1061\n",
            "linux-tools-5.15.0-1061-nvidia - Linux kernel version specific tools for version 5.15.0-1061\n",
            "linux-tools-5.15.0-1061-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1061\n",
            "linux-tools-5.15.0-1061-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1061\n",
            "linux-tools-5.15.0-1062-aws - Linux kernel version specific tools for version 5.15.0-1062\n",
            "linux-tools-5.15.0-1062-gcp - Linux kernel version specific tools for version 5.15.0-1062\n",
            "linux-tools-5.15.0-1062-gke - Linux kernel version specific tools for version 5.15.0-1062\n",
            "linux-tools-5.15.0-1062-ibm - Linux kernel version specific tools for version 5.15.0-1062\n",
            "linux-tools-5.15.0-1062-intel-iotg - Linux kernel version specific tools for version 5.15.0-1062\n",
            "linux-tools-5.15.0-1062-kvm - Linux kernel version specific tools for version 5.15.0-1062\n",
            "linux-tools-5.15.0-1062-nvidia - Linux kernel version specific tools for version 5.15.0-1062\n",
            "linux-tools-5.15.0-1062-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1062\n",
            "linux-tools-5.15.0-1062-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1062\n",
            "linux-tools-5.15.0-1063-aws - Linux kernel version specific tools for version 5.15.0-1063\n",
            "linux-tools-5.15.0-1063-azure - Linux kernel version specific tools for version 5.15.0-1063\n",
            "linux-tools-5.15.0-1063-gcp - Linux kernel version specific tools for version 5.15.0-1063\n",
            "linux-tools-5.15.0-1063-gke - Linux kernel version specific tools for version 5.15.0-1063\n",
            "linux-tools-5.15.0-1063-ibm - Linux kernel version specific tools for version 5.15.0-1063\n",
            "linux-tools-5.15.0-1063-intel-iotg - Linux kernel version specific tools for version 5.15.0-1063\n",
            "linux-tools-5.15.0-1063-kvm - Linux kernel version specific tools for version 5.15.0-1063\n",
            "linux-tools-5.15.0-1063-nvidia - Linux kernel version specific tools for version 5.15.0-1063\n",
            "linux-tools-5.15.0-1063-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1063\n",
            "linux-tools-5.15.0-1063-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1063\n",
            "linux-tools-5.15.0-1064-aws - Linux kernel version specific tools for version 5.15.0-1064\n",
            "linux-tools-5.15.0-1064-azure - Linux kernel version specific tools for version 5.15.0-1064\n",
            "linux-tools-5.15.0-1064-gcp - Linux kernel version specific tools for version 5.15.0-1064\n",
            "linux-tools-5.15.0-1064-gke - Linux kernel version specific tools for version 5.15.0-1064\n",
            "linux-tools-5.15.0-1064-intel-iotg - Linux kernel version specific tools for version 5.15.0-1064\n",
            "linux-tools-5.15.0-1064-kvm - Linux kernel version specific tools for version 5.15.0-1064\n",
            "linux-tools-5.15.0-1064-nvidia - Linux kernel version specific tools for version 5.15.0-1064\n",
            "linux-tools-5.15.0-1064-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1064\n",
            "linux-tools-5.15.0-1064-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1064\n",
            "linux-tools-5.15.0-1065-aws - Linux kernel version specific tools for version 5.15.0-1065\n",
            "linux-tools-5.15.0-1065-gcp - Linux kernel version specific tools for version 5.15.0-1065\n",
            "linux-tools-5.15.0-1065-gke - Linux kernel version specific tools for version 5.15.0-1065\n",
            "linux-tools-5.15.0-1065-intel-iotg - Linux kernel version specific tools for version 5.15.0-1065\n",
            "linux-tools-5.15.0-1065-kvm - Linux kernel version specific tools for version 5.15.0-1065\n",
            "linux-tools-5.15.0-1065-nvidia - Linux kernel version specific tools for version 5.15.0-1065\n",
            "linux-tools-5.15.0-1065-nvidia-lowlatency - Linux kernel version specific tools for version 5.15.0-1065\n",
            "linux-tools-5.15.0-1065-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1065\n",
            "linux-tools-5.15.0-1066-aws - Linux kernel version specific tools for version 5.15.0-1066\n",
            "linux-tools-5.15.0-1066-azure - Linux kernel version specific tools for version 5.15.0-1066\n",
            "linux-tools-5.15.0-1066-gcp - Linux kernel version specific tools for version 5.15.0-1066\n",
            "linux-tools-5.15.0-1066-gke - Linux kernel version specific tools for version 5.15.0-1066\n",
            "linux-tools-5.15.0-1066-kvm - Linux kernel version specific tools for version 5.15.0-1066\n",
            "linux-tools-5.15.0-1066-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1066\n",
            "linux-tools-5.15.0-1067-aws - Linux kernel version specific tools for version 5.15.0-1067\n",
            "linux-tools-5.15.0-1067-azure - Linux kernel version specific tools for version 5.15.0-1067\n",
            "linux-tools-5.15.0-1067-gcp - Linux kernel version specific tools for version 5.15.0-1067\n",
            "linux-tools-5.15.0-1067-gke - Linux kernel version specific tools for version 5.15.0-1067\n",
            "linux-tools-5.15.0-1067-kvm - Linux kernel version specific tools for version 5.15.0-1067\n",
            "linux-tools-5.15.0-1067-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1067\n",
            "linux-tools-5.15.0-1068-aws - Linux kernel version specific tools for version 5.15.0-1068\n",
            "linux-tools-5.15.0-1068-azure - Linux kernel version specific tools for version 5.15.0-1068\n",
            "linux-tools-5.15.0-1068-gcp - Linux kernel version specific tools for version 5.15.0-1068\n",
            "linux-tools-5.15.0-1068-oracle - Oracle Linux kernel version specific tools for version 5.15.0-1068\n",
            "linux-tools-5.15.0-1069-aws - Linux kernel version specific tools for version 5.15.0-1069\n",
            "linux-tools-5.15.0-1069-gcp - Linux kernel version specific tools for version 5.15.0-1069\n",
            "linux-tools-5.15.0-107 - Linux kernel version specific tools for version 5.15.0-107\n",
            "linux-tools-5.15.0-107-generic - Linux kernel version specific tools for version 5.15.0-107\n",
            "linux-tools-5.15.0-107-lowlatency - Linux kernel version specific tools for version 5.15.0-107\n",
            "linux-tools-5.15.0-1070-aws - Linux kernel version specific tools for version 5.15.0-1070\n",
            "linux-tools-5.15.0-1070-azure - Linux kernel version specific tools for version 5.15.0-1070\n",
            "linux-tools-5.15.0-1071-azure - Linux kernel version specific tools for version 5.15.0-1071\n",
            "linux-tools-5.15.0-1072-azure - Linux kernel version specific tools for version 5.15.0-1072\n",
            "linux-tools-5.15.0-1073-azure - Linux kernel version specific tools for version 5.15.0-1073\n",
            "linux-tools-5.15.0-110-lowlatency - Linux kernel version specific tools for version 5.15.0-110\n",
            "linux-tools-5.15.0-112 - Linux kernel version specific tools for version 5.15.0-112\n",
            "linux-tools-5.15.0-112-generic - Linux kernel version specific tools for version 5.15.0-112\n",
            "linux-tools-5.15.0-113 - Linux kernel version specific tools for version 5.15.0-113\n",
            "linux-tools-5.15.0-113-generic - Linux kernel version specific tools for version 5.15.0-113\n",
            "linux-tools-5.15.0-113-lowlatency - Linux kernel version specific tools for version 5.15.0-113\n",
            "linux-tools-5.15.0-116 - Linux kernel version specific tools for version 5.15.0-116\n",
            "linux-tools-5.15.0-116-generic - Linux kernel version specific tools for version 5.15.0-116\n",
            "linux-tools-5.15.0-116-lowlatency - Linux kernel version specific tools for version 5.15.0-116\n",
            "linux-tools-5.15.0-117 - Linux kernel version specific tools for version 5.15.0-117\n",
            "linux-tools-5.15.0-117-generic - Linux kernel version specific tools for version 5.15.0-117\n",
            "linux-tools-5.15.0-117-lowlatency - Linux kernel version specific tools for version 5.15.0-117\n",
            "linux-tools-5.15.0-118 - Linux kernel version specific tools for version 5.15.0-118\n",
            "linux-tools-5.15.0-118-generic - Linux kernel version specific tools for version 5.15.0-118\n",
            "linux-tools-5.15.0-118-lowlatency - Linux kernel version specific tools for version 5.15.0-118\n",
            "linux-tools-5.15.0-119 - Linux kernel version specific tools for version 5.15.0-119\n",
            "linux-tools-5.15.0-119-generic - Linux kernel version specific tools for version 5.15.0-119\n",
            "linux-tools-5.15.0-119-lowlatency - Linux kernel version specific tools for version 5.15.0-119\n",
            "linux-tools-5.15.0-121 - Linux kernel version specific tools for version 5.15.0-121\n",
            "linux-tools-5.15.0-121-generic - Linux kernel version specific tools for version 5.15.0-121\n",
            "linux-tools-5.15.0-121-lowlatency - Linux kernel version specific tools for version 5.15.0-121\n",
            "linux-tools-5.15.0-122 - Linux kernel version specific tools for version 5.15.0-122\n",
            "linux-tools-5.15.0-122-generic - Linux kernel version specific tools for version 5.15.0-122\n",
            "linux-tools-5.15.0-72 - Linux kernel version specific tools for version 5.15.0-72\n",
            "linux-tools-5.15.0-72-generic - Linux kernel version specific tools for version 5.15.0-72\n",
            "linux-tools-5.15.0-72-lowlatency - Linux kernel version specific tools for version 5.15.0-72\n",
            "linux-tools-5.15.0-73 - Linux kernel version specific tools for version 5.15.0-73\n",
            "linux-tools-5.15.0-73-generic - Linux kernel version specific tools for version 5.15.0-73\n",
            "linux-tools-5.15.0-73-lowlatency - Linux kernel version specific tools for version 5.15.0-73\n",
            "linux-tools-5.15.0-75 - Linux kernel version specific tools for version 5.15.0-75\n",
            "linux-tools-5.15.0-75-generic - Linux kernel version specific tools for version 5.15.0-75\n",
            "linux-tools-5.15.0-75-lowlatency - Linux kernel version specific tools for version 5.15.0-75\n",
            "linux-tools-5.15.0-76-lowlatency - Linux kernel version specific tools for version 5.15.0-76\n",
            "linux-tools-5.15.0-78 - Linux kernel version specific tools for version 5.15.0-78\n",
            "linux-tools-5.15.0-78-generic - Linux kernel version specific tools for version 5.15.0-78\n",
            "linux-tools-5.15.0-78-lowlatency - Linux kernel version specific tools for version 5.15.0-78\n",
            "linux-tools-5.15.0-79 - Linux kernel version specific tools for version 5.15.0-79\n",
            "linux-tools-5.15.0-79-generic - Linux kernel version specific tools for version 5.15.0-79\n",
            "linux-tools-5.15.0-79-lowlatency - Linux kernel version specific tools for version 5.15.0-79\n",
            "linux-tools-5.15.0-82 - Linux kernel version specific tools for version 5.15.0-82\n",
            "linux-tools-5.15.0-82-generic - Linux kernel version specific tools for version 5.15.0-82\n",
            "linux-tools-5.15.0-82-lowlatency - Linux kernel version specific tools for version 5.15.0-82\n",
            "linux-tools-5.15.0-83 - Linux kernel version specific tools for version 5.15.0-83\n",
            "linux-tools-5.15.0-83-generic - Linux kernel version specific tools for version 5.15.0-83\n",
            "linux-tools-5.15.0-83-lowlatency - Linux kernel version specific tools for version 5.15.0-83\n",
            "linux-tools-5.15.0-84 - Linux kernel version specific tools for version 5.15.0-84\n",
            "linux-tools-5.15.0-84-generic - Linux kernel version specific tools for version 5.15.0-84\n",
            "linux-tools-5.15.0-84-lowlatency - Linux kernel version specific tools for version 5.15.0-84\n",
            "linux-tools-5.15.0-86 - Linux kernel version specific tools for version 5.15.0-86\n",
            "linux-tools-5.15.0-86-generic - Linux kernel version specific tools for version 5.15.0-86\n",
            "linux-tools-5.15.0-86-lowlatency - Linux kernel version specific tools for version 5.15.0-86\n",
            "linux-tools-5.15.0-87 - Linux kernel version specific tools for version 5.15.0-87\n",
            "linux-tools-5.15.0-87-generic - Linux kernel version specific tools for version 5.15.0-87\n",
            "linux-tools-5.15.0-87-lowlatency - Linux kernel version specific tools for version 5.15.0-87\n",
            "linux-tools-5.15.0-88 - Linux kernel version specific tools for version 5.15.0-88\n",
            "linux-tools-5.15.0-88-generic - Linux kernel version specific tools for version 5.15.0-88\n",
            "linux-tools-5.15.0-88-lowlatency - Linux kernel version specific tools for version 5.15.0-88\n",
            "linux-tools-5.15.0-89 - Linux kernel version specific tools for version 5.15.0-89\n",
            "linux-tools-5.15.0-89-generic - Linux kernel version specific tools for version 5.15.0-89\n",
            "linux-tools-5.15.0-89-lowlatency - Linux kernel version specific tools for version 5.15.0-89\n",
            "linux-tools-5.15.0-91 - Linux kernel version specific tools for version 5.15.0-91\n",
            "linux-tools-5.15.0-91-generic - Linux kernel version specific tools for version 5.15.0-91\n",
            "linux-tools-5.15.0-91-lowlatency - Linux kernel version specific tools for version 5.15.0-91\n",
            "linux-tools-5.15.0-92 - Linux kernel version specific tools for version 5.15.0-92\n",
            "linux-tools-5.15.0-92-generic - Linux kernel version specific tools for version 5.15.0-92\n",
            "linux-tools-5.15.0-92-lowlatency - Linux kernel version specific tools for version 5.15.0-92\n",
            "linux-tools-5.15.0-94 - Linux kernel version specific tools for version 5.15.0-94\n",
            "linux-tools-5.15.0-94-generic - Linux kernel version specific tools for version 5.15.0-94\n",
            "linux-tools-5.15.0-94-lowlatency - Linux kernel version specific tools for version 5.15.0-94\n",
            "linux-tools-5.15.0-97 - Linux kernel version specific tools for version 5.15.0-97\n",
            "linux-tools-5.15.0-97-generic - Linux kernel version specific tools for version 5.15.0-97\n",
            "linux-tools-5.15.0-97-lowlatency - Linux kernel version specific tools for version 5.15.0-97\n",
            "linux-tools-5.17.0-1031-oem - Linux kernel version specific tools for version 5.17.0-1031\n",
            "linux-tools-5.17.0-1032-oem - Linux kernel version specific tools for version 5.17.0-1032\n",
            "linux-tools-5.17.0-1033-oem - Linux kernel version specific tools for version 5.17.0-1033\n",
            "linux-tools-5.17.0-1034-oem - Linux kernel version specific tools for version 5.17.0-1034\n",
            "linux-tools-5.17.0-1035-oem - Linux kernel version specific tools for version 5.17.0-1035\n",
            "linux-tools-5.19.0-1022-gcp - Linux kernel version specific tools for version 5.19.0-1022\n",
            "linux-tools-5.19.0-1023-oracle - Oracle Linux kernel version specific tools for version 5.19.0-1023\n",
            "linux-tools-5.19.0-1024-aws - Linux kernel version specific tools for version 5.19.0-1024\n",
            "linux-tools-5.19.0-1024-gcp - Linux kernel version specific tools for version 5.19.0-1024\n",
            "linux-tools-5.19.0-1024-lowlatency - Linux kernel version specific tools for version 5.19.0-1024\n",
            "linux-tools-5.19.0-1024-oracle - Oracle Linux kernel version specific tools for version 5.19.0-1024\n",
            "linux-tools-5.19.0-1025-aws - Linux kernel version specific tools for version 5.19.0-1025\n",
            "linux-tools-5.19.0-1025-azure - Linux kernel version specific tools for version 5.19.0-1025\n",
            "linux-tools-5.19.0-1025-gcp - Linux kernel version specific tools for version 5.19.0-1025\n",
            "linux-tools-5.19.0-1025-lowlatency - Linux kernel version specific tools for version 5.19.0-1025\n",
            "linux-tools-5.19.0-1025-oracle - Oracle Linux kernel version specific tools for version 5.19.0-1025\n",
            "linux-tools-5.19.0-1026-aws - Linux kernel version specific tools for version 5.19.0-1026\n",
            "linux-tools-5.19.0-1026-azure - Linux kernel version specific tools for version 5.19.0-1026\n",
            "linux-tools-5.19.0-1026-gcp - Linux kernel version specific tools for version 5.19.0-1026\n",
            "linux-tools-5.19.0-1026-oracle - Oracle Linux kernel version specific tools for version 5.19.0-1026\n",
            "linux-tools-5.19.0-1027-aws - Linux kernel version specific tools for version 5.19.0-1027\n",
            "linux-tools-5.19.0-1027-azure - Linux kernel version specific tools for version 5.19.0-1027\n",
            "linux-tools-5.19.0-1027-gcp - Linux kernel version specific tools for version 5.19.0-1027\n",
            "linux-tools-5.19.0-1027-lowlatency - Linux kernel version specific tools for version 5.19.0-1027\n",
            "linux-tools-5.19.0-1027-oracle - Oracle Linux kernel version specific tools for version 5.19.0-1027\n",
            "linux-tools-5.19.0-1028-aws - Linux kernel version specific tools for version 5.19.0-1028\n",
            "linux-tools-5.19.0-1028-lowlatency - Linux kernel version specific tools for version 5.19.0-1028\n",
            "linux-tools-5.19.0-1029-aws - Linux kernel version specific tools for version 5.19.0-1029\n",
            "linux-tools-5.19.0-1030-gcp - Linux kernel version specific tools for version 5.19.0-1030\n",
            "linux-tools-5.19.0-1030-lowlatency - Linux kernel version specific tools for version 5.19.0-1030\n",
            "linux-tools-5.19.0-41-generic - Linux kernel version specific tools for version 5.19.0-41\n",
            "linux-tools-5.19.0-42-generic - Linux kernel version specific tools for version 5.19.0-42\n",
            "linux-tools-5.19.0-43-generic - Linux kernel version specific tools for version 5.19.0-43\n",
            "linux-tools-5.19.0-45-generic - Linux kernel version specific tools for version 5.19.0-45\n",
            "linux-tools-5.19.0-46-generic - Linux kernel version specific tools for version 5.19.0-46\n",
            "linux-tools-5.19.0-50-generic - Linux kernel version specific tools for version 5.19.0-50\n",
            "linux-tools-6.0.0-1016-oem - Linux kernel version specific tools for version 6.0.0-1016\n",
            "linux-tools-6.0.0-1017-oem - Linux kernel version specific tools for version 6.0.0-1017\n",
            "linux-tools-6.0.0-1018-oem - Linux kernel version specific tools for version 6.0.0-1018\n",
            "linux-tools-6.0.0-1019-oem - Linux kernel version specific tools for version 6.0.0-1019\n",
            "linux-tools-6.0.0-1020-oem - Linux kernel version specific tools for version 6.0.0-1020\n",
            "linux-tools-6.0.0-1021-oem - Linux kernel version specific tools for version 6.0.0-1021\n",
            "linux-tools-6.1.0-1012-oem - Linux kernel version specific tools for version 6.1.0-1012\n",
            "linux-tools-6.1.0-1013-oem - Linux kernel version specific tools for version 6.1.0-1013\n",
            "linux-tools-6.1.0-1014-oem - Linux kernel version specific tools for version 6.1.0-1014\n",
            "linux-tools-6.1.0-1015-oem - Linux kernel version specific tools for version 6.1.0-1015\n",
            "linux-tools-6.1.0-1016-oem - Linux kernel version specific tools for version 6.1.0-1016\n",
            "linux-tools-6.1.0-1017-oem - Linux kernel version specific tools for version 6.1.0-1017\n",
            "linux-tools-6.1.0-1019-oem - Linux kernel version specific tools for version 6.1.0-1019\n",
            "linux-tools-6.1.0-1020-oem - Linux kernel version specific tools for version 6.1.0-1020\n",
            "linux-tools-6.1.0-1021-oem - Linux kernel version specific tools for version 6.1.0-1021\n",
            "linux-tools-6.1.0-1022-oem - Linux kernel version specific tools for version 6.1.0-1022\n",
            "linux-tools-6.1.0-1023-oem - Linux kernel version specific tools for version 6.1.0-1023\n",
            "linux-tools-6.1.0-1024-oem - Linux kernel version specific tools for version 6.1.0-1024\n",
            "linux-tools-6.1.0-1025-oem - Linux kernel version specific tools for version 6.1.0-1025\n",
            "linux-tools-6.1.0-1026-oem - Linux kernel version specific tools for version 6.1.0-1026\n",
            "linux-tools-6.1.0-1027-oem - Linux kernel version specific tools for version 6.1.0-1027\n",
            "linux-tools-6.1.0-1028-oem - Linux kernel version specific tools for version 6.1.0-1028\n",
            "linux-tools-6.1.0-1029-oem - Linux kernel version specific tools for version 6.1.0-1029\n",
            "linux-tools-6.1.0-1033-oem - Linux kernel version specific tools for version 6.1.0-1033\n",
            "linux-tools-6.1.0-1034-oem - Linux kernel version specific tools for version 6.1.0-1034\n",
            "linux-tools-6.1.0-1035-oem - Linux kernel version specific tools for version 6.1.0-1035\n",
            "linux-tools-6.1.0-1036-oem - Linux kernel version specific tools for version 6.1.0-1036\n",
            "linux-tools-6.2.0-1003-nvidia - Linux kernel version specific tools for version 6.2.0-1003\n",
            "linux-tools-6.2.0-1005-aws - Linux kernel version specific tools for version 6.2.0-1005\n",
            "linux-tools-6.2.0-1005-azure - Linux kernel version specific tools for version 6.2.0-1005\n",
            "linux-tools-6.2.0-1006-aws - Linux kernel version specific tools for version 6.2.0-1006\n",
            "linux-tools-6.2.0-1006-azure - Linux kernel version specific tools for version 6.2.0-1006\n",
            "linux-tools-6.2.0-1007-aws - Linux kernel version specific tools for version 6.2.0-1007\n",
            "linux-tools-6.2.0-1007-azure - Linux kernel version specific tools for version 6.2.0-1007\n",
            "linux-tools-6.2.0-1008-aws - Linux kernel version specific tools for version 6.2.0-1008\n",
            "linux-tools-6.2.0-1008-azure - Linux kernel version specific tools for version 6.2.0-1008\n",
            "linux-tools-6.2.0-1008-lowlatency - Linux kernel version specific tools for version 6.2.0-1008\n",
            "linux-tools-6.2.0-1009-aws - Linux kernel version specific tools for version 6.2.0-1009\n",
            "linux-tools-6.2.0-1009-gcp - Linux kernel version specific tools for version 6.2.0-1009\n",
            "linux-tools-6.2.0-1009-lowlatency - Linux kernel version specific tools for version 6.2.0-1009\n",
            "linux-tools-6.2.0-1009-nvidia - Linux kernel version specific tools for version 6.2.0-1009\n",
            "linux-tools-6.2.0-1010-aws - Linux kernel version specific tools for version 6.2.0-1010\n",
            "linux-tools-6.2.0-1010-gcp - Linux kernel version specific tools for version 6.2.0-1010\n",
            "linux-tools-6.2.0-1010-nvidia - Linux kernel version specific tools for version 6.2.0-1010\n",
            "linux-tools-6.2.0-1011-aws - Linux kernel version specific tools for version 6.2.0-1011\n",
            "linux-tools-6.2.0-1011-azure - Linux kernel version specific tools for version 6.2.0-1011\n",
            "linux-tools-6.2.0-1011-gcp - Linux kernel version specific tools for version 6.2.0-1011\n",
            "linux-tools-6.2.0-1011-lowlatency - Linux kernel version specific tools for version 6.2.0-1011\n",
            "linux-tools-6.2.0-1011-nvidia - Linux kernel version specific tools for version 6.2.0-1011\n",
            "linux-tools-6.2.0-1012-aws - Linux kernel version specific tools for version 6.2.0-1012\n",
            "linux-tools-6.2.0-1012-azure - Linux kernel version specific tools for version 6.2.0-1012\n",
            "linux-tools-6.2.0-1012-gcp - Linux kernel version specific tools for version 6.2.0-1012\n",
            "linux-tools-6.2.0-1012-lowlatency - Linux kernel version specific tools for version 6.2.0-1012\n",
            "linux-tools-6.2.0-1012-nvidia - Linux kernel version specific tools for version 6.2.0-1012\n",
            "linux-tools-6.2.0-1013-aws - Linux kernel version specific tools for version 6.2.0-1013\n",
            "linux-tools-6.2.0-1013-gcp - Linux kernel version specific tools for version 6.2.0-1013\n",
            "linux-tools-6.2.0-1013-lowlatency - Linux kernel version specific tools for version 6.2.0-1013\n",
            "linux-tools-6.2.0-1013-nvidia - Linux kernel version specific tools for version 6.2.0-1013\n",
            "linux-tools-6.2.0-1013-oracle - Oracle Linux kernel version specific tools for version 6.2.0-1013\n",
            "linux-tools-6.2.0-1014-aws - Linux kernel version specific tools for version 6.2.0-1014\n",
            "linux-tools-6.2.0-1014-azure - Linux kernel version specific tools for version 6.2.0-1014\n",
            "linux-tools-6.2.0-1014-gcp - Linux kernel version specific tools for version 6.2.0-1014\n",
            "linux-tools-6.2.0-1014-lowlatency - Linux kernel version specific tools for version 6.2.0-1014\n",
            "linux-tools-6.2.0-1014-oracle - Oracle Linux kernel version specific tools for version 6.2.0-1014\n",
            "linux-tools-6.2.0-1015-aws - Linux kernel version specific tools for version 6.2.0-1015\n",
            "linux-tools-6.2.0-1015-azure - Linux kernel version specific tools for version 6.2.0-1015\n",
            "linux-tools-6.2.0-1015-lowlatency - Linux kernel version specific tools for version 6.2.0-1015\n",
            "linux-tools-6.2.0-1015-nvidia - Linux kernel version specific tools for version 6.2.0-1015\n",
            "linux-tools-6.2.0-1015-oracle - Oracle Linux kernel version specific tools for version 6.2.0-1015\n",
            "linux-tools-6.2.0-1016-aws - Linux kernel version specific tools for version 6.2.0-1016\n",
            "linux-tools-6.2.0-1016-azure - Linux kernel version specific tools for version 6.2.0-1016\n",
            "linux-tools-6.2.0-1016-gcp - Linux kernel version specific tools for version 6.2.0-1016\n",
            "linux-tools-6.2.0-1016-lowlatency - Linux kernel version specific tools for version 6.2.0-1016\n",
            "linux-tools-6.2.0-1016-oracle - Oracle Linux kernel version specific tools for version 6.2.0-1016\n",
            "linux-tools-6.2.0-1017-aws - Linux kernel version specific tools for version 6.2.0-1017\n",
            "linux-tools-6.2.0-1017-azure - Linux kernel version specific tools for version 6.2.0-1017\n",
            "linux-tools-6.2.0-1017-gcp - Linux kernel version specific tools for version 6.2.0-1017\n",
            "linux-tools-6.2.0-1017-lowlatency - Linux kernel version specific tools for version 6.2.0-1017\n",
            "linux-tools-6.2.0-1018-aws - Linux kernel version specific tools for version 6.2.0-1018\n",
            "linux-tools-6.2.0-1018-azure - Linux kernel version specific tools for version 6.2.0-1018\n",
            "linux-tools-6.2.0-1018-gcp - Linux kernel version specific tools for version 6.2.0-1018\n",
            "linux-tools-6.2.0-1018-lowlatency - Linux kernel version specific tools for version 6.2.0-1018\n",
            "linux-tools-6.2.0-1019-azure - Linux kernel version specific tools for version 6.2.0-1019\n",
            "linux-tools-6.2.0-1019-gcp - Linux kernel version specific tools for version 6.2.0-1019\n",
            "linux-tools-6.2.0-1021-gcp - Linux kernel version specific tools for version 6.2.0-1021\n",
            "linux-tools-6.2.0-25-generic - Linux kernel version specific tools for version 6.2.0-25\n",
            "linux-tools-6.2.0-26-generic - Linux kernel version specific tools for version 6.2.0-26\n",
            "linux-tools-6.2.0-31-generic - Linux kernel version specific tools for version 6.2.0-31\n",
            "linux-tools-6.2.0-32-generic - Linux kernel version specific tools for version 6.2.0-32\n",
            "linux-tools-6.2.0-33-generic - Linux kernel version specific tools for version 6.2.0-33\n",
            "linux-tools-6.2.0-34-generic - Linux kernel version specific tools for version 6.2.0-34\n",
            "linux-tools-6.2.0-35-generic - Linux kernel version specific tools for version 6.2.0-35\n",
            "linux-tools-6.2.0-36-generic - Linux kernel version specific tools for version 6.2.0-36\n",
            "linux-tools-6.2.0-37-generic - Linux kernel version specific tools for version 6.2.0-37\n",
            "linux-tools-6.2.0-39-generic - Linux kernel version specific tools for version 6.2.0-39\n",
            "linux-tools-6.5.0-1003-oem - Linux kernel version specific tools for version 6.5.0-1003\n",
            "linux-tools-6.5.0-1004-nvidia - Linux kernel version specific tools for version 6.5.0-1004\n",
            "linux-tools-6.5.0-1004-oem - Linux kernel version specific tools for version 6.5.0-1004\n",
            "linux-tools-6.5.0-1006-oem - Linux kernel version specific tools for version 6.5.0-1006\n",
            "linux-tools-6.5.0-1007-azure - Linux kernel version specific tools for version 6.5.0-1007\n",
            "linux-tools-6.5.0-1007-nvidia - Linux kernel version specific tools for version 6.5.0-1007\n",
            "linux-tools-6.5.0-1007-oem - Linux kernel version specific tools for version 6.5.0-1007\n",
            "linux-tools-6.5.0-1008-aws - Linux kernel version specific tools for version 6.5.0-1008\n",
            "linux-tools-6.5.0-1008-oem - Linux kernel version specific tools for version 6.5.0-1008\n",
            "linux-tools-6.5.0-1009-azure - Linux kernel version specific tools for version 6.5.0-1009\n",
            "linux-tools-6.5.0-1009-oem - Linux kernel version specific tools for version 6.5.0-1009\n",
            "linux-tools-6.5.0-1010-aws - Linux kernel version specific tools for version 6.5.0-1010\n",
            "linux-tools-6.5.0-1010-azure - Linux kernel version specific tools for version 6.5.0-1010\n",
            "linux-tools-6.5.0-1010-gcp - Linux kernel version specific tools for version 6.5.0-1010\n",
            "linux-tools-6.5.0-1011-aws - Linux kernel version specific tools for version 6.5.0-1011\n",
            "linux-tools-6.5.0-1011-azure - Linux kernel version specific tools for version 6.5.0-1011\n",
            "linux-tools-6.5.0-1011-gcp - Linux kernel version specific tools for version 6.5.0-1011\n",
            "linux-tools-6.5.0-1011-oem - Linux kernel version specific tools for version 6.5.0-1011\n",
            "linux-tools-6.5.0-1012-aws - Linux kernel version specific tools for version 6.5.0-1012\n",
            "linux-tools-6.5.0-1013-gcp - Linux kernel version specific tools for version 6.5.0-1013\n",
            "linux-tools-6.5.0-1013-nvidia - Linux kernel version specific tools for version 6.5.0-1013\n",
            "linux-tools-6.5.0-1013-oem - Linux kernel version specific tools for version 6.5.0-1013\n",
            "linux-tools-6.5.0-1013-oracle - Oracle Linux kernel version specific tools for version 6.5.0-1013\n",
            "linux-tools-6.5.0-1014-aws - Linux kernel version specific tools for version 6.5.0-1014\n",
            "linux-tools-6.5.0-1014-gcp - Linux kernel version specific tools for version 6.5.0-1014\n",
            "linux-tools-6.5.0-1014-nvidia - Linux kernel version specific tools for version 6.5.0-1014\n",
            "linux-tools-6.5.0-1014-oem - Linux kernel version specific tools for version 6.5.0-1014\n",
            "linux-tools-6.5.0-1014-oracle - Oracle Linux kernel version specific tools for version 6.5.0-1014\n",
            "linux-tools-6.5.0-1015-aws - Linux kernel version specific tools for version 6.5.0-1015\n",
            "linux-tools-6.5.0-1015-azure - Linux kernel version specific tools for version 6.5.0-1015\n",
            "linux-tools-6.5.0-1015-gcp - Linux kernel version specific tools for version 6.5.0-1015\n",
            "linux-tools-6.5.0-1015-nvidia - Linux kernel version specific tools for version 6.5.0-1015\n",
            "linux-tools-6.5.0-1015-oem - Linux kernel version specific tools for version 6.5.0-1015\n",
            "linux-tools-6.5.0-1015-oracle - Oracle Linux kernel version specific tools for version 6.5.0-1015\n",
            "linux-tools-6.5.0-1016-aws - Linux kernel version specific tools for version 6.5.0-1016\n",
            "linux-tools-6.5.0-1016-azure - Linux kernel version specific tools for version 6.5.0-1016\n",
            "linux-tools-6.5.0-1016-gcp - Linux kernel version specific tools for version 6.5.0-1016\n",
            "linux-tools-6.5.0-1016-oem - Linux kernel version specific tools for version 6.5.0-1016\n",
            "linux-tools-6.5.0-1016-oracle - Oracle Linux kernel version specific tools for version 6.5.0-1016\n",
            "linux-tools-6.5.0-1017-aws - Linux kernel version specific tools for version 6.5.0-1017\n",
            "linux-tools-6.5.0-1017-azure - Linux kernel version specific tools for version 6.5.0-1017\n",
            "linux-tools-6.5.0-1017-gcp - Linux kernel version specific tools for version 6.5.0-1017\n",
            "linux-tools-6.5.0-1018-aws - Linux kernel version specific tools for version 6.5.0-1018\n",
            "linux-tools-6.5.0-1018-azure - Linux kernel version specific tools for version 6.5.0-1018\n",
            "linux-tools-6.5.0-1018-gcp - Linux kernel version specific tools for version 6.5.0-1018\n",
            "linux-tools-6.5.0-1018-nvidia - Linux kernel version specific tools for version 6.5.0-1018\n",
            "linux-tools-6.5.0-1018-oem - Linux kernel version specific tools for version 6.5.0-1018\n",
            "linux-tools-6.5.0-1018-oracle - Oracle Linux kernel version specific tools for version 6.5.0-1018\n",
            "linux-tools-6.5.0-1019-azure - Linux kernel version specific tools for version 6.5.0-1019\n",
            "linux-tools-6.5.0-1019-nvidia - Linux kernel version specific tools for version 6.5.0-1019\n",
            "linux-tools-6.5.0-1019-oem - Linux kernel version specific tools for version 6.5.0-1019\n",
            "linux-tools-6.5.0-1019-oracle - Oracle Linux kernel version specific tools for version 6.5.0-1019\n",
            "linux-tools-6.5.0-1020-aws - Linux kernel version specific tools for version 6.5.0-1020\n",
            "linux-tools-6.5.0-1020-gcp - Linux kernel version specific tools for version 6.5.0-1020\n",
            "linux-tools-6.5.0-1020-oem - Linux kernel version specific tools for version 6.5.0-1020\n",
            "linux-tools-6.5.0-1020-oracle - Oracle Linux kernel version specific tools for version 6.5.0-1020\n",
            "linux-tools-6.5.0-1021-aws - Linux kernel version specific tools for version 6.5.0-1021\n",
            "linux-tools-6.5.0-1021-azure - Linux kernel version specific tools for version 6.5.0-1021\n",
            "linux-tools-6.5.0-1021-nvidia - Linux kernel version specific tools for version 6.5.0-1021\n",
            "linux-tools-6.5.0-1021-oracle - Oracle Linux kernel version specific tools for version 6.5.0-1021\n",
            "linux-tools-6.5.0-1022-aws - Linux kernel version specific tools for version 6.5.0-1022\n",
            "linux-tools-6.5.0-1022-azure - Linux kernel version specific tools for version 6.5.0-1022\n",
            "linux-tools-6.5.0-1022-gcp - Linux kernel version specific tools for version 6.5.0-1022\n",
            "linux-tools-6.5.0-1022-nvidia - Linux kernel version specific tools for version 6.5.0-1022\n",
            "linux-tools-6.5.0-1022-oem - Linux kernel version specific tools for version 6.5.0-1022\n",
            "linux-tools-6.5.0-1023-aws - Linux kernel version specific tools for version 6.5.0-1023\n",
            "linux-tools-6.5.0-1023-azure - Linux kernel version specific tools for version 6.5.0-1023\n",
            "linux-tools-6.5.0-1023-gcp - Linux kernel version specific tools for version 6.5.0-1023\n",
            "linux-tools-6.5.0-1023-nvidia - Linux kernel version specific tools for version 6.5.0-1023\n",
            "linux-tools-6.5.0-1023-oem - Linux kernel version specific tools for version 6.5.0-1023\n",
            "linux-tools-6.5.0-1023-oracle - Oracle Linux kernel version specific tools for version 6.5.0-1023\n",
            "linux-tools-6.5.0-1024-aws - Linux kernel version specific tools for version 6.5.0-1024\n",
            "linux-tools-6.5.0-1024-azure - Linux kernel version specific tools for version 6.5.0-1024\n",
            "linux-tools-6.5.0-1024-gcp - Linux kernel version specific tools for version 6.5.0-1024\n",
            "linux-tools-6.5.0-1024-nvidia - Linux kernel version specific tools for version 6.5.0-1024\n",
            "linux-tools-6.5.0-1024-oem - Linux kernel version specific tools for version 6.5.0-1024\n",
            "linux-tools-6.5.0-1024-oracle - Oracle Linux kernel version specific tools for version 6.5.0-1024\n",
            "linux-tools-6.5.0-1025-azure - Linux kernel version specific tools for version 6.5.0-1025\n",
            "linux-tools-6.5.0-1025-gcp - Linux kernel version specific tools for version 6.5.0-1025\n",
            "linux-tools-6.5.0-1025-oem - Linux kernel version specific tools for version 6.5.0-1025\n",
            "linux-tools-6.5.0-1025-oracle - Oracle Linux kernel version specific tools for version 6.5.0-1025\n",
            "linux-tools-6.5.0-1026-oracle - Oracle Linux kernel version specific tools for version 6.5.0-1026\n",
            "linux-tools-6.5.0-1027-oem - Linux kernel version specific tools for version 6.5.0-1027\n",
            "linux-tools-6.5.0-1027-oracle - Oracle Linux kernel version specific tools for version 6.5.0-1027\n",
            "linux-tools-6.5.0-14-generic - Linux kernel version specific tools for version 6.5.0-14\n",
            "linux-tools-6.5.0-14-lowlatency - Linux kernel version specific tools for version 6.5.0-14\n",
            "linux-tools-6.5.0-15-generic - Linux kernel version specific tools for version 6.5.0-15\n",
            "linux-tools-6.5.0-15-lowlatency - Linux kernel version specific tools for version 6.5.0-15\n",
            "linux-tools-6.5.0-17-generic - Linux kernel version specific tools for version 6.5.0-17\n",
            "linux-tools-6.5.0-17-lowlatency - Linux kernel version specific tools for version 6.5.0-17\n",
            "linux-tools-6.5.0-18-generic - Linux kernel version specific tools for version 6.5.0-18\n",
            "linux-tools-6.5.0-21-generic - Linux kernel version specific tools for version 6.5.0-21\n",
            "linux-tools-6.5.0-21-lowlatency - Linux kernel version specific tools for version 6.5.0-21\n",
            "linux-tools-6.5.0-25-generic - Linux kernel version specific tools for version 6.5.0-25\n",
            "linux-tools-6.5.0-25-lowlatency - Linux kernel version specific tools for version 6.5.0-25\n",
            "linux-tools-6.5.0-26-generic - Linux kernel version specific tools for version 6.5.0-26\n",
            "linux-tools-6.5.0-26-lowlatency - Linux kernel version specific tools for version 6.5.0-26\n",
            "linux-tools-6.5.0-27-generic - Linux kernel version specific tools for version 6.5.0-27\n",
            "linux-tools-6.5.0-27-lowlatency - Linux kernel version specific tools for version 6.5.0-27\n",
            "linux-tools-6.5.0-28-generic - Linux kernel version specific tools for version 6.5.0-28\n",
            "linux-tools-6.5.0-28-lowlatency - Linux kernel version specific tools for version 6.5.0-28\n",
            "linux-tools-6.5.0-35-generic - Linux kernel version specific tools for version 6.5.0-35\n",
            "linux-tools-6.5.0-35-lowlatency - Linux kernel version specific tools for version 6.5.0-35\n",
            "linux-tools-6.5.0-41-generic - Linux kernel version specific tools for version 6.5.0-41\n",
            "linux-tools-6.5.0-41-lowlatency - Linux kernel version specific tools for version 6.5.0-41\n",
            "linux-tools-6.5.0-42-lowlatency - Linux kernel version specific tools for version 6.5.0-42\n",
            "linux-tools-6.5.0-44-generic - Linux kernel version specific tools for version 6.5.0-44\n",
            "linux-tools-6.5.0-44-lowlatency - Linux kernel version specific tools for version 6.5.0-44\n",
            "linux-tools-6.5.0-45-generic - Linux kernel version specific tools for version 6.5.0-45\n",
            "linux-tools-6.5.0-45-lowlatency - Linux kernel version specific tools for version 6.5.0-45\n",
            "linux-tools-6.8.0-1006-oracle - Linux kernel version specific tools for version 6.8.0-1006\n",
            "linux-tools-6.8.0-1008-azure - Linux kernel version specific tools for version 6.8.0-1008\n",
            "linux-tools-6.8.0-1008-ibm - Linux kernel version specific tools for version 6.8.0-1008\n",
            "linux-tools-6.8.0-1008-nvidia - Linux kernel version specific tools for version 6.8.0-1008\n",
            "linux-tools-6.8.0-1008-oracle - Linux kernel version specific tools for version 6.8.0-1008\n",
            "linux-tools-6.8.0-1009-aws - Linux kernel version specific tools for version 6.8.0-1009\n",
            "linux-tools-6.8.0-1009-azure - Linux kernel version specific tools for version 6.8.0-1009\n",
            "linux-tools-6.8.0-1009-nvidia - Linux kernel version specific tools for version 6.8.0-1009\n",
            "linux-tools-6.8.0-1010-aws - Linux kernel version specific tools for version 6.8.0-1010\n",
            "linux-tools-6.8.0-1010-azure - Linux kernel version specific tools for version 6.8.0-1010\n",
            "linux-tools-6.8.0-1010-gcp - Linux kernel version specific tools for version 6.8.0-1010\n",
            "linux-tools-6.8.0-1010-ibm - Linux kernel version specific tools for version 6.8.0-1010\n",
            "linux-tools-6.8.0-1010-nvidia - Linux kernel version specific tools for version 6.8.0-1010\n",
            "linux-tools-6.8.0-1010-oracle - Linux kernel version specific tools for version 6.8.0-1010\n",
            "linux-tools-6.8.0-1011-aws - Linux kernel version specific tools for version 6.8.0-1011\n",
            "linux-tools-6.8.0-1011-gcp - Linux kernel version specific tools for version 6.8.0-1011\n",
            "linux-tools-6.8.0-1011-ibm - Linux kernel version specific tools for version 6.8.0-1011\n",
            "linux-tools-6.8.0-1011-nvidia - Linux kernel version specific tools for version 6.8.0-1011\n",
            "linux-tools-6.8.0-1011-oracle - Linux kernel version specific tools for version 6.8.0-1011\n",
            "linux-tools-6.8.0-1012-azure - Linux kernel version specific tools for version 6.8.0-1012\n",
            "linux-tools-6.8.0-1012-gcp - Linux kernel version specific tools for version 6.8.0-1012\n",
            "linux-tools-6.8.0-1012-ibm - Linux kernel version specific tools for version 6.8.0-1012\n",
            "linux-tools-6.8.0-1012-nvidia - Linux kernel version specific tools for version 6.8.0-1012\n",
            "linux-tools-6.8.0-1012-oracle - Linux kernel version specific tools for version 6.8.0-1012\n",
            "linux-tools-6.8.0-1013-aws - Linux kernel version specific tools for version 6.8.0-1013\n",
            "linux-tools-6.8.0-1013-azure - Linux kernel version specific tools for version 6.8.0-1013\n",
            "linux-tools-6.8.0-1013-gcp - Linux kernel version specific tools for version 6.8.0-1013\n",
            "linux-tools-6.8.0-1013-ibm - Linux kernel version specific tools for version 6.8.0-1013\n",
            "linux-tools-6.8.0-1013-nvidia - Linux kernel version specific tools for version 6.8.0-1013\n",
            "linux-tools-6.8.0-1014-aws - Linux kernel version specific tools for version 6.8.0-1014\n",
            "linux-tools-6.8.0-1014-azure - Linux kernel version specific tools for version 6.8.0-1014\n",
            "linux-tools-6.8.0-1014-gcp - Linux kernel version specific tools for version 6.8.0-1014\n",
            "linux-tools-6.8.0-1014-nvidia - Linux kernel version specific tools for version 6.8.0-1014\n",
            "linux-tools-6.8.0-1015-aws - Linux kernel version specific tools for version 6.8.0-1015\n",
            "linux-tools-6.8.0-1015-gcp - Linux kernel version specific tools for version 6.8.0-1015\n",
            "linux-tools-6.8.0-38-generic - Linux kernel version specific tools for version 6.8.0-38\n",
            "linux-tools-6.8.0-38-lowlatency - Linux kernel version specific tools for version 6.8.0-38\n",
            "linux-tools-6.8.0-39-generic - Linux kernel version specific tools for version 6.8.0-39\n",
            "linux-tools-6.8.0-40-generic - Linux kernel version specific tools for version 6.8.0-40\n",
            "linux-tools-6.8.0-40-lowlatency - Linux kernel version specific tools for version 6.8.0-40\n",
            "linux-tools-6.8.0-44-lowlatency - Linux kernel version specific tools for version 6.8.0-44\n",
            "linux-tools-6.8.0-45-generic - Linux kernel version specific tools for version 6.8.0-45\n",
            "linux-tools-6.8.0-45-lowlatency - Linux kernel version specific tools for version 6.8.0-45\n",
            "linux-tools-aws-edge - Linux kernel versioned tools for Amazon Web Services (AWS) systems.\n",
            "linux-tools-aws-lts-22.04 - Linux kernel versioned tools for Amazon Web Services (AWS) systems.\n",
            "linux-tools-azure-edge - Linux kernel versioned tools for Azure systems.\n",
            "linux-tools-azure-fde - Linux kernel versioned tools for Azure systems.\n",
            "linux-tools-azure-fde-edge - Linux kernel versioned tools for Azure systems.\n",
            "linux-tools-azure-fde-lts-22.04 - Linux kernel versioned tools for Azure systems.\n",
            "linux-tools-azure-lts-22.04 - Linux kernel versioned tools for Azure systems.\n",
            "linux-tools-gcp-edge - Google Cloud Platform (GCP) Linux kernel tools\n",
            "linux-tools-gcp-lts-22.04 - Google Cloud Platform (GCP) Linux kernel tools\n",
            "linux-tools-gkeop - Generic Linux kernel tools\n",
            "linux-tools-gkeop-5.15 - Generic Linux kernel tools\n",
            "linux-tools-ibm-edge - IBM Cloud Platform (ibm) Linux kernel tools\n",
            "linux-tools-nvidia - Linux kernel tools for Nvidia systems.\n",
            "linux-tools-nvidia-6.2 - Nvidia Linux kernel tools\n",
            "linux-tools-nvidia-6.5 - Nvidia Linux kernel tools\n",
            "linux-tools-nvidia-6.8 - Nvidia Linux kernel tools\n",
            "linux-tools-nvidia-edge - Nvidia Linux kernel tools\n",
            "linux-tools-nvidia-hwe-22.04 - Nvidia Linux kernel tools\n",
            "linux-tools-nvidia-hwe-22.04-edge - Nvidia Linux kernel tools\n",
            "linux-tools-nvidia-hwe-22.04-wip - Nvidia Linux kernel tools\n",
            "linux-tools-nvidia-lowlatency - Linux kernel tools for Nvidia systems.\n",
            "linux-tools-oem-22.04 - OEM Linux kernel tools (transitional package)\n",
            "linux-tools-oem-22.04a - OEM Linux kernel tools (transitional package)\n",
            "linux-tools-oem-22.04b - OEM Linux kernel tools (transitional package)\n",
            "linux-tools-oem-22.04c - OEM Linux kernel tools (transitional package)\n",
            "linux-tools-oem-22.04d - OEM Linux kernel tools (transitional package)\n",
            "linux-tools-oracle-edge - Linux kernel versioned tools for Oracle systems.\n",
            "linux-tools-oracle-lts-22.04 - Linux kernel versioned tools for Oracle systems.\n",
            "linux-tools-5.15.0-1019-gkeop - Linux kernel version specific tools for version 5.15.0-1019\n",
            "linux-tools-5.15.0-1020-gkeop - Linux kernel version specific tools for version 5.15.0-1020\n",
            "linux-tools-5.15.0-1021-gkeop - Linux kernel version specific tools for version 5.15.0-1021\n",
            "linux-tools-5.15.0-1022-gkeop - Linux kernel version specific tools for version 5.15.0-1022\n",
            "linux-tools-5.15.0-1023-gkeop - Linux kernel version specific tools for version 5.15.0-1023\n",
            "linux-tools-5.15.0-1024-gkeop - Linux kernel version specific tools for version 5.15.0-1024\n",
            "linux-tools-5.15.0-1025-gkeop - Linux kernel version specific tools for version 5.15.0-1025\n",
            "linux-tools-5.15.0-1026-gkeop - Linux kernel version specific tools for version 5.15.0-1026\n",
            "linux-tools-5.15.0-1027-gkeop - Linux kernel version specific tools for version 5.15.0-1027\n",
            "linux-tools-5.15.0-1028-gkeop - Linux kernel version specific tools for version 5.15.0-1028\n",
            "linux-tools-5.15.0-1030-gkeop - Linux kernel version specific tools for version 5.15.0-1030\n",
            "linux-tools-5.15.0-1031-gkeop - Linux kernel version specific tools for version 5.15.0-1031\n",
            "linux-tools-5.15.0-1032-realtime - Linux kernel version specific tools for version 5.15.0-1032\n",
            "linux-tools-5.19.0-1010-nvidia - Linux kernel version specific tools for version 5.19.0-1010\n",
            "linux-tools-5.19.0-1010-nvidia-lowlatency - Linux kernel version specific tools for version 5.19.0-1010\n",
            "linux-tools-5.19.0-1014-nvidia - Linux kernel version specific tools for version 5.19.0-1014\n",
            "linux-tools-5.19.0-1014-nvidia-lowlatency - Linux kernel version specific tools for version 5.19.0-1014\n",
            "linux-tools-5.19.0-1022-oracle - Oracle Linux kernel version specific tools for version 5.19.0-1022\n",
            "linux-tools-nvidia-5.19 - Nvidia-5.19 Linux kernel tools\n",
            "linux-tools-nvidia-lowlatency-5.19 - Nvidia-5.19 Linux kernel tools\n",
            "linux-tools-nvidia-lowlatency-edge - Nvidia-5.19 Linux kernel tools\n",
            "linux-tools-realtime - Linux kernel versioned tools for real-time systems.\n",
            "linux-tools-azure-fde-5.19-edge - Linux kernel versioned tools for Azure systems.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  hwdata libpci3 linux-tools-5.15.0-122 linux-tools-5.15.0-122-generic pci.ids\n",
            "  usb.ids\n",
            "The following NEW packages will be installed:\n",
            "  hwdata libpci3 linux-tools-5.15.0-122 linux-tools-5.15.0-122-generic\n",
            "  linux-tools-common linux-tools-generic pci.ids usb.ids\n",
            "0 upgraded, 8 newly installed, 0 to remove and 55 not upgraded.\n",
            "Need to get 8,777 kB of archives.\n",
            "After this operation, 31.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 pci.ids all 0.0~2022.01.22-1 [251 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpci3 amd64 1:3.7.0-6 [28.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb.ids all 2022.04.02-1 [219 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 hwdata all 0.357-1 [26.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 linux-tools-common all 5.15.0-122.132 [293 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 linux-tools-5.15.0-122 amd64 5.15.0-122.132 [7,955 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 linux-tools-5.15.0-122-generic amd64 5.15.0-122.132 [1,790 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 linux-tools-generic amd64 5.15.0.122.122 [2,290 B]\n",
            "Fetched 8,777 kB in 2s (4,664 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 8.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package pci.ids.\n",
            "(Reading database ... 124772 files and directories currently installed.)\n",
            "Preparing to unpack .../0-pci.ids_0.0~2022.01.22-1_all.deb ...\n",
            "Unpacking pci.ids (0.0~2022.01.22-1) ...\n",
            "Selecting previously unselected package libpci3:amd64.\n",
            "Preparing to unpack .../1-libpci3_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking libpci3:amd64 (1:3.7.0-6) ...\n",
            "Selecting previously unselected package usb.ids.\n",
            "Preparing to unpack .../2-usb.ids_2022.04.02-1_all.deb ...\n",
            "Unpacking usb.ids (2022.04.02-1) ...\n",
            "Selecting previously unselected package hwdata.\n",
            "Preparing to unpack .../3-hwdata_0.357-1_all.deb ...\n",
            "Unpacking hwdata (0.357-1) ...\n",
            "Selecting previously unselected package linux-tools-common.\n",
            "Preparing to unpack .../4-linux-tools-common_5.15.0-122.132_all.deb ...\n",
            "Unpacking linux-tools-common (5.15.0-122.132) ...\n",
            "Selecting previously unselected package linux-tools-5.15.0-122.\n",
            "Preparing to unpack .../5-linux-tools-5.15.0-122_5.15.0-122.132_amd64.deb ...\n",
            "Unpacking linux-tools-5.15.0-122 (5.15.0-122.132) ...\n",
            "Selecting previously unselected package linux-tools-5.15.0-122-generic.\n",
            "Preparing to unpack .../6-linux-tools-5.15.0-122-generic_5.15.0-122.132_amd64.deb ...\n",
            "Unpacking linux-tools-5.15.0-122-generic (5.15.0-122.132) ...\n",
            "Selecting previously unselected package linux-tools-generic.\n",
            "Preparing to unpack .../7-linux-tools-generic_5.15.0.122.122_amd64.deb ...\n",
            "Unpacking linux-tools-generic (5.15.0.122.122) ...\n",
            "Setting up pci.ids (0.0~2022.01.22-1) ...\n",
            "Setting up usb.ids (2022.04.02-1) ...\n",
            "Setting up libpci3:amd64 (1:3.7.0-6) ...\n",
            "Setting up hwdata (0.357-1) ...\n",
            "Setting up linux-tools-common (5.15.0-122.132) ...\n",
            "Setting up linux-tools-5.15.0-122 (5.15.0-122.132) ...\n",
            "Setting up linux-tools-5.15.0-122-generic (5.15.0-122.132) ...\n",
            "Setting up linux-tools-generic (5.15.0.122.122) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 55 not upgraded.\n",
            "Cloning into 'linux'...\n",
            "remote: Enumerating objects: 12805090, done.\u001b[K\n",
            "remote: Counting objects: 100% (4211/4211), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1940/1940), done.\u001b[K\n",
            "remote: Total 12805090 (delta 3132), reused 2794 (delta 2263), pack-reused 12800879\u001b[K\n",
            "Receiving objects: 100% (12805090/12805090), 5.09 GiB | 17.69 MiB/s, done.\n",
            "^C\n",
            "/bin/bash: line 1: cd: linux/tools/perf: No such file or directory\n",
            "make: *** No targets specified and no makefile found.  Stop.\n",
            "cp: cannot stat 'perf': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!perf --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isckVhGwWT_V",
        "outputId": "09b66785-52bd-4dc1-96be-56d33b4409e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: perf not found for kernel 6.1.85+\n",
            "\n",
            "  You may need to install the following packages for this specific kernel:\n",
            "    linux-tools-6.1.85+-6.1.85+\n",
            "    linux-cloud-tools-6.1.85+-6.1.85+\n",
            "\n",
            "  You may also want to install one of the following packages to keep up to date:\n",
            "    linux-tools-6.1.85+\n",
            "    linux-cloud-tools-6.1.85+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "def write_and_compile_cpp():\n",
        "    # C++ code to process a large vector of data\n",
        "    code = \"\"\"\n",
        "    #include <iostream>\n",
        "    #include <vector>\n",
        "\n",
        "    // Function to process data\n",
        "    void processData(std::vector<int>& data) {\n",
        "        for (auto& x : data) {\n",
        "            x *= 2;  // Multiply each element by 2\n",
        "        }\n",
        "    }\n",
        "\n",
        "    int main() {\n",
        "        std::vector<int> data(1000000, 1);  // Initialize a vector with 1,000,000 elements set to 1\n",
        "        processData(data);  // Process the data\n",
        "        std::cout << \"Data processed.\" << std::endl;\n",
        "        return 0;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    # Save the C++ code to a file\n",
        "    with open(\"process_data.cpp\", \"w\") as file:\n",
        "        file.write(code)\n",
        "\n",
        "    # Compile the C++ program\n",
        "    compile_command = \"g++ -o process_data process_data.cpp\"\n",
        "    subprocess.run(compile_command, shell=True, check=True)\n",
        "    print(\"C++ program compiled successfully.\")\n",
        "\n",
        "# Write, compile, and run the C++ program\n",
        "write_and_compile_cpp()\n",
        "\n",
        "# Check if `perf` is available in the system\n",
        "try:\n",
        "    subprocess.run([\"perf\", \"--version\"], check=True)\n",
        "    print(\"`perf` is available. Running the program with `perf`...\")\n",
        "\n",
        "    # Run the program with `perf` to collect profiling data\n",
        "    perf_command = \"perf record -g ./process_data\"\n",
        "    subprocess.run(perf_command, shell=True, check=True)\n",
        "\n",
        "    # Generate the `perf` report\n",
        "    perf_report_command = \"perf report\"\n",
        "    subprocess.run(perf_report_command, shell=True)\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(\"Error running `perf`:\", e)\n",
        "    print(\"\\nIt seems `perf` is not available or cannot be run in this environment. Please try running these commands manually in a terminal:\\n\")\n",
        "    print(\"1. Compile the program: g++ -o process_data process_data.cpp\")\n",
        "    print(\"2. Run the program with `perf`: perf record -g ./process_data\")\n",
        "    print(\"3. View the report: perf report\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wlRQjQLSHO_",
        "outputId": "7e2073c2-a176-482d-d534-a4027b58cb34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C++ program compiled successfully.\n",
            "Error running `perf`: Command '['perf', '--version']' returned non-zero exit status 2.\n",
            "\n",
            "It seems `perf` is not available or cannot be run in this environment. Please try running these commands manually in a terminal:\n",
            "\n",
            "1. Compile the program: g++ -o process_data process_data.cpp\n",
            "2. Run the program with `perf`: perf record -g ./process_data\n",
            "3. View the report: perf report\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Explanation of the Code\n",
        "\n",
        "1. **C++ Program Overview**:\n",
        "   The program initializes a large vector (`std::vector<int>`) with 1,000,000 elements, all set to 1. The `processData` function then processes this vector by multiplying each element by 2. Finally, the program prints \"Data processed\" to the console.\n",
        "\n",
        "2. **Profiling with `perf`**:\n",
        "   - We use the `perf` tool to profile the program and collect sampling data. The command `perf record -g ./process_data` runs the program and collects profiling data, including a call graph to show the function hierarchy.\n",
        "   - After execution, we run `perf report` to generate a performance report. This report will display how much time was spent in each function.\n",
        "\n",
        "3. **Interpreting the Results**:\n",
        "   - Once the program is run and the profiling data is collected, we use `perf` to view the performance report. It will highlight the time spent in functions such as `main` and `processData`, showing where optimization might be needed.\n"
      ],
      "metadata": {
        "id": "M48Y1rI_SG2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ug-Qfr8mcW-U"
      }
    }
  ]
}